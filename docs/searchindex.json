{"categories":[{"title":"Ai Agent","uri":"https://wymli.github.io/categories/ai-agent/"},{"title":"Algorithm","uri":"https://wymli.github.io/categories/algorithm/"},{"title":"Arch","uri":"https://wymli.github.io/categories/arch/"},{"title":"Atomic","uri":"https://wymli.github.io/categories/atomic/"},{"title":"BigData","uri":"https://wymli.github.io/categories/bigdata/"},{"title":"ByteDance","uri":"https://wymli.github.io/categories/bytedance/"},{"title":"C","uri":"https://wymli.github.io/categories/c/"},{"title":"Cache","uri":"https://wymli.github.io/categories/cache/"},{"title":"Cli","uri":"https://wymli.github.io/categories/cli/"},{"title":"Concurrency","uri":"https://wymli.github.io/categories/concurrency/"},{"title":"ConfigCenter","uri":"https://wymli.github.io/categories/configcenter/"},{"title":"Container","uri":"https://wymli.github.io/categories/container/"},{"title":"Database","uri":"https://wymli.github.io/categories/database/"},{"title":"DataMining","uri":"https://wymli.github.io/categories/datamining/"},{"title":"DataStructure","uri":"https://wymli.github.io/categories/datastructure/"},{"title":"Db","uri":"https://wymli.github.io/categories/db/"},{"title":"Deploy","uri":"https://wymli.github.io/categories/deploy/"},{"title":"Distribute","uri":"https://wymli.github.io/categories/distribute/"},{"title":"Golang","uri":"https://wymli.github.io/categories/golang/"},{"title":"Gpu","uri":"https://wymli.github.io/categories/gpu/"},{"title":"Http","uri":"https://wymli.github.io/categories/http/"},{"title":"Install","uri":"https://wymli.github.io/categories/install/"},{"title":"Interview","uri":"https://wymli.github.io/categories/interview/"},{"title":"K8s","uri":"https://wymli.github.io/categories/k8s/"},{"title":"Linux","uri":"https://wymli.github.io/categories/linux/"},{"title":"Llm","uri":"https://wymli.github.io/categories/llm/"},{"title":"MessageQueue","uri":"https://wymli.github.io/categories/messagequeue/"},{"title":"Net","uri":"https://wymli.github.io/categories/net/"},{"title":"OS","uri":"https://wymli.github.io/categories/os/"},{"title":"OS-Memory","uri":"https://wymli.github.io/categories/os-memory/"},{"title":"Other","uri":"https://wymli.github.io/categories/other/"},{"title":"Protocal","uri":"https://wymli.github.io/categories/protocal/"},{"title":"Protocol","uri":"https://wymli.github.io/categories/protocol/"},{"title":"Python","uri":"https://wymli.github.io/categories/python/"},{"title":"Redis","uri":"https://wymli.github.io/categories/redis/"},{"title":"Rpc","uri":"https://wymli.github.io/categories/rpc/"},{"title":"Script","uri":"https://wymli.github.io/categories/script/"},{"title":"Sys","uri":"https://wymli.github.io/categories/sys/"},{"title":"TaskQueue","uri":"https://wymli.github.io/categories/taskqueue/"},{"title":"Tensorflow","uri":"https://wymli.github.io/categories/tensorflow/"},{"title":"Todo","uri":"https://wymli.github.io/categories/todo/"},{"title":"UnderTheHood","uri":"https://wymli.github.io/categories/underthehood/"},{"title":"Volcano","uri":"https://wymli.github.io/categories/volcano/"},{"title":"Vue","uri":"https://wymli.github.io/categories/vue/"},{"title":"Workflow","uri":"https://wymli.github.io/categories/workflow/"}],"posts":[{"content":"UnderTheHood 这里记录一些具有重要的知识\nPage Cache 主存充当两个功能,一个是进程的存储空间(堆栈),一个磁盘的缓存(page cache) 如此一来,一切都说得通了,我们常说read要从内核缓冲区拷贝到用户缓冲区,你也许和我有一样的疑惑,为什么要先拷贝到内核缓冲区呢?不能直接拷贝到用户缓冲区呢?\n其实,这是属于名词的误用,这个内核缓冲区,其实不是缓冲区,而是磁盘的缓存page cache.当我们读取磁盘时,为了降低缺失率,我们会在内存中缓存磁盘的数据,这称为page cache.大部分未被分配给进程的内存都作为page cache存在.\n因此,这里内核缓冲区到用户缓冲区的拷贝,实际是page cache到用户buffer的拷贝!\n那为什么不直接从磁盘拷贝到用户缓冲区呢?\n为了缓存 如果是直接拷贝到用户缓冲区,那么同时还要拷贝到page cache上,这是愚蠢的.就像cpu的cache一样,寄存器永远是从cache读数据,而不是从内存读数据,当cache缺失时,会read allocate,从内存拷贝到缓存,再从缓存拷贝到寄存器.这里也是一样的道理,从磁盘buffer拷贝到page cache,再从page cache拷贝到user buffer.(注意到磁盘也是有buffer,常称为disk buffer,是位于磁盘上的内存,用于减少io次数)\n接受接口，返回结构 这是一个go谚语(或Gopherism),我们期望函数能接收抽象的类型,但是返回实际的类型.\n接受接口,这是因为函数内部只需要调用有限的对象的方法,因此我们不期望限定死对象的类别,只要实现了对应的方法即可.\n返回结构,这是因为接口定义了特定的有限的方法集,我们无法访问该结构其他的方法或内置变量,除非type assertion.这降低了用户的可操作性.\n第三方库不应该panic,应该返回错误 进程，线程，协程 硬件线程：对硬件来说，四核八线程就是只支持8个硬件线程，即8条同时运行的指令序列。 内核线程：操作系统内核有专门的线程结构体task_struct，这个结构体就唯一代表了一个内核线程，内核可以调度内核线程运行到cpu的8个硬件线程上，典型的如pthread，对于该pthread执行的指令序列，可以视之为用户态的一个线程，因此典型的pthread是内核：用户=1：1。 用户态线程：完全由用户程序去调度异步的指令序列，一个异步的指令序列就可以看作是一个用户态线程，该线程需要的堆栈，调度都由用户态调度代码去完成，而不是内核来调度。 （堆是进程级别的内存资源不需要特别去管，因为是用户态，没办法去管理栈，只能访问堆，所以用户线程的栈是在堆上的，在堆上申请一下空间，在调度到这个线程的时候，就设置下cpu的esp，ebp寄存器的地址就好了。关于用户线程的栈还分共享栈和独立栈，栈是一种需要在堆上分配的资源，一种朴素的想法是每个用户线程都分配一个静态的一定大小的栈，称为独立栈，但这样会对资源浪费，因为很可能线程用不到那么大的栈空间；共享栈就是你线程运行时候的栈是一个公共的栈，大家所有线程运行的时候，ebp都是这个共享栈基质，当你被调度出去的时候，你就把你在共享栈上的数据保存到你自己的空间，调度回来的时候就把栈数据拷贝到共享栈重新运行。在实现上，可以多个用户线程共享一个栈，而不是所有用户线程共享一个栈，这样也许切换的不是和你一起共享栈的线程，你就不用拷贝栈，继续占着也可以） 此时有两种模型 M:1，多个用户态线程跑到一个pthread上。 M:N，多个用户态线程跑到多个pthread上，简单来说就是可以跨内核线程调度，比如go的协程。 组件依赖 如果你只是想要实现一个差不多就行的，或者说是内部系统，不要引入太多外部依赖，可以使用一些嵌入式的数据库，比如badger，嵌入式kv。\nprotobuf 一个对象应该独立成一个结构，而不是字段平铺在Response里，这样方便在detail和list接口复用。\n// Contains Production-related information message Production { string id = 1; // ... more fields } message GetProductionRequest { string production_id = 1; } message GetProductionResponse { Production production = 1; } service ProductionService { rpc GetProduction (GetProductionRequest) returns (GetProductionResponse); } 一个良好实现上，Request应该加上FieldMask，以标识所期望收到的Response的字段，实现按需。http://dockone.io/article/2434655\n不过用pb原生支持的话，可能就只能决定返回哪些字段了，如果是我的话，会自己定义一个select_fields字段, 定义一些逻辑上的分类，再自己在代码里根据逻辑分类选择返回相关的所有字段，这样更灵活，因为很多时候，某些相关的字段是平铺的，没有聚合在一个结构体里。\n如何学习 学习一个东西的方法，先看怎么使用，跑个demo出来，才不会言之无物。\n","id":0,"section":"posts","summary":"\u003ch1 id=\"underthehood\"\u003eUnderTheHood\u003c/h1\u003e\n\u003cp\u003e这里记录一些具有重要的知识\u003c/p\u003e\n\u003ch2 id=\"page-cache\"\u003ePage Cache\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e主存充当两个功能,一个是进程的存储空间(堆栈),一个磁盘的缓存(page cache)\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e如此一来,一切都说得通了,我们常说read要从内核缓冲区拷贝到用户缓冲区,你也许和我有一样的疑惑,为什么要先拷贝到内核缓冲区呢?不能直接拷贝到用户缓冲区呢?\u003c/p\u003e","tags":["UnderTheHood"],"title":"[UnderTheHood] 基础-重要-知识-教旨-格言-蝉","uri":"https://wymli.github.io/2021/04/a1underthehood-underthehood/","year":"2021"},{"content":" 前往飞书云文档查看 ","id":1,"section":"posts","summary":"\u003cp\u003e\u003ca href=\"https://c6t4wbgxht.feishu.cn/docx/OuIud1XOZo1A10xmYuVc3ph2n9O\" target=\"_blank\"\u003e 前往飞书云文档查看 \u003c/a\u003e\u003c/p\u003e\n\u003ciframe \n    width=\"100%\"\n    style=\"height: 80vh;\"\n    allow=\"fullscreen\"\n    src=\"https://c6t4wbgxht.feishu.cn/docx/OuIud1XOZo1A10xmYuVc3ph2n9O\"\u003e","tags":["k8s","volcano","gpu"],"title":"[k8s] volcano gpu device plugin","uri":"https://wymli.github.io/2025/05/k8s-volcano-gpu-device-plugin/","year":"2025"},{"content":" 前往飞书云文档查看 ","id":2,"section":"posts","summary":"\u003cp\u003e\u003ca href=\"https://c6t4wbgxht.feishu.cn/docx/SPPcdeeuGo74IuxARRHcAJZ1nkh\" target=\"_blank\"\u003e 前往飞书云文档查看 \u003c/a\u003e\u003c/p\u003e\n\u003ciframe \n    width=\"100%\"\n    style=\"height: 80vh;\"\n    allow=\"fullscreen\"\n    src=\"https://c6t4wbgxht.feishu.cn/docx/SPPcdeeuGo74IuxARRHcAJZ1nkh\"\u003e","tags":["k8s","scheduler"],"title":"[k8s] scheduler","uri":"https://wymli.github.io/2025/05/k8s-scheduler/","year":"2025"},{"content":" 前往飞书云文档查看 ","id":3,"section":"posts","summary":"\u003cp\u003e\u003ca href=\"https://c6t4wbgxht.feishu.cn/docx/K0nidx31xoBpvMxJjyEcYqTUnfc\" target=\"_blank\"\u003e 前往飞书云文档查看 \u003c/a\u003e\u003c/p\u003e\n\u003ciframe \n    width=\"100%\"\n    style=\"height: 80vh;\"\n    allow=\"fullscreen\"\n    src=\"https://c6t4wbgxht.feishu.cn/docx/K0nidx31xoBpvMxJjyEcYqTUnfc\"\u003e","tags":["python","uv"],"title":"[python] uv 版本与包管理","uri":"https://wymli.github.io/2025/05/python-uv/","year":"2025"},{"content":" 前往飞书云文档查看 ","id":4,"section":"posts","summary":"\u003cp\u003e\u003ca href=\"https://c6t4wbgxht.feishu.cn/docx/ByvGdm0fyo5MPZx3BlbchrF9nKb\" target=\"_blank\"\u003e 前往飞书云文档查看 \u003c/a\u003e\u003c/p\u003e\n\u003ciframe \n    width=\"100%\"\n    style=\"height: 80vh;\"\n    allow=\"fullscreen\"\n    src=\"https://c6t4wbgxht.feishu.cn/docx/ByvGdm0fyo5MPZx3BlbchrF9nKb\"\u003e","tags":["net","epoll"],"title":"[epoll] Epoll/Reactor/Netpoll","uri":"https://wymli.github.io/2025/05/net-epoll/","year":"2025"},{"content":" 前往飞书云文档查看 ","id":5,"section":"posts","summary":"\u003cp\u003e\u003ca href=\"https://c6t4wbgxht.feishu.cn/docx/FgcCdRVVgoe72gxMkCecS9L1nzc\" target=\"_blank\"\u003e 前往飞书云文档查看 \u003c/a\u003e\u003c/p\u003e\n\u003ciframe \n    width=\"100%\"\n    style=\"height: 80vh;\"\n    allow=\"fullscreen\"\n    src=\"https://c6t4wbgxht.feishu.cn/docx/FgcCdRVVgoe72gxMkCecS9L1nzc\"\u003e","tags":["llm"],"title":"[llm] Intro","uri":"https://wymli.github.io/2025/05/llm-intro/","year":"2025"},{"content":" 前往飞书云文档查看 ","id":6,"section":"posts","summary":"\u003cp\u003e\u003ca href=\"https://c6t4wbgxht.feishu.cn/docx/WLmndFiDgokHVvxoBkZczB67n3b\" target=\"_blank\"\u003e 前往飞书云文档查看 \u003c/a\u003e\u003c/p\u003e\n\u003ciframe \n    width=\"100%\"\n    style=\"height: 80vh;\"\n    allow=\"fullscreen\"\n    src=\"https://c6t4wbgxht.feishu.cn/docx/WLmndFiDgokHVvxoBkZczB67n3b\"\u003e","tags":["ai agent","eino"],"title":"[AI Agent] Eino","uri":"https://wymli.github.io/2025/05/aiagent-eino/","year":"2025"},{"content":" 前往飞书云文档查看 ","id":7,"section":"posts","summary":"\u003cp\u003e\u003ca href=\"https://c6t4wbgxht.feishu.cn/docx/Uyvadiw7zorRhLxww1LcMRaanib\" target=\"_blank\"\u003e 前往飞书云文档查看 \u003c/a\u003e\u003c/p\u003e\n\u003ciframe \n    width=\"100%\"\n    style=\"height: 80vh;\"\n    allow=\"fullscreen\"\n    src=\"https://c6t4wbgxht.feishu.cn/docx/Uyvadiw7zorRhLxww1LcMRaanib\"\u003e","tags":["db"],"title":"[DB] 事务隔离与锁","uri":"https://wymli.github.io/2025/05/db-mutex/","year":"2025"},{"content":" 前往飞书云文档查看 ","id":8,"section":"posts","summary":"\u003cp\u003e\u003ca href=\"https://c6t4wbgxht.feishu.cn/docx/O5M1dTRLxol7G0xScsucuYm6nSg\" target=\"_blank\"\u003e 前往飞书云文档查看 \u003c/a\u003e\u003c/p\u003e\n\u003ciframe \n    width=\"100%\"\n    style=\"height: 80vh;\"\n    allow=\"fullscreen\"\n    src=\"https://c6t4wbgxht.feishu.cn/docx/O5M1dTRLxol7G0xScsucuYm6nSg\"\u003e","tags":["golang"],"title":"[Go] GMP","uri":"https://wymli.github.io/2025/05/go-gmp/","year":"2025"},{"content":" 前往飞书云文档查看 ","id":9,"section":"posts","summary":"\u003cp\u003e\u003ca href=\"https://c6t4wbgxht.feishu.cn/docx/Nu9sd0FobokaxMxEddxc9VTXnIg\" target=\"_blank\"\u003e 前往飞书云文档查看 \u003c/a\u003e\u003c/p\u003e\n\u003ciframe \n    width=\"100%\"\n    style=\"height: 80vh;\"\n    allow=\"fullscreen\"\n    src=\"https://c6t4wbgxht.feishu.cn/docx/Nu9sd0FobokaxMxEddxc9VTXnIg\"\u003e","tags":["golang"],"title":"[Go] release notes","uri":"https://wymli.github.io/2025/05/go-release-notes/","year":"2025"},{"content":" 前往飞书云文档查看 ","id":10,"section":"posts","summary":"\u003cp\u003e\u003ca href=\"https://c6t4wbgxht.feishu.cn/docx/MQmod4xkdoZ2TlxDbQncyQG9nbg\" target=\"_blank\"\u003e 前往飞书云文档查看 \u003c/a\u003e\u003c/p\u003e\n\u003ciframe \n    width=\"100%\"\n    style=\"height: 80vh;\"\n    allow=\"fullscreen\"\n    src=\"https://c6t4wbgxht.feishu.cn/docx/MQmod4xkdoZ2TlxDbQncyQG9nbg\"\u003e","tags":["workflow","temporal"],"title":"[airflow] temporal","uri":"https://wymli.github.io/2025/05/workflow-2.-temporal/","year":"2025"},{"content":" 前往飞书云文档查看 ","id":11,"section":"posts","summary":"\u003cp\u003e\u003ca href=\"https://c6t4wbgxht.feishu.cn/docx/POUfdFT2YoXlbHxeUA2cntmanzc\" target=\"_blank\"\u003e 前往飞书云文档查看 \u003c/a\u003e\u003c/p\u003e\n\u003ciframe \n    width=\"100%\"\n    style=\"height: 80vh;\"\n    allow=\"fullscreen\"\n    src=\"https://c6t4wbgxht.feishu.cn/docx/POUfdFT2YoXlbHxeUA2cntmanzc\"\u003e","tags":["workflow","airflow"],"title":"[airflow] airflow","uri":"https://wymli.github.io/2025/03/worklfow-1.-airflow/","year":"2025"},{"content":"git clone https://github.com/opencontainers/runc.git, 我们简单阅读下，代码不多\n入口 入口没啥好说的，先找main.go文件，可以看到runc这个库用了 github.com/urfave/cli 这个命令行库和 github.com/sirupsen/logrus 这个日志库，能在这种比较重要的工具里面使用，说明这两个库是很不错的。\ncreate create的实际作用是由runc拉起一个 runc（通常称为parentProcess，也就是 runc create \u0026hellip; 这个进程） 拉起一个子runc进程（通常称为childProcess, 或更精确的，initProcess），子runc进程的执行命令为 runc init, 执行后会进行所有ns/rootfs的初始化操作，并阻塞在打开exec.fifo命名管道上，等待start指令，收到指令之后会立即执行system.Exec原地将自己替换成用户主进程。\n这里有无start其实都不太重要，create之后容器环境就创建好了，后续无论是start还是exec都行，一个是执行config.json里的主进程，一个是执行exec命令行里的进程。\nnotify.sock 创建 如果指定了环境变量 NOTIFY_SOCKET， 会创建notify.sock\n默认创建在 ${root}/${container_name}/notify/notify.sock, root是/run/runc 或者 /run/user/1000/runc\nnotifySocket := newNotifySocket(context, os.Getenv(\u0026quot;NOTIFY_SOCKET\u0026quot;), id) if notifySocket != nil { notifySocket.setupSpec(spec) // 在 config.json 中添加 notify.socket 的mount和env } // ... // 创建容器 ... // ... if notifySocket != nil { if err := notifySocket.setupSocketDirectory(); err != nil { // 创建目录和权限 os.Mkdir(path.Dir(s.socketPath), 0o755) return -1, err } if action == CT_ACT_RUN { // 如果是在运行容器，就生成socket文件 if err := notifySocket.bindSocket(); err != nil { return -1, err } } } notifySocket 的主要逻辑其实就是监听 notify.socket, 转发到用户自定义的 socket addr, 应该是用来实现一些事件驱动的\nfunc (n *notifySocket) run(pid1 int) error { if n.socket == nil { return nil } notifySocketHostAddr := net.UnixAddr{Name: n.host, Net: \u0026quot;unixgram\u0026quot;} client, err := net.DialUnix(\u0026quot;unixgram\u0026quot;, nil, \u0026amp;notifySocketHostAddr) if err != nil { return err } ticker := time.NewTicker(time.Millisecond * 100) defer ticker.Stop() fileChan := make(chan []byte) go func() { for { buf := make([]byte, 4096) r, err := n.socket.Read(buf) if err != nil { return } got := buf[0:r] // systemd-ready sends a single datagram with the state string as payload, // so we don't need to worry about partial messages. for _, line := range bytes.Split(got, []byte{'\\n'}) { if bytes.HasPrefix(got, []byte(\u0026quot;READY=\u0026quot;)) { fileChan \u0026lt;- line return } } } }() for { select { case \u0026lt;-ticker.C: _, err := os.Stat(filepath.Join(\u0026quot;/proc\u0026quot;, strconv.Itoa(pid1))) if err != nil { return nil } case b := \u0026lt;-fileChan: return notifyHost(client, b, pid1) } } } systemd on-demand socket 这里学到一个新知识，systemd on-demand socket，大致意思时，配置一个systemd的socket文件，监听某个端口，再配置一个systemd的service文件，关联某个socket文件，随后，当请求打到socket文件关联的端口时，会启动service文件，做到按需启动的功能。\n// Support on-demand socket activation by passing file descriptors into the container init process. listenFDs := []*os.File{} if os.Getenv(\u0026quot;LISTEN_FDS\u0026quot;) != \u0026quot;\u0026quot; { listenFDs = activation.Files(false) } // ... if len(r.listenFDs) \u0026gt; 0 { process.Env = append(process.Env, \u0026quot;LISTEN_FDS=\u0026quot;+strconv.Itoa(len(r.listenFDs)), \u0026quot;LISTEN_PID=1\u0026quot;) process.ExtraFiles = append(process.ExtraFiles, r.listenFDs...) // 应该是为了容器内的进程可以读到LISTEN_FD } 回头专门开一章跑个demo试试，有点faas的意思\ncreate container func createContainer(context *cli.Context, id string, spec *specs.Spec) (*libcontainer.Container, error) { rootlessCg, err := shouldUseRootlessCgroupManager(context) // 内容暂时看不懂，反正就是准备rootless cgroup配置 if err != nil { return nil, err } config, err := specconv.CreateLibcontainerConfig(\u0026amp;specconv.CreateOpts{ // 这一步是将runc 的config转成 libcontainer的config CgroupName: id, UseSystemdCgroup: context.GlobalBool(\u0026quot;systemd-cgroup\u0026quot;), NoPivotRoot: context.Bool(\u0026quot;no-pivot\u0026quot;), NoNewKeyring: context.Bool(\u0026quot;no-new-keyring\u0026quot;), Spec: spec, RootlessEUID: os.Geteuid() != 0, RootlessCgroups: rootlessCg, }) if err != nil { return nil, err } root := context.GlobalString(\u0026quot;root\u0026quot;) return libcontainer.Create(root, id, config) // 得到了一个 Container 结构体 } 处理container console io 我们知道docker一般有 -i, -t, -d 选项和console io有关\n-i 交互模式：容器共享父进程的stdin/stdout/stderr -t 打开一个伪终端: 伪终端的意义就是将stdin/stdout变得不再是一个输入输出流，而是像一个真的终端一点，支持控制字符之类的，比如退格键和方向键，比如显示颜色 -d detach：容器在后台运行，不占用当前终端 // setupIO modifies the given process config according to the options. func setupIO(process *libcontainer.Process, container *libcontainer.Container, createTTY, detach bool, sockpath string) (*tty, error) { // -t 对应 createTTY if createTTY { process.Stdin = nil // 清空进程的标准输入输出 process.Stdout = nil process.Stderr = nil t := \u0026amp;tty{} if !detach { if err := t.initHostConsole(); err != nil { // 从 stderr, stdout, stdin 中找到一个有效的console(tty)，因为有可能当前进程并没有attach一个console return nil, err } parent, child, err := utils.NewSockPair(\u0026quot;console\u0026quot;) if err != nil { return nil, err } process.ConsoleSocket = child t.postStart = append(t.postStart, parent, child) // io.closer t.consoleC = make(chan error, 1) // 这个就是一个简单的wait信号了，console channel go func() { t.consoleC \u0026lt;- t.recvtty(parent) }() } else { // the caller of runc will handle receiving the console master conn, err := net.Dial(\u0026quot;unix\u0026quot;, sockpath) if err != nil { return nil, err } uc, ok := conn.(*net.UnixConn) if !ok { return nil, errors.New(\u0026quot;casting to UnixConn failed\u0026quot;) } t.postStart = append(t.postStart, uc) socket, err := uc.File() if err != nil { return nil, err } t.postStart = append(t.postStart, socket) process.ConsoleSocket = socket // 如果指定了detach，又想分配tty，就得指定一个socket path } return t, nil } // when runc will detach the caller provides the stdio to runc via runc's 0,1,2 // and the container's process inherits runc's stdio. if detach { // 直接继承runc进程的stdio，可以和 setupProcessPipes 对比， setupProcessPipes是新建pipe，在runc进程的stdio之间拷贝 // 直接继承的原因是什么？ inheritStdio(process) // 使用runc进程的stdio, 也就是os.stdout, os.stdin, os.stderr return \u0026amp;tty{}, nil } config := container.Config() rootuid, err := config.HostRootUID() // rootless相关配置 if err != nil { return nil, err } rootgid, err := config.HostRootGID() // rootless相关配置 if err != nil { return nil, err } // 如果既没有tty，也没有detach，进入这里 return setupProcessPipes(process, rootuid, rootgid) } // setup pipes for the process so that advanced features like c/r are able to easily checkpoint // and restore the process's IO without depending on a host specific path or device func setupProcessPipes(p *libcontainer.Process, rootuid, rootgid int) (*tty, error) { i, err := p.InitializeIO(rootuid, rootgid) 创建 os.Pipe, w端挂在process上，r端挂在i，i将会被下面的代码使用 // 这里要新创建一个os.Pipe，而不是直接继承runc进程的stdio的原因是什么？可能是怕多进程写同一个pipe写坏了? if err != nil { return nil, err } t := \u0026amp;tty{ closers: []io.Closer{ i.Stdin, i.Stdout, i.Stderr, }, } // add the process's io to the post start closers if they support close for _, cc := range []interface{}{ p.Stdin, p.Stdout, p.Stderr, } { if c, ok := cc.(io.Closer); ok { t.postStart = append(t.postStart, c) } } go func() { _, _ = io.Copy(i.Stdin, os.Stdin) // 一直copy直到 stdin EOF _ = i.Stdin.Close() // stdin 不用 t.copyIO 是因为copy完后要关闭w端 }() t.wg.Add(2) go t.copyIO(os.Stdout, i.Stdout) // copy完后关闭读端, 一直copy直到EOF go t.copyIO(os.Stderr, i.Stderr) return t, nil } init process 在start的核心逻辑 container.start(process) 中，通过 parent, err := c.newParentProcess(process) 创建出parentProcess, 这里的 parentProcess 有两种，initProcess 或 setnsProcess（这里其实叫做 ProcessControler 好一点，会由这个controler启动子进程，并和子进程交互）\n简化后如下:\ncmd := exec.Command(\u0026quot;/proc/self/exe\u0026quot;, \u0026quot;init\u0026quot;) // `runc init` cmd.Args[0] = os.Args[0] cmd.Stdin = p.Stdin cmd.Stdout = p.Stdout cmd.Stderr = p.Stderr cmd.Dir = c.config.Rootfs // ... // 创建 ipc socket pair (这里不创建os.Pipe, 而是uds, 因为uds是双向的，更灵活，管道是单向的) var ( comm processComm err error ) comm.initSockParent, comm.initSockChild, err = utils.NewSockPair(\u0026quot;init\u0026quot;) // initSock(或者是initPipe, 代码里面是混用的) 作用是 parentProcess和childProcess进行交互，传递childProcess的real pid 和 用户自定义命令等 if err != nil { return nil, fmt.Errorf(\u0026quot;unable to create init pipe: %w\u0026quot;, err) } comm.syncSockParent, comm.syncSockChild, err = newSyncSockpair(\u0026quot;sync\u0026quot;) if err != nil { return nil, fmt.Errorf(\u0026quot;unable to create sync pipe: %w\u0026quot;, err) } comm.logPipeParent, comm.logPipeChild, err = os.Pipe() if err != nil { return nil, fmt.Errorf(\u0026quot;unable to create log pipe: %w\u0026quot;, err) } return \u0026amp;comm, nil // ... if p.Init { // We only set up fifoFd if we're not doing a `runc exec`. The historic // reason for this is that previously we would pass a dirfd that allowed // for container rootfs escape (and not doing it in `runc exec` avoided // that problem), but we no longer do that. However, there's no need to do // this for `runc exec` so we just keep it this way to be safe. if err := c.includeExecFifo(cmd); err != nil { return nil, fmt.Errorf(\u0026quot;unable to setup exec fifo: %w\u0026quot;, err) } return c.newInitProcess(p, cmd, comm) //\tinit := \u0026amp;initProcess{ //\tcontainerProcess: containerProcess{ //\tcmd: cmd, // runc init //\tcomm: comm, // 几个通信的uds //\tmanager: c.cgroupManager, //\tconfig: c.newInitConfig(p), // 里面是 childProcess 用户进程的命令，如果是initProcess，这里是config.json 里的command //\tprocess: p, //\tbootstrapData: data, //\tcontainer: c, //\t}, //\tintelRdtManager: c.intelRdtManager, //\t} //\tc.initProcess = init } return c.newSetnsProcess(p, cmd, comm) //\tproc := \u0026amp;setnsProcess{ //\tcontainerProcess: containerProcess{ //\tcmd: cmd, // runc init //\tcomm: comm, // 几个通信的uds //\tmanager: c.cgroupManager, //\tconfig: c.newInitConfig(p),// 里面是process 用户进程的命令，如果是setnsProcess，这里是 runc exec -it $container $command //\tprocess: p, //\tbootstrapData: data, //\tcontainer: c, //\t}, //\tcgroupPaths: state.CgroupPaths, //\trootlessCgroups: c.config.RootlessCgroups, //\tintelRdtPath: state.IntelRdtPath, //\tinitProcessPid: state.InitProcessPid, //\t} Container 我们看看container有哪些操作：\n// 启动容器，也就是启动 parentProcess，可能是 initProcess 也可能是 setnsProcess (实例化一个processControler后拉起childProcess) func (c *Container) Start(process *Process) error {} func (c *Container) Run(process *Process) error {} func (c *Container) Exec() error {} // 设置容器的配置，比如cgroup配置（可以用于running态容器调整资源） func (c *Container) Set(config configs.Config) error {} // runc进程创建parent进程（parent进程包含两种:initProcess 和 setnsProcess ） func (c *Container) newParentProcess(p *Process) (parentProcess, error) {} // 容器的init进程的controller，当调用runc create后被调用，实例化的process controler将拉起子进程启动init进程，随后原地exec成用户主进程 func (c *Container) newInitProcess(p *Process, cmd *exec.Cmd, comm *processComm) (*initProcess, error) {} // 容器的setns进程的controller，当调用runc exec $command 后被调用，实例化的process controler将拉起子进程启动init进程，随后原地exec成$command进程 func (c *Container) newSetnsProcess(p *Process, cmd *exec.Cmd, comm *processComm) (*setnsProcess, error) {} parentProcess parentProcess 是个interface， 可能的实现是initProcess或者setnsProcess, 这里的parentProcess 可以理解成一个process controller，负责拉起子进程并和子进程交互。\ntype parentProcess interface { // pid returns the pid for the running process. pid() int // start starts the process execution. start() error // send a SIGKILL to the process and wait for the exit. terminate() error // wait waits on the process returning the process state. wait() (*os.ProcessState, error) // startTime returns the process start time. startTime() (uint64, error) signal(os.Signal) error externalDescriptors() []string setExternalDescriptors(fds []string) forwardChildLogs() chan error } initProcess Controller parentProcess // 启动 `runc init` 进程 // err := p.cmd.Start() // 传递 NewNetlinkRequest, 这里使用NetLink结构，因为netlink结构是内核支持的，后面调用系统调用时会比较方便 // if _, err := io.Copy(p.comm.initSockParent, p.bootstrapData); err != nil { // return fmt.Errorf(\u0026quot;can't copy bootstrap data to pipe: %w\u0026quot;, err) // } // 通过initSock获取最终子进程initProcess的pid （子进程在cgo里面的nsexec函数里面经过了多次clone，这里拿到最终的子进程） // childPid, err := p.getChildPid() // 等待直接子进程退出, 然后将 initProcess 设置为待管理的最终子进程 // if err := p.waitForChildExit(childPid); err != nil { // return fmt.Errorf(\u0026quot;error waiting for our first child to exit: %w\u0026quot;, err) // } // 对childPid创建Mount配置：这里的request是个往requestCh发送数据的fn，在 goCreateMountSources 中创建了requestCh，并异步消费requestCh用于mount // request, cancel, err := p.goCreateMountSources(context.Background()) // 对childPid创建网络配置 // p.createNetworkInterfaces() // 向initSock 发送用户进程相关的配置，比如用户进程的启动命令 // utils.WriteJSON(p.comm.initSockParent, p.config) // loop 处理子进程发送过来的一些信息，比如 procMountPlease 请求挂载路径，procSeccomp 暂时没看懂是在干嘛，似乎只是往 seccomp 的listenerPath发送了点东西， procReady 代表container created成功， procHooks 代表runc可以执行一些hooks了，比如Prestart、CreateRuntime // parseSync(p.comm.syncSockParent, func(sync *syncT) error {}) // 读到EOF或处理error后，关闭socket写端，读端会收到EOF // p.comm.syncSockParent.Shutdown(unix.SHUT_WR) func (p *initProcess) start() (retErr error) {} childProcess端 runc会创建出 runc init 子进程, 这个进程会先调用cgo里面的nsexec函数, clone出多个子进程（clone了两次，用于setns等），最终子进程会调用 return system.Exec(name, l.config.Args, l.config.Env) 原地执行用户自定义命令。\n// 可以看到 `init` command 没有注册在main.go, 而是注册在 init func 里 // 原因其实比较简单，是因为使用的cli库没有提供一种ignore参数，如果cli库允许注册某种command，但是不展示在help信息里，那么作为内部command的init，也可以注册在main.go 里，而不用hack在init func 里。 func init() { if len(os.Args) \u0026gt; 1 \u0026amp;\u0026amp; os.Args[1] == \u0026quot;init\u0026quot; { // This is the golang entry point for runc init, executed // before main() but after libcontainer/nsenter's nsexec(). libcontainer.Init() } } // libcontainer: func Init() { runtime.GOMAXPROCS(1) runtime.LockOSThread() if err := startInitialization(); err != nil { // If the error is returned, it was not communicated // back to the parent (which is not a common case), // so print it to stderr here as a last resort. // // Do not use logrus as we are not sure if it has been // set up yet, but most important, if the parent is // alive (and its log forwarding is working). fmt.Fprintln(os.Stderr, err) } // Normally, StartInitialization() never returns, meaning // if we are here, it had failed. os.Exit(255) // 可以看到这里直接退出了，不会进入main 函数 } // Normally, this function does not return. If it returns, with or without an // error, it means the initialization has failed. If the error is returned, // it means the error can not be communicated back to the parent. func startInitialization() (retErr error) { // Get the synchronisation pipe. envSyncPipe := os.Getenv(\u0026quot;_LIBCONTAINER_SYNCPIPE\u0026quot;) syncPipeFd, err := strconv.Atoi(envSyncPipe) if err != nil { return fmt.Errorf(\u0026quot;unable to convert _LIBCONTAINER_SYNCPIPE: %w\u0026quot;, err) } syncPipe := newSyncSocket(os.NewFile(uintptr(syncPipeFd), \u0026quot;sync\u0026quot;)) defer syncPipe.Close() defer func() { // If this defer is ever called, this means initialization has failed. // Send the error back to the parent process in the form of an initError // if the sync socket has not been closed. if syncPipe.isClosed() { return } ierr := initError{Message: retErr.Error()} if err := writeSyncArg(syncPipe, procError, ierr); err != nil { fmt.Fprintln(os.Stderr, err) return } // The error is sent, no need to also return it (or it will be reported twice). retErr = nil }() // Get the INITPIPE. envInitPipe := os.Getenv(\u0026quot;_LIBCONTAINER_INITPIPE\u0026quot;) initPipeFd, err := strconv.Atoi(envInitPipe) if err != nil { return fmt.Errorf(\u0026quot;unable to convert _LIBCONTAINER_INITPIPE: %w\u0026quot;, err) } initPipe := os.NewFile(uintptr(initPipeFd), \u0026quot;init\u0026quot;) defer initPipe.Close() // Set up logging. This is used rarely, and mostly for init debugging. // Passing log level is optional; currently libcontainer/integration does not do it. if levelStr := os.Getenv(\u0026quot;_LIBCONTAINER_LOGLEVEL\u0026quot;); levelStr != \u0026quot;\u0026quot; { logLevel, err := strconv.Atoi(levelStr) if err != nil { return fmt.Errorf(\u0026quot;unable to convert _LIBCONTAINER_LOGLEVEL: %w\u0026quot;, err) } logrus.SetLevel(logrus.Level(logLevel)) } logFd, err := strconv.Atoi(os.Getenv(\u0026quot;_LIBCONTAINER_LOGPIPE\u0026quot;)) if err != nil { return fmt.Errorf(\u0026quot;unable to convert _LIBCONTAINER_LOGPIPE: %w\u0026quot;, err) } logPipe := os.NewFile(uintptr(logFd), \u0026quot;logpipe\u0026quot;) logrus.SetOutput(logPipe) logrus.SetFormatter(new(logrus.JSONFormatter)) logrus.Debug(\u0026quot;child process in init()\u0026quot;) // Only init processes have FIFOFD. var fifoFile *os.File // 这里initType 就两种类型：standard、setns，starndard表示initProcess envInitType := os.Getenv(\u0026quot;_LIBCONTAINER_INITTYPE\u0026quot;) it := initType(envInitType) if it == initStandard { // fifofd 是 exec.fifo 文件，是个fifo命名管道，用于通知initProcess 是否可以调用system.exec 执行用户主进程 fifoFd, err := strconv.Atoi(os.Getenv(\u0026quot;_LIBCONTAINER_FIFOFD\u0026quot;)) if err != nil { return fmt.Errorf(\u0026quot;unable to convert _LIBCONTAINER_FIFOFD: %w\u0026quot;, err) } fifoFile = os.NewFile(uintptr(fifoFd), \u0026quot;initfifo\u0026quot;) } var consoleSocket *os.File if envConsole := os.Getenv(\u0026quot;_LIBCONTAINER_CONSOLE\u0026quot;); envConsole != \u0026quot;\u0026quot; { console, err := strconv.Atoi(envConsole) if err != nil { return fmt.Errorf(\u0026quot;unable to convert _LIBCONTAINER_CONSOLE: %w\u0026quot;, err) } consoleSocket = os.NewFile(uintptr(console), \u0026quot;console-socket\u0026quot;) defer consoleSocket.Close() } var pidfdSocket *os.File if envSockFd := os.Getenv(\u0026quot;_LIBCONTAINER_PIDFD_SOCK\u0026quot;); envSockFd != \u0026quot;\u0026quot; { sockFd, err := strconv.Atoi(envSockFd) if err != nil { return fmt.Errorf(\u0026quot;unable to convert _LIBCONTAINER_PIDFD_SOCK: %w\u0026quot;, err) } pidfdSocket = os.NewFile(uintptr(sockFd), \u0026quot;pidfd-socket\u0026quot;) defer pidfdSocket.Close() } // From here on, we don't need current process environment. It is not // used directly anywhere below this point, but let's clear it anyway. os.Clearenv() defer func() { if err := recover(); err != nil { if err2, ok := err.(error); ok { retErr = fmt.Errorf(\u0026quot;panic from initialization: %w, %s\u0026quot;, err2, debug.Stack()) } else { retErr = fmt.Errorf(\u0026quot;panic from initialization: %v, %s\u0026quot;, err, debug.Stack()) } } }() // 在这里阻塞读runc进程发送过来的init数据，比如用户进程命令啥的 var config initConfig if err := json.NewDecoder(initPipe).Decode(\u0026amp;config); err != nil { return err } // If init succeeds, it will not return, hence none of the defers will be called. return containerInit(it, \u0026amp;config, syncPipe, consoleSocket, pidfdSocket, fifoFile, logPipe) } i := \u0026amp;linuxStandardInit{ pipe: pipe, // sync socket, 用于和 parentProcess(也就是runc) 交互 consoleSocket: consoleSocket, // console socket pidfdSocket: pidfdSocket, // childProcess 创建出来后, 发送childProcess的pid到socket，这个是用户自己建出来的socket，不是runc内部的。在parentProcess中open，继承给childProcess parentPid: unix.Getppid(), // parentProcess(也就是runc)的pid config: config, // 从initPipe 读到的config, 包含用户自定义命令等信息 fifoFile: fifoFile, // exec.fifo 文件, initProcess 特有，用于作为一种信号通知，告知initProcess可以从created变成running(即调用system.exec 原地替换成用户主进程) logPipe: logPipe, // 日志pipe，日志将被parentProcess消费 } fd继承 如果通过fork, 那当然就直接继承了打开的fd，如果是通过*exec.Cmd（或者就是一般说的调用子进程的方式（本质上是fork+exec））, 在go语言的处理上，是通过cmd.ExtraFiles, 比如 cmd.ExtraFiles = append(cmd.ExtraFiles, fifo)\nExtraFiles specifies additional open files to be inherited by the new process. It does not include standard input, standard output, or standard error. If non-nil, entry i becomes file descriptor 3+i. ExtraFiles is not supported on Windows. field ExtraFiles []*os.File 子进程使用该描述符时，其fd编号从3开始（因为0、1、2是内置的），比如ExtraFiles[0]的fd是3，ExtraFiles[1]的编号是4\n很显然，我们比较难知道ExtraFiles[0]到底是个啥，所以runc中会通过环境变量传递：\nfifoName := filepath.Join(c.stateDir, execFifoFilename) fifo, err := os.OpenFile(fifoName, unix.O_PATH|unix.O_CLOEXEC, 0) cmd.ExtraFiles = append(cmd.ExtraFiles, fifo) stdioFdCount := 3 cmd.Env = append(cmd.Env, \u0026quot;_LIBCONTAINER_FIFOFD=\u0026quot;+strconv.Itoa(stdioFdCount+len(cmd.ExtraFiles)-1)) 子进程通过os.NewFile(fd, $name)得到*os.File, name 随便取。\nfifoFd, err := strconv.Atoi(os.Getenv(\u0026quot;_LIBCONTAINER_FIFOFD\u0026quot;)) if err != nil { return fmt.Errorf(\u0026quot;unable to convert _LIBCONTAINER_FIFOFD: %w\u0026quot;, err) } fifoFile = os.NewFile(uintptr(fifoFd), \u0026quot;initfifo\u0026quot;) start 当执行create命令后, initProcess 会阻塞在 fifo 管道上，直到有另一个进程打开管道\nfd, err := unix.Open(fifoPath, unix.O_WRONLY|unix.O_CLOEXEC, 0) if err != nil { return \u0026amp;os.PathError{Op: \u0026quot;open exec fifo\u0026quot;, Path: fifoPath, Err: err} } if _, err := unix.Write(fd, []byte(\u0026quot;0\u0026quot;)); err != nil { return \u0026amp;os.PathError{Op: \u0026quot;write exec fifo\u0026quot;, Path: fifoPath, Err: err} } // ... // 执行用户主进程 return system.Exec(name, l.config.Args, l.config.Env) 当执行start命令时，作用只是打开并读取一下 fifo 管道（这里的读取内容没啥实际信息，可能是为了并发考虑，如果并发调用start，前一个会成功，后一个会失败）\nfunc (c *Container) exec() error { // ... blockingFifoOpenCh := awaitFifoOpen(path) // ... } exec 在runc的设计中，exec和create的差别不大，都有parentProcess和childProcess的概念，只不过从parent/childProcess的意义上将，一个是initProcess，一个是setnsProcess, 但毫无疑问，流程都是差不多的，因为initProcess就是执行用户主进程，setnsProcess就是执行用户自定义命令。\ninitProcess需要执行所有的初始化操作，比如rootfs，各种ns，网络路由等，setns只需要进入对应的ns即可。\nnsexec 在拉起childProcess的过程中，有一个很关键的技术，nsexec(), 这是一个c写的代码, 用于在程序启动时自动进入特定Linux命名空间。 可以看到，cgo的init函数里执行了 nsexec(), 这个 nsexec() 将会在 go 的所有代码（全局变量、init函数、main函数）之前执行，\nattribute((constructor)) 是GCC特性，标记 init() 函数在 ​共享库加载时自动执行。 当Go程序启动时，C代码作为共享库加载，init() 会立即调用 nsexec()\n//go:build linux \u0026amp;\u0026amp; !gccgo package nsenter /* #cgo CFLAGS: -Wall extern void nsexec(); void __attribute__((constructor)) init(void) { nsexec(); } */ import \u0026quot;C\u0026quot; 当正常使用 runc 时，nsexec会直接退出：\npipenum = getenv_int(\u0026quot;_LIBCONTAINER_INITPIPE\u0026quot;); if (pipenum \u0026lt; 0) { /* We are not a runc init. Just return to go runtime. */ return; } 当执行runc init时，也就是childProcess时，nsexec正常执行， 完成了 childProcess 的ns设置(err = setns(ns-\u0026gt;fd, type);)，并进行了多次clone：\n// 当前在stage-0 进程 // 初始化几个pipe int sync_child_pipe[2], sync_grandchild_pipe[2]; socketpair(AF_LOCAL, SOCK_STREAM, 0, sync_child_pipe) socketpair(AF_LOCAL, SOCK_STREAM, 0, sync_grandchild_pipe) switch (setjmp(env)) { case STAGE_PARENT:{ // 子进程直接跳到 STAGE_CHILD 执行 // CLONE_PARENT 参数表示clone出兄弟进程，而非子进程 stage1_pid = clone(()=\u0026gt;{longjmp(env, STAGE_CHILD)}, ca.stack_ptr, CLONE_PARENT | SIGCHLD, \u0026amp;ca); syncfd = sync_child_pipe[1]; close(sync_child_pipe[0]) stage1_complete = false; while (!stage1_complete) { // 处理 syncfd 传递过来的 stage-1 的: // 1. SYNC_USERMAP_PLS(更新进程的uid/gid map: e.g. write_file(map, map_len, \u0026quot;/proc/%d/gid_map\u0026quot;, pid)) // 2. SYNC_RECVPID_PLS(收到stage-1进程发送来的stage2_pid) , 并将stage1_pid, stage2_pid 发送给initPipe, 在parentProcess中会wait stage0_pid/stage1_pid, 并将真实的pid设置为stage2_pid // 3. SYNC_TIMEOFFSETS_PLS 设置容器时间相对物理机的偏移量，这是一种time namepsace // 4. SYNC_CHILD_FINISH：stage1_complete=true } syncfd = sync_grandchild_pipe[1]; close(sync_grandchild_pipe[0]) stage2_complete = false; while (!stage2_complete) { // 向 stage-2 发送信息 s = SYNC_GRANDCHILD; write(syncfd, \u0026amp;s, sizeof(s)) read(syncfd, \u0026amp;s, sizeof(s)) if (s != SYNC_CHILD_FINISH){failed} } // stage-0 进程退出 exit(0); } case STAGE_CHILD:{ // 当前在stage-1进程 syncfd = sync_child_pipe[0]; close(sync_child_pipe[1]) join_namespaces(config.namespaces) if (config.cloneflags \u0026amp; CLONE_NEWUSER) { try_unshare(CLONE_NEWUSER, \u0026quot;user namespace\u0026quot;); // 如果是rootless模式，用unshare将当前进程移入 user namespace （如果是让子进程进入user namespace，把CLONE_NEWUSER传给clone就行） // ... // 请求stage-0 进行 user mapping， 因为stage-1 进程没权限（具体为啥没权限不清楚，看源码注释是和CLONE_PARENT有关） s = SYNC_USERMAP_PLS; write(syncfd, \u0026amp;s, sizeof(s)) read(syncfd, \u0026amp;s, sizeof(s)) if (s != SYNC_USERMAP_ACK){failed} // ... setresuid(0, 0, 0) // 将当前进程作为ns里的root，也就是uid=0 } try_unshare(config.cloneflags, \u0026quot;remaining namespaces\u0026quot;); // 注释里有提到，某些内核的clone对一些参数的联合使用有点问题，所以在这里unshare。 // 当unshare CLONE_PID 时，当前进程的pid仍在原pid ns，其子进程在新的pid namespace, pid = 1 // ... // 子进程直接跳到 STAGE_INIT 执行 stage2_pid = clone(()=\u0026gt;{longjmp(env, STAGE_INIT)}, ca.stack_ptr, CLONE_PARENT | SIGCHLD, \u0026amp;ca); s = SYNC_RECVPID_PLS write(syncfd, \u0026amp;s, sizeof(s)) write(syncfd, \u0026amp;stage2_pid, sizeof(stage2_pid)) read(syncfd, \u0026amp;s, sizeof(s)) if (s != SYNC_RECVPID_ACK){failed} s = SYNC_CHILD_FINISH; write(syncfd, \u0026amp;s, sizeof(s)) // stage-1 进程退出 exit(0); } case STAGE_INIT:{ syncfd = sync_grandchild_pipe[0]; close(sync_grandchild_pipe[1]) close(sync_child_pipe[0]) read(syncfd, \u0026amp;s, sizeof(s)) if (s != SYNC_GRANDCHILD){failed} setsid() setuid(0) setgid(0) s = SYNC_CHILD_FINISH; write(syncfd, \u0026amp;s, sizeof(s)) close(sync_grandchild_pipe[0]) return; } } FS mount 这里讲一下文件或者rootfs是怎么挂载的\n首先，runc bundle要求我们已经准备好了一个rootfs，其次，我们进入一个全新的mount namespace。\nrootfs 对rootfs的mount可以通过chroot或者pivotroot 如果没有指定 new mount namespace, 那就直接chroot: unix.Chroot(\u0026quot;.\u0026quot;); unix.Chdir(\u0026quot;/\u0026quot;); (这里后面再调用一次chdir，避免rootfs切换后路径没对齐) 一般来说，都指定了new mount namespace，这时使用 unix.PivotRoot(\u0026quot;.\u0026quot;, \u0026ldquo;.\u0026quot;)，中间有一些复杂的内核层面的trick，看了一些issue也没太看懂，这里不赘述了。 bind mount 对于常见的文件/目录挂载，都是通过mount -o bind.\n首先在目标挂载目录创建一个挂载点：\ndestDir, destBase := filepath.Split(dest) destDirFd, err := utils.MkdirAllInRootOpen(rootfs, destDir, 0o755) unix.Mknodat(int(destDirFd.Fd()), destBase, unix.S_IFREG|0o644, 0) 随后将对应文件或目录的fd对应的文件（形如 /proc/self/fd/111） 挂在目标的fd（形如 /proc/self/fd/112）上： unix.Mount(src, dst, fstype, flags, data)\nConsole IO tty是怎么创建的，以及怎么生效的，即怎么把某个进程的stdio关联到终端的stdio？\n如果我们直接在前台调用某个进程，倒是不用担心tty的问题，都会自动继承tty的io，但如果是dockerd/containerd 这种daemon场景呢？\nmount 通过打开 f = os.OpenFile(\u0026quot;/dev/ptmx\u0026quot;, unix.O_RDWR|unix.O_NOCTTY|unix.O_CLOEXEC, 0) 文件，就会拿到一个tty的fd，通过 unix.Syscall(unix.SYS_IOCTL, f.Fd(), \u0026amp;u, ...) 系统调用，拿到对应的创建出来的tty的文件地址fmt.Sprintf(\u0026quot;/dev/pts/%d\u0026quot;, u)， 随后，将tty的文件地址mount到 /dev/console, 随后打开slavepath，将对应的fd dup到 0、1、2 上，这意味着对0/1/2的重定向\n在这里，存在console的master和slave，master就是打开 /dev/ptmx 得到的fd， slave就是 unix.Syscall(unix.SYS_IOCTL 得到的 fd\n​Master → Slave：控制端（如用户键盘输入）发送数据到被控进程。 ​Slave → Master：被控进程的输出（如命令结果）返回给控制端。 Master/Slave 之间的数据拷贝是内核自动完成的，基本上来说，只要某个被控进程的stdio被重定向到slave，就正常关联到console的stdio了。我们操作的目的的本质就是怎么把某个进程的stdio关联到终端的stdio。\n在 new mount namespace 里面执行 // setupConsole sets up the console from inside the container, and sends the // master pty fd to the config.Pipe (using cmsg). This is done to ensure that // consoles are scoped to a container properly (see runc#814 and the many // issues related to that). This has to be run *after* we've pivoted to the new // rootfs (and the users' configuration is entirely set up). func setupConsole(socket *os.File, config *initConfig, mount bool) error { defer socket.Close() // At this point, /dev/ptmx points to something that we would expect. We // used to change the owner of the slave path, but since the /dev/pts mount // can have gid=X set (at the users' option). So touching the owner of the // slave PTY is not necessary, as the kernel will handle that for us. Note // however, that setupUser (specifically fixStdioPermissions) *will* change // the UID owner of the console to be the user the process will run as (so // they can actually control their console). pty, slavePath, err := console.NewPty() if err != nil { return err } // After we return from here, we don't need the console anymore. defer pty.Close() if config.ConsoleHeight != 0 \u0026amp;\u0026amp; config.ConsoleWidth != 0 { err = pty.Resize(console.WinSize{ Height: config.ConsoleHeight, Width: config.ConsoleWidth, }) if err != nil { return err } } // Mount the console inside our rootfs. if mount { if err := mountConsole(slavePath); err != nil { return err } } // While we can access console.master, using the API is a good idea. if err := utils.SendRawFd(socket, pty.Name(), pty.Fd()); err != nil { return err } runtime.KeepAlive(pty) // Now, dup over all the things. return dupStdio(slavePath) } // NewPty creates a new pty pair // The master is returned as the first console and a string // with the path to the pty slave is returned as the second func NewPty() (Console, string, error) { f, err := openpt() if err != nil { return nil, \u0026quot;\u0026quot;, err } slave, err := ptsname(f) if err != nil { return nil, \u0026quot;\u0026quot;, err } if err := unlockpt(f); err != nil { return nil, \u0026quot;\u0026quot;, err } m, err := newMaster(f) if err != nil { return nil, \u0026quot;\u0026quot;, err } return m, slave, nil } // openpt allocates a new pseudo-terminal by opening the /dev/ptmx device func openpt() (*os.File, error) { return os.OpenFile(\u0026quot;/dev/ptmx\u0026quot;, unix.O_RDWR|unix.O_NOCTTY|unix.O_CLOEXEC, 0) } // dupStdio opens the slavePath for the console and dups the fds to the current // processes stdio, fd 0,1,2. func dupStdio(slavePath string) error { fd, err := unix.Open(slavePath, unix.O_RDWR, 0) if err != nil { return \u0026amp;os.PathError{ Op: \u0026quot;open\u0026quot;, Path: slavePath, Err: err, } } for _, i := range []int{0, 1, 2} { if err := unix.Dup3(fd, i, 0); err != nil { return err } } return nil } // mount initializes the console inside the rootfs mounting with the specified mount label // and applying the correct ownership of the console. func mountConsole(slavePath string) error { f, err := os.Create(\u0026quot;/dev/console\u0026quot;) if err != nil \u0026amp;\u0026amp; !os.IsExist(err) { return err } if f != nil { // Ensure permission bits (can be different because of umask). if err := f.Chmod(0o666); err != nil { return err } f.Close() } return mount(slavePath, \u0026quot;/dev/console\u0026quot;, \u0026quot;bind\u0026quot;, unix.MS_BIND, \u0026quot;\u0026quot;) } ","id":12,"section":"posts","summary":"\u003cp\u003egit clone \u003ca href=\"https://github.com/opencontainers/runc.git\"\u003ehttps://github.com/opencontainers/runc.git\u003c/a\u003e, 我们简单阅读下，代码不多\u003c/p\u003e\n\u003ch1 id=\"入口\"\u003e入口\u003c/h1\u003e\n\u003cp\u003e入口没啥好说的，先找main.go文件，可以看到runc这个库用了 github.com/urfave/cli 这个命令行库和 github.com/sirupsen/logrus 这个日志库，能在这种比较重要的工具里面使用，说明这两个库是很不错的。\u003c/p\u003e","tags":["container","oci","runc"],"title":"[container] 6.容器基础之runc源码","uri":"https://wymli.github.io/2025/03/container-6.%E5%AE%B9%E5%99%A8%E5%9F%BA%E7%A1%80%E4%B9%8Brunc%E6%BA%90%E7%A0%81/","year":"2025"},{"content":"oci distribution spec 比较简单，就是定义了一些用于pull/push 的api\n一个有趣的事实是，oci registry 不只是存储镜像，也可以用于存储helm chart。\nPull Pull manifest GET /v2//manifests/ name: 一般是${namespace/image_name}, 比如 library/nginx reference：一般是digest或者tag，比如latest、v1.2.3、sha256:abc123\u0026hellip; 拉取下来的是符合oci image spec的manifest文件 Pull blobs GET /v2//blobs/ Push 值得注意的是，在push image时，是先push blobs，再push manifest，与pull相反\nPush blobs 单次Post 直接往 /v2//blobs/uploads/?digest= 进行Post，body就是blob二进制内容 先Post再Put Post /v2//blobs/uploads/ 拿到 upload url(upload url将被放在rsp header里的Location字段) 这里的location url往往是专用存储的地址，比如s3 随后上传二进制到 ?digest= 分块上传 不再赘述，和http chunk机制有关 digest: 值得注意的是: A config file references the uncompressed layer contents by sha256. A manifest references the compressed layer contents by sha256 and the size of the layer. A manifest references the config file contents by sha256 and the size of the file. 这有一张图，很清晰 https://github.com/google/go-containerregistry/tree/d7f8d06c87ed209507dd5f2d723267fe35b38a9f/pkg/v1/remote#anatomy-of-an-image-upload 所以，从registry直接拉下来的manifest里的内容，会和docker save导出的manifest的内容会有差异，体现在blobs/layer的tar包是否有gzip过 Push manifest PUT /v2//manifests/ ","id":13,"section":"posts","summary":"\u003cp\u003eoci distribution spec 比较简单，就是定义了一些用于pull/push 的api\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e一个有趣的事实是，oci registry 不只是存储镜像，也可以用于存储helm chart。\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch1 id=\"pull\"\u003ePull\u003c/h1\u003e\n\u003ch2 id=\"pull-manifest\"\u003ePull manifest\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eGET /v2/\u003cname\u003e/manifests/\u003creference\u003e\n\u003col\u003e\n\u003cli\u003ename: 一般是${namespace/image_name}, 比如 library/nginx\u003c/li\u003e\n\u003cli\u003ereference：一般是digest或者tag，比如latest、v1.2.3、sha256:abc123\u0026hellip;\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e拉取下来的是符合oci image spec的manifest文件\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"pull-blobs\"\u003ePull blobs\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eGET /v2/\u003cname\u003e/blobs/\u003cdigest\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch1 id=\"push\"\u003ePush\u003c/h1\u003e\n\u003cp\u003e值得注意的是，在push image时，是先push blobs，再push manifest，与pull相反\u003c/p\u003e","tags":["container","oci"],"title":"[container] 5.容器基础之oci dist","uri":"https://wymli.github.io/2025/03/container-5.%E5%AE%B9%E5%99%A8%E5%9F%BA%E7%A1%80%E4%B9%8Boci-dist/","year":"2025"},{"content":"描述了一个镜像的打包目录和相关文件的schema\n目录结构 利用docker save拿到一个docke 镜像的tar包，解包后得到如下目录，这是一个兼容oci image spec的目录（但也只是兼容，不是严格相等，里面有一些oci image spec里未定义的文件）\n. ├── blobs // Contains content-addressable blobs, 以文件的hash值作为文件名，内容可能是json或者是tar包等，是oci image的data层 │ └── sha256 │ ├── 01c9a2a5f23727d0aab91da9d479286e25780d50b574f1a9df47ca850a88b591 │ ├── 20a9b386e10e3498e69df416a8399580266c8a1a5e9b61499dad040b6adf389d │ ├── 36d17f72f4f3630dbc93a0b2fe6f7e61179c597cbef32f815b34f70ef1e402f2 │ ├── 4571159699acacba5c116a51948bf915c1ddd4e948835281959a4057d9585ea5 │ ├── 462728c2d5e8545bccb55245c5b1894e2b38f433e7c626b9decfa0d8c450c7f0 │ ├── 4b017a36fd9c6bc8b31d2435fd4542fadb6ff333f58089e13fdae0c9c32521ba │ ├── 6a2f4c46fde663a8ba77d90d5c03cce66bb73ab86420ef4d7601dd4efbc8e8df │ ├── 75c81d4302970814333f1d90f05991d1d41e3eb6ff685022f8daaf7d3b8d9b55 │ ├── 93bc0edf8c04050dd64e3167e6f61e947f95eba2015fc2a52681edc949f32494 │ ├── b200d32a35f55dcf1abbe58c3853d03ad3ae426768930e15c862e778831acd82 │ ├── c11894706a24d6c86caa0ed1dcd3c12ba4ea829b92f90e4d3693e803f1fdc696 │ ├── c3d5e3eb8c7ece0139d56c6e321f2d4f42ced54469d8b77439b1221c61a05e51 │ ├── c7833e0541d97c713cc25f793288fe745fbadb35e28662f095898772796d02b3 │ ├── f8217d7865d28a53786a3f9ccb3760a59500fba32d367b1fe99470f974a6a669 │ ├── f911087b1237b68bf2fde6931af826d83fbcad04b37c6df2eee0fc1560e7f655 │ ├── fb8d481c6b59d23edcf9529bfd9683a62245ec7adb22fb6307e04d0293eab4e0 | ├── index.json // 索引，是oci image的入口，里面定义了manifest.json的hash值（随后可以在blobs里找到），是oci image的meta层 ├── manifest.json // docker的manifest.json, 不是oci image 规范，其内容和blobs/manifest.json 有区别 ├── oci-layout // 内容是镜像布局版本 └── repositories // docker 特有 blobs blobs里主要有三类文件：\nmanifest.json 里面定义每一层的digest + config.json 的digest （由于contenet-addressable, digest就是文件名） config.json 里面定义了一些元数据，比如镜像的env、cmd、构建历史（docker history 命令）等 构建 oci runtime spec时，config.json 会基于这个config进行渲染 layer tarball 每一层的文件tar打包，unpack后就是该层新增的一些文件(注意出于效率考虑，并没有压缩) manifest.json 一个典型的manifest.json如下，里面包含了config文件和layers文件列表，简单来说，config文件用于形成runtime的config.json，layers的tar包列表用于形成runtime的rootfs。\n{ \u0026quot;schemaVersion\u0026quot;: 2, \u0026quot;mediaType\u0026quot;: \u0026quot;application/vnd.oci.image.manifest.v1+json\u0026quot;, \u0026quot;config\u0026quot;: { \u0026quot;mediaType\u0026quot;: \u0026quot;application/vnd.oci.image.config.v1+json\u0026quot;, \u0026quot;digest\u0026quot;: \u0026quot;sha256:36d17f72f4f3630dbc93a0b2fe6f7e61179c597cbef32f815b34f70ef1e402f2\u0026quot;, \u0026quot;size\u0026quot;: 6256 }, \u0026quot;layers\u0026quot;: [ { \u0026quot;mediaType\u0026quot;: \u0026quot;application/vnd.oci.image.layer.v1.tar\u0026quot;, \u0026quot;digest\u0026quot;: \u0026quot;sha256:01c9a2a5f23727d0aab91da9d479286e25780d50b574f1a9df47ca850a88b591\u0026quot;, \u0026quot;size\u0026quot;: 121313280 }, { \u0026quot;mediaType\u0026quot;: \u0026quot;application/vnd.oci.image.layer.v1.tar\u0026quot;, \u0026quot;digest\u0026quot;: \u0026quot;sha256:f8217d7865d28a53786a3f9ccb3760a59500fba32d367b1fe99470f974a6a669\u0026quot;, \u0026quot;size\u0026quot;: 49581056 }, { \u0026quot;mediaType\u0026quot;: \u0026quot;application/vnd.oci.image.layer.v1.tar\u0026quot;, \u0026quot;digest\u0026quot;: \u0026quot;sha256:20a9b386e10e3498e69df416a8399580266c8a1a5e9b61499dad040b6adf389d\u0026quot;, \u0026quot;size\u0026quot;: 181902848 }, { \u0026quot;mediaType\u0026quot;: \u0026quot;application/vnd.oci.image.layer.v1.tar\u0026quot;, \u0026quot;digest\u0026quot;: \u0026quot;sha256:4b017a36fd9c6bc8b31d2435fd4542fadb6ff333f58089e13fdae0c9c32521ba\u0026quot;, \u0026quot;size\u0026quot;: 597108736 }, { \u0026quot;mediaType\u0026quot;: \u0026quot;application/vnd.oci.image.layer.v1.tar\u0026quot;, \u0026quot;digest\u0026quot;: \u0026quot;sha256:462728c2d5e8545bccb55245c5b1894e2b38f433e7c626b9decfa0d8c450c7f0\u0026quot;, \u0026quot;size\u0026quot;: 18359296 }, { \u0026quot;mediaType\u0026quot;: \u0026quot;application/vnd.oci.image.layer.v1.tar\u0026quot;, \u0026quot;digest\u0026quot;: \u0026quot;sha256:93bc0edf8c04050dd64e3167e6f61e947f95eba2015fc2a52681edc949f32494\u0026quot;, \u0026quot;size\u0026quot;: 72050688 }, { \u0026quot;mediaType\u0026quot;: \u0026quot;application/vnd.oci.image.layer.v1.tar\u0026quot;, \u0026quot;digest\u0026quot;: \u0026quot;sha256:fb8d481c6b59d23edcf9529bfd9683a62245ec7adb22fb6307e04d0293eab4e0\u0026quot;, \u0026quot;size\u0026quot;: 5120 } ] } config.json 一个典型的config.json 如下。\n值得注意的是里面的diff_ids, 里面记录了每一层tar包的哈希值(只是比较奇怪，为什么叫diff_id)\n{ \u0026quot;architecture\u0026quot;: \u0026quot;amd64\u0026quot;, \u0026quot;config\u0026quot;: { \u0026quot;Env\u0026quot;: [ \u0026quot;PATH=/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\u0026quot;, \u0026quot;GPG_KEY=7169605F62C751356D054A26A821E680E5FA6305\u0026quot;, \u0026quot;PYTHON_VERSION=3.13.2\u0026quot;, \u0026quot;PYTHON_SHA256=d984bcc57cd67caab26f7def42e523b1c015bbc5dc07836cf4f0b63fa159eb56\u0026quot; ], \u0026quot;Cmd\u0026quot;: [ \u0026quot;python3\u0026quot; ] }, \u0026quot;created\u0026quot;: \u0026quot;2025-02-04T23:51:20Z\u0026quot;, \u0026quot;history\u0026quot;: [ { \u0026quot;created\u0026quot;: \u0026quot;2023-05-10T23:29:59Z\u0026quot;, \u0026quot;created_by\u0026quot;: \u0026quot;# debian.sh --arch 'amd64' out/ 'bookworm' '@1740355200'\u0026quot;, \u0026quot;comment\u0026quot;: \u0026quot;debuerreotype 0.15\u0026quot; }, { \u0026quot;created\u0026quot;: \u0026quot;2023-05-10T23:29:59Z\u0026quot;, \u0026quot;created_by\u0026quot;: \u0026quot;RUN /bin/sh -c set -eux; \\tapt-get update; \\tapt-get install -y --no-install-recommends \\t\\tca-certificates \\t\\tcurl \\t\\tgnupg \\t\\tnetbase \\t\\tsq \\t\\twget \\t; \\trm -rf /var/lib/apt/lists/* # buildkit\u0026quot;, \u0026quot;comment\u0026quot;: \u0026quot;buildkit.dockerfile.v0\u0026quot; }, { \u0026quot;created\u0026quot;: \u0026quot;2024-01-09T01:14:25Z\u0026quot;, \u0026quot;created_by\u0026quot;: \u0026quot;RUN /bin/sh -c set -eux; \\tapt-get update; \\tapt-get install -y --no-install-recommends \\t\\tgit \\t\\tmercurial \\t\\topenssh-client \\t\\tsubversion \\t\\t\\t\\tprocps \\t; \\trm -rf /var/lib/apt/lists/* # buildkit\u0026quot;, \u0026quot;comment\u0026quot;: \u0026quot;buildkit.dockerfile.v0\u0026quot; }, { \u0026quot;created\u0026quot;: \u0026quot;2024-01-09T01:14:25Z\u0026quot;, \u0026quot;created_by\u0026quot;: \u0026quot;RUN /bin/sh -c set -ex; \\tapt-get update; \\tapt-get install -y --no-install-recommends \\t\\tautoconf \\t\\tautomake \\t\\tbzip2 \\t\\tdefault-libmysqlclient-dev \\t\\tdpkg-dev \\t\\tfile \\t\\tg++ \\t\\tgcc \\t\\timagemagick \\t\\tlibbz2-dev \\t\\tlibc6-dev \\t\\tlibcurl4-openssl-dev \\t\\tlibdb-dev \\t\\tlibevent-dev \\t\\tlibffi-dev \\t\\tlibgdbm-dev \\t\\tlibglib2.0-dev \\t\\tlibgmp-dev \\t\\tlibjpeg-dev \\t\\tlibkrb5-dev \\t\\tliblzma-dev \\t\\tlibmagickcore-dev \\t\\tlibmagickwand-dev \\t\\tlibmaxminddb-dev \\t\\tlibncurses5-dev \\t\\tlibncursesw5-dev \\t\\tlibpng-dev \\t\\tlibpq-dev \\t\\tlibreadline-dev \\t\\tlibsqlite3-dev \\t\\tlibssl-dev \\t\\tlibtool \\t\\tlibwebp-dev \\t\\tlibxml2-dev \\t\\tlibxslt-dev \\t\\tlibyaml-dev \\t\\tmake \\t\\tpatch \\t\\tunzip \\t\\txz-utils \\t\\tzlib1g-dev \\t; \\trm -rf /var/lib/apt/lists/* # buildkit\u0026quot;, \u0026quot;comment\u0026quot;: \u0026quot;buildkit.dockerfile.v0\u0026quot; }, { \u0026quot;created\u0026quot;: \u0026quot;2025-02-04T23:51:20Z\u0026quot;, \u0026quot;created_by\u0026quot;: \u0026quot;ENV PATH=/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\u0026quot;, \u0026quot;comment\u0026quot;: \u0026quot;buildkit.dockerfile.v0\u0026quot;, \u0026quot;empty_layer\u0026quot;: true }, { \u0026quot;created\u0026quot;: \u0026quot;2025-02-04T23:51:20Z\u0026quot;, \u0026quot;created_by\u0026quot;: \u0026quot;RUN /bin/sh -c set -eux; \\tapt-get update; \\tapt-get install -y --no-install-recommends \\t\\tlibbluetooth-dev \\t\\ttk-dev \\t\\tuuid-dev \\t; \\trm -rf /var/lib/apt/lists/* # buildkit\u0026quot;, \u0026quot;comment\u0026quot;: \u0026quot;buildkit.dockerfile.v0\u0026quot; }, { \u0026quot;created\u0026quot;: \u0026quot;2025-02-04T23:51:20Z\u0026quot;, \u0026quot;created_by\u0026quot;: \u0026quot;ENV GPG_KEY=7169605F62C751356D054A26A821E680E5FA6305\u0026quot;, \u0026quot;comment\u0026quot;: \u0026quot;buildkit.dockerfile.v0\u0026quot;, \u0026quot;empty_layer\u0026quot;: true }, { \u0026quot;created\u0026quot;: \u0026quot;2025-02-04T23:51:20Z\u0026quot;, \u0026quot;created_by\u0026quot;: \u0026quot;ENV PYTHON_VERSION=3.13.2\u0026quot;, \u0026quot;comment\u0026quot;: \u0026quot;buildkit.dockerfile.v0\u0026quot;, \u0026quot;empty_layer\u0026quot;: true }, { \u0026quot;created\u0026quot;: \u0026quot;2025-02-04T23:51:20Z\u0026quot;, \u0026quot;created_by\u0026quot;: \u0026quot;ENV PYTHON_SHA256=d984bcc57cd67caab26f7def42e523b1c015bbc5dc07836cf4f0b63fa159eb56\u0026quot;, \u0026quot;comment\u0026quot;: \u0026quot;buildkit.dockerfile.v0\u0026quot;, \u0026quot;empty_layer\u0026quot;: true }, { \u0026quot;created\u0026quot;: \u0026quot;2025-02-04T23:51:20Z\u0026quot;, \u0026quot;created_by\u0026quot;: \u0026quot;RUN /bin/sh -c set -eux; \\t\\twget -O python.tar.xz \\\u0026quot;https://www.python.org/ftp/python/${PYTHON_VERSION%%[a-z]*}/Python-$PYTHON_VERSION.tar.xz\\\u0026quot;; \\techo \\\u0026quot;$PYTHON_SHA256 *python.tar.xz\\\u0026quot; | sha256sum -c -; \\twget -O python.tar.xz.asc \\\u0026quot;https://www.python.org/ftp/python/${PYTHON_VERSION%%[a-z]*}/Python-$PYTHON_VERSION.tar.xz.asc\\\u0026quot;; \\tGNUPGHOME=\\\u0026quot;$(mktemp -d)\\\u0026quot;; export GNUPGHOME; \\tgpg --batch --keyserver hkps://keys.openpgp.org --recv-keys \\\u0026quot;$GPG_KEY\\\u0026quot;; \\tgpg --batch --verify python.tar.xz.asc python.tar.xz; \\tgpgconf --kill all; \\trm -rf \\\u0026quot;$GNUPGHOME\\\u0026quot; python.tar.xz.asc; \\tmkdir -p /usr/src/python; \\ttar --extract --directory /usr/src/python --strip-components=1 --file python.tar.xz; \\trm python.tar.xz; \\t\\tcd /usr/src/python; \\tgnuArch=\\\u0026quot;$(dpkg-architecture --query DEB_BUILD_GNU_TYPE)\\\u0026quot;; \\t./configure \\t\\t--build=\\\u0026quot;$gnuArch\\\u0026quot; \\t\\t--enable-loadable-sqlite-extensions \\t\\t--enable-optimizations \\t\\t--enable-option-checking=fatal \\t\\t--enable-shared \\t\\t--with-lto \\t\\t--with-ensurepip \\t; \\tnproc=\\\u0026quot;$(nproc)\\\u0026quot;; \\tEXTRA_CFLAGS=\\\u0026quot;$(dpkg-buildflags --get CFLAGS)\\\u0026quot;; \\tLDFLAGS=\\\u0026quot;$(dpkg-buildflags --get LDFLAGS)\\\u0026quot;; \\t\\tarch=\\\u0026quot;$(dpkg --print-architecture)\\\u0026quot;; arch=\\\u0026quot;${arch##*-}\\\u0026quot;; \\t\\tcase \\\u0026quot;$arch\\\u0026quot; in \\t\\t\\tamd64|arm64) \\t\\t\\t\\tEXTRA_CFLAGS=\\\u0026quot;${EXTRA_CFLAGS:-} -fno-omit-frame-pointer -mno-omit-leaf-frame-pointer\\\u0026quot;; \\t\\t\\t\\t;; \\t\\t\\ti386) \\t\\t\\t\\t;; \\t\\t\\t*) \\t\\t\\t\\tEXTRA_CFLAGS=\\\u0026quot;${EXTRA_CFLAGS:-} -fno-omit-frame-pointer\\\u0026quot;; \\t\\t\\t\\t;; \\t\\tesac; \\tmake -j \\\u0026quot;$nproc\\\u0026quot; \\t\\t\\\u0026quot;EXTRA_CFLAGS=${EXTRA_CFLAGS:-}\\\u0026quot; \\t\\t\\\u0026quot;LDFLAGS=${LDFLAGS:-}\\\u0026quot; \\t; \\trm python; \\tmake -j \\\u0026quot;$nproc\\\u0026quot; \\t\\t\\\u0026quot;EXTRA_CFLAGS=${EXTRA_CFLAGS:-}\\\u0026quot; \\t\\t\\\u0026quot;LDFLAGS=${LDFLAGS:--Wl},-rpath='\\\\$\\\\$ORIGIN/../lib'\\\u0026quot; \\t\\tpython \\t; \\tmake install; \\t\\tbin=\\\u0026quot;$(readlink -ve /usr/local/bin/python3)\\\u0026quot;; \\tdir=\\\u0026quot;$(dirname \\\u0026quot;$bin\\\u0026quot;)\\\u0026quot;; \\tmkdir -p \\\u0026quot;/usr/share/gdb/auto-load/$dir\\\u0026quot;; \\tcp -vL Tools/gdb/libpython.py \\\u0026quot;/usr/share/gdb/auto-load/$bin-gdb.py\\\u0026quot;; \\t\\tcd /; \\trm -rf /usr/src/python; \\t\\tfind /usr/local -depth \\t\\t\\\\( \\t\\t\\t\\\\( -type d -a \\\\( -name test -o -name tests -o -name idle_test \\\\) \\\\) \\t\\t\\t-o \\\\( -type f -a \\\\( -name '*.pyc' -o -name '*.pyo' -o -name 'libpython*.a' \\\\) \\\\) \\t\\t\\\\) -exec rm -rf '{}' + \\t; \\t\\tldconfig; \\t\\texport PYTHONDONTWRITEBYTECODE=1; \\tpython3 --version; \\tpip3 --version # buildkit\u0026quot;, \u0026quot;comment\u0026quot;: \u0026quot;buildkit.dockerfile.v0\u0026quot; }, { \u0026quot;created\u0026quot;: \u0026quot;2025-02-04T23:51:20Z\u0026quot;, \u0026quot;created_by\u0026quot;: \u0026quot;RUN /bin/sh -c set -eux; \\tfor src in idle3 pip3 pydoc3 python3 python3-config; do \\t\\tdst=\\\u0026quot;$(echo \\\u0026quot;$src\\\u0026quot; | tr -d 3)\\\u0026quot;; \\t\\t[ -s \\\u0026quot;/usr/local/bin/$src\\\u0026quot; ]; \\t\\t[ ! -e \\\u0026quot;/usr/local/bin/$dst\\\u0026quot; ]; \\t\\tln -svT \\\u0026quot;$src\\\u0026quot; \\\u0026quot;/usr/local/bin/$dst\\\u0026quot;; \\tdone # buildkit\u0026quot;, \u0026quot;comment\u0026quot;: \u0026quot;buildkit.dockerfile.v0\u0026quot; }, { \u0026quot;created\u0026quot;: \u0026quot;2025-02-04T23:51:20Z\u0026quot;, \u0026quot;created_by\u0026quot;: \u0026quot;CMD [\\\u0026quot;python3\\\u0026quot;]\u0026quot;, \u0026quot;comment\u0026quot;: \u0026quot;buildkit.dockerfile.v0\u0026quot;, \u0026quot;empty_layer\u0026quot;: true } ], \u0026quot;os\u0026quot;: \u0026quot;linux\u0026quot;, \u0026quot;rootfs\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;layers\u0026quot;, \u0026quot;diff_ids\u0026quot;: [ \u0026quot;sha256:01c9a2a5f23727d0aab91da9d479286e25780d50b574f1a9df47ca850a88b591\u0026quot;, \u0026quot;sha256:f8217d7865d28a53786a3f9ccb3760a59500fba32d367b1fe99470f974a6a669\u0026quot;, \u0026quot;sha256:20a9b386e10e3498e69df416a8399580266c8a1a5e9b61499dad040b6adf389d\u0026quot;, \u0026quot;sha256:4b017a36fd9c6bc8b31d2435fd4542fadb6ff333f58089e13fdae0c9c32521ba\u0026quot;, \u0026quot;sha256:462728c2d5e8545bccb55245c5b1894e2b38f433e7c626b9decfa0d8c450c7f0\u0026quot;, \u0026quot;sha256:93bc0edf8c04050dd64e3167e6f61e947f95eba2015fc2a52681edc949f32494\u0026quot;, \u0026quot;sha256:fb8d481c6b59d23edcf9529bfd9683a62245ec7adb22fb6307e04d0293eab4e0\u0026quot; ] } } docker build dockerd在收到docker cli传过来的 build bundle后，是怎么一层一层构建镜像的呢？\n其实很简单，首先镜像是分层构建的，每一层构建完后，都打包层一个tar包\n那么，每一层对应的那一条命令，是如何构建出来tar包的呢？也很简单，在前面将overlayfs的时候，已经知道，我们有lowerdir和upperdir，所以在构建每一层时，其实就是以之前所有层构建好的镜像（你可以理解为是一个临时镜像，但它是完备的镜像，因为dockerfile即使没有下一行命令，它也是完备的dockerfile）启动一个临时容器，执行新层的命令，新产出的文件将会在upperdir，进而可以被打包成tar包，如此循环。\nimage bundle to runtime bundle 一个镜像bundle是如何转换成运行时bundle的呢？（这里的bundle就是一个文件目录树）\n对于rootfs，会按照manifest里定义的tar包列表按顺序解压。 这时候你会发现，有一些文件只在blobs里有，但manifest里没有，这些文件不会应用到runtime rootfs里，可能是一些注释文件啥的，比如Dockerfile里的COMMENT、MANINTAINER之类的。 容器运行时对image的处理 值得注意的是，oci image spec定义了一种标准的image存储格式，用于兼容不同的容器运行时，类似一种数据交换协议（比如json），但是在容器运行时内部，往往会用自己内部的方式存储image，比如对于containerd，所有的blobs存储在一个目录，所有的manifest存储在一个目录。\nOCI Image Spec 更像是一个 ​中间格式，用于在不同工具和平台之间传输和共享镜像。\n","id":14,"section":"posts","summary":"\u003cp\u003e描述了一个镜像的打包目录和相关文件的schema\u003c/p\u003e\n\u003ch1 id=\"目录结构\"\u003e目录结构\u003c/h1\u003e\n\u003cp\u003e利用docker save拿到一个docke 镜像的tar包，解包后得到如下目录，这是一个兼容oci image spec的目录（但也只是兼容，不是严格相等，里面有一些oci image spec里未定义的文件）\u003c/p\u003e","tags":["container","oci"],"title":"[container] 4.容器基础之oci image","uri":"https://wymli.github.io/2025/03/container-4.%E5%AE%B9%E5%99%A8%E5%9F%BA%E7%A1%80%E4%B9%8Boci-image/","year":"2025"},{"content":"如果没有安装runc，先安装 (如果你安装了dockerd/containerd，一般不用再单独安装)\nwget https://github.com/opencontainers/runc/releases/download/v1.2.5/runc.amd64 -O runc \u0026amp;\u0026amp; chmod +x runc 制作 bundle 安装oci runtime spec, 我们先制作oci runtime bundle，也就是config.json 和 rootfs\nrootfs 一般rootfs不是从零开始制作的，直接用现有的镜像\n可以直接使用ctr mount 指令将镜像mount到某个目录 可以使用 docker export 指令导出一个这在运行的容器的rootfs tar包 可以使用 docker save 指令导出一个镜像的oci tar包，然后逐个解压blobs目录下的每个layer的tar包 docker run -d python:3.13 sleep 1d docker export aaa4edf37e57 -o python-3.13.tar mkdir rootfs \u0026amp;\u0026amp; tar -xvf python-3.13.tar -C rootfs 如此，rootfs已经被准备好\n在这一步，也可以通过ctr mount 指令，直接mount镜像到某个目录，无需上面这么复杂\nconfig.json 生成默认的config.json (rootless container)\nrunc spec --rootless 啥也不用改，直接run，就能以当前目录下的config.json + rootfs 启动一个名为test的容器\nrunc run test 修改overlayfs 我们希望能在原有的python镜像的基础上，hack进一些ssh的相关工具\nmv rootfs lowerdir mkdir rootfs sudo mount -t overlay test -o lowerdir=lowerdir,upperdir=uppe rdir,workdir=workdir rootfs 注意修改一下config.json里的rootfs.readonly, 改为false 随后可以直接用runc直接启动, 在根目录创建一个文件试试\nrunc run test # echo \u0026quot;hello world\u0026quot; \u0026gt; /test 退出容器后可以看到，lowerdir无变更，upperdir有变更\n基于此，在一些需要持久化存储的场景，可以把容器的upperdir放在ebs上\n添加sshd https://github.com/opencontainers/runc/issues/2517#issuecomment-720897616\n在容器里安装 openssh-server 即可，安装的内容将在upperdir中 ","id":15,"section":"posts","summary":"\u003cp\u003e如果没有安装runc，先安装 (如果你安装了dockerd/containerd，一般不用再单独安装)\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ewget https://github.com/opencontainers/runc/releases/download/v1.2.5/runc.amd64 -O runc \u0026amp;\u0026amp; chmod +x runc\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1 id=\"制作-bundle\"\u003e制作 bundle\u003c/h1\u003e\n\u003cp\u003e安装oci runtime spec, 我们先制作oci runtime bundle，也就是config.json 和 rootfs\u003c/p\u003e","tags":["container","oci","runc"],"title":"[container] 3.容器基础之runc","uri":"https://wymli.github.io/2025/03/container-3.%E5%AE%B9%E5%99%A8%E5%9F%BA%E7%A1%80%E4%B9%8Brunc/","year":"2025"},{"content":"WIP\n","id":16,"section":"posts","summary":"\u003cp\u003eWIP\u003c/p\u003e","tags":["http","event-stream"],"title":"[http] 流式响应之text/event-stream","uri":"https://wymli.github.io/2025/03/http-%E6%B5%81%E5%BC%8F%E5%93%8D%E5%BA%94%E4%B9%8Btext.event-stream/","year":"2025"},{"content":"overlayfs ，如其名，覆盖文件系统，类似那些 overlay network一样（在underlay network上包一层），在原生的fs上包一层。\noverlayfs 是linux内核提供的功能，相关文档见 https://docs.kernel.org/filesystems/overlayfs.html\n容器使用 overlayfs 作为容器的文件系统，比如镜像是按层构建的，每一层都是lowerdir, 并创建一个容器的upperdir, 最终得到用户看到的容器文件系统。\n使用 学习一个东西的方法，先看怎么使用，跑个demo出来，才不会言之无物。\n查看内核是否支持overlayfs\n(base) liweiming@DESKTOP-4IDR6UQ:~/code/wymli.github.io$ grep overlay /proc/filesystems nodev overlay 这里的 nodev （no device）表示 overlayfs是一个虚拟文件系统，无需基于物理的块设备(比如硬盘)\n跑一下 mount 指令\nmkdir -p {lower,upper,work,merged} mount -t overlay overlay_lwm -o lowerdir=lower,upperdir=upper,workdir=work merged 指令也比较好懂， mount -t ${fs_type} ${fs_name} -o ... ${dest} , -o 后面的是overlayfs相关的options\noverlayfs 的设计上，有四个文件夹，各自含义如下：\nlower: 只读的下层文件夹 upper: 可写的上层文件夹 work: 可以理解为tmp目录，用以完成overlay内部的一些操作，主要是为了操作的原子性， 防止操作在一半时突然断电，影响overlayfs的完整性。具体例子可以看后面COW。 merged: 最终视图文件夹，提供给使用方 道理很好懂，merged文件夹时lower+upper的merge视图，包含两边的所有文件，其中lower层只读，以便于在多个容器中复用，upper层就是每个容器专有。\n自己随便创建几个文件可以看到，在lowerdir 、upperdir创建的文件都会出现merged dir，在mergeddir删除的文件，会影响upperdir, 但不会影响lowerdir\n特性 读文件：读到的是lowerdir + upperdir 的合并视图 写文件：当写只读层的lowerdir里的文件时, 会先copy文件到upperdir, 也就是有一步的COW(copy-on-write)，实际上会先copy到workdir, 然后rename到upperdir，可以认为copy是非原子的，但是rename是原子的，用workdir来完成原子操作 删文件: 当删只读层的lowerdir里的文件时，会在upperdir创建一个root用户下的同名空文件（这一步，网上的文档(比如大模型)一般是说会创建 .wh.${name} 文件，用以标识文件删除） 不过官方文档还是比较清楚的:A whiteout is created as a character device with 0/0 device number or as a zero-size regular file with the xattr \u0026quot;trusted.overlay.whiteout\u0026quot;.\n这里我在mergedir删除lowerdir的文件后，可以在upperdir看到如下的新生成文件，对应 设备号为0(设备类型), 0(同一设备的某个具体实例)的字符设备文件\n这里a显示0, 0, 因为a是字符设备，所以显示设备号。x是regular file，对应的那栏显示文件大小 2 byte. c--------- 2 root root 0, 0 Mar 3 19:50 a -rw-r--r-- 1 liweiming liweiming 2 Mar 3 20:08 x 这里可以在回顾一下文件类型：\nd: 代表目录 c: 字符设备(比如终端 /dev/tty, 键盘鼠标啥的，按字节流访问) b: 块设备(比如硬盘，一次能访问一大块字节) -: 普通文件(regular file) ","id":17,"section":"posts","summary":"\u003cp\u003eoverlayfs ，如其名，覆盖文件系统，类似那些 overlay network一样（在underlay network上包一层），在原生的fs上包一层。\u003cbr\u003e\noverlayfs 是linux内核提供的功能，相关文档见 \u003ca href=\"https://docs.kernel.org/filesystems/overlayfs.html\"\u003ehttps://docs.kernel.org/filesystems/overlayfs.html\u003c/a\u003e\u003cbr\u003e\n容器使用 overlayfs 作为容器的文件系统，比如镜像是按层构建的，每一层都是lowerdir, 并创建一个容器的upperdir, 最终得到用户看到的容器文件系统。\u003c/p\u003e","tags":["container","overlayfs"],"title":"[container] 1.容器基础之overlayfs","uri":"https://wymli.github.io/2025/03/container-1.%E5%AE%B9%E5%99%A8%E5%9F%BA%E7%A1%80%E4%B9%8Boverlayfs/","year":"2025"},{"content":"oci(open container initiative, 开放容器倡议) 主要有三个大的spec, runtime（容器运行时）、image（镜像）、distribution（分发）\nOCI Runtime Spec 包含三方面：配置和打包定义（也就是bundle和config.json的schema）、执行环境、容器生命周期及相关操作\n对于 oci runtime spec，有较多实现，比如各个语言的容器实现，比如runc、crun, 也有vm实现，比如kata\ncontainer bundle 容器打包 容器打包后，可以被运行时消费进而运行容器，所以这里定义了打包的规则：\nbundle 包含 1. config.json 2. rootfs bundle.tar 解压后直接就是 bundle files, 没有嵌套的一层根目录 执行runc spec, 将会生成如下的config.json\n{ \u0026quot;ociVersion\u0026quot;: \u0026quot;1.0.2-dev\u0026quot;, // schema版本，一个良好的设计，一定要一个版本字段，用来应对可能的schema不兼容改动 \u0026quot;process\u0026quot;: { // 容器主进程相关的配置 \u0026quot;terminal\u0026quot;: true, // 类似 docker run -t \u0026quot;user\u0026quot;: { \u0026quot;uid\u0026quot;: 0, \u0026quot;gid\u0026quot;: 0 }, \u0026quot;args\u0026quot;: [ \u0026quot;sh\u0026quot; ], \u0026quot;env\u0026quot;: [ \u0026quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\u0026quot;, \u0026quot;TERM=xterm\u0026quot; ], \u0026quot;cwd\u0026quot;: \u0026quot;/\u0026quot;, // working directory \u0026quot;capabilities\u0026quot;: { \u0026quot;bounding\u0026quot;: [ // 进程及子进程可以使用的全部能力 \u0026quot;CAP_AUDIT_WRITE\u0026quot;, \u0026quot;CAP_KILL\u0026quot;, \u0026quot;CAP_NET_BIND_SERVICE\u0026quot; ], \u0026quot;effective\u0026quot;: [ // 进程已经生效的实际能力 \u0026quot;CAP_AUDIT_WRITE\u0026quot;, \u0026quot;CAP_KILL\u0026quot;, \u0026quot;CAP_NET_BIND_SERVICE\u0026quot; ], \u0026quot;permitted\u0026quot;: [ // 进程可以使用的全部能力，进程主动激活后成为effective capabilities \u0026quot;CAP_AUDIT_WRITE\u0026quot;, \u0026quot;CAP_KILL\u0026quot;, \u0026quot;CAP_NET_BIND_SERVICE\u0026quot; ], \u0026quot;ambient\u0026quot;: [ // 子进程继承的能力 \u0026quot;CAP_AUDIT_WRITE\u0026quot;, \u0026quot;CAP_KILL\u0026quot;, \u0026quot;CAP_NET_BIND_SERVICE\u0026quot; ] }, \u0026quot;rlimits\u0026quot;: [ { \u0026quot;type\u0026quot;: \u0026quot;RLIMIT_NOFILE\u0026quot;, // 限制打开文件数 number of file \u0026quot;hard\u0026quot;: 1024, \u0026quot;soft\u0026quot;: 1024 } ], \u0026quot;noNewPrivileges\u0026quot;: true // 禁止容器进程新增权限 }, \u0026quot;root\u0026quot;: { \u0026quot;path\u0026quot;: \u0026quot;rootfs\u0026quot;, \u0026quot;readonly\u0026quot;: true }, \u0026quot;hostname\u0026quot;: \u0026quot;runc\u0026quot;, \u0026quot;mounts\u0026quot;: [ { \u0026quot;destination\u0026quot;: \u0026quot;/proc\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;proc\u0026quot;, \u0026quot;source\u0026quot;: \u0026quot;proc\u0026quot; }, { \u0026quot;destination\u0026quot;: \u0026quot;/dev\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;tmpfs\u0026quot;, \u0026quot;source\u0026quot;: \u0026quot;tmpfs\u0026quot;, \u0026quot;options\u0026quot;: [ \u0026quot;nosuid\u0026quot;, \u0026quot;strictatime\u0026quot;, \u0026quot;mode=755\u0026quot;, \u0026quot;size=65536k\u0026quot; ] }, { \u0026quot;destination\u0026quot;: \u0026quot;/dev/pts\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;devpts\u0026quot;, \u0026quot;source\u0026quot;: \u0026quot;devpts\u0026quot;, \u0026quot;options\u0026quot;: [ \u0026quot;nosuid\u0026quot;, \u0026quot;noexec\u0026quot;, \u0026quot;newinstance\u0026quot;, \u0026quot;ptmxmode=0666\u0026quot;, \u0026quot;mode=0620\u0026quot;, \u0026quot;gid=5\u0026quot; ] }, { \u0026quot;destination\u0026quot;: \u0026quot;/dev/shm\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;tmpfs\u0026quot;, \u0026quot;source\u0026quot;: \u0026quot;shm\u0026quot;, \u0026quot;options\u0026quot;: [ \u0026quot;nosuid\u0026quot;, \u0026quot;noexec\u0026quot;, \u0026quot;nodev\u0026quot;, \u0026quot;mode=1777\u0026quot;, \u0026quot;size=65536k\u0026quot; ] }, { \u0026quot;destination\u0026quot;: \u0026quot;/dev/mqueue\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;mqueue\u0026quot;, \u0026quot;source\u0026quot;: \u0026quot;mqueue\u0026quot;, \u0026quot;options\u0026quot;: [ \u0026quot;nosuid\u0026quot;, \u0026quot;noexec\u0026quot;, \u0026quot;nodev\u0026quot; ] }, { \u0026quot;destination\u0026quot;: \u0026quot;/sys\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;sysfs\u0026quot;, \u0026quot;source\u0026quot;: \u0026quot;sysfs\u0026quot;, \u0026quot;options\u0026quot;: [ \u0026quot;nosuid\u0026quot;, \u0026quot;noexec\u0026quot;, \u0026quot;nodev\u0026quot;, \u0026quot;ro\u0026quot; ] }, { \u0026quot;destination\u0026quot;: \u0026quot;/sys/fs/cgroup\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;cgroup\u0026quot;, \u0026quot;source\u0026quot;: \u0026quot;cgroup\u0026quot;, \u0026quot;options\u0026quot;: [ \u0026quot;nosuid\u0026quot;, \u0026quot;noexec\u0026quot;, \u0026quot;nodev\u0026quot;, \u0026quot;relatime\u0026quot;, \u0026quot;ro\u0026quot; ] } ], \u0026quot;linux\u0026quot;: { \u0026quot;resources\u0026quot;: { \u0026quot;devices\u0026quot;: [ { \u0026quot;allow\u0026quot;: false, \u0026quot;access\u0026quot;: \u0026quot;rwm\u0026quot; } ] }, \u0026quot;namespaces\u0026quot;: [ // 表示容器是否新建下面的namespace { \u0026quot;type\u0026quot;: \u0026quot;pid\u0026quot; }, { \u0026quot;type\u0026quot;: \u0026quot;network\u0026quot; }, { \u0026quot;type\u0026quot;: \u0026quot;ipc\u0026quot; }, { \u0026quot;type\u0026quot;: \u0026quot;uts\u0026quot; }, { \u0026quot;type\u0026quot;: \u0026quot;mount\u0026quot; } ], \u0026quot;maskedPaths\u0026quot;: [ \u0026quot;/proc/acpi\u0026quot;, \u0026quot;/proc/asound\u0026quot;, \u0026quot;/proc/kcore\u0026quot;, \u0026quot;/proc/keys\u0026quot;, \u0026quot;/proc/latency_stats\u0026quot;, \u0026quot;/proc/timer_list\u0026quot;, \u0026quot;/proc/timer_stats\u0026quot;, \u0026quot;/proc/sched_debug\u0026quot;, \u0026quot;/sys/firmware\u0026quot;, \u0026quot;/proc/scsi\u0026quot; ], \u0026quot;readonlyPaths\u0026quot;: [ \u0026quot;/proc/bus\u0026quot;, \u0026quot;/proc/fs\u0026quot;, \u0026quot;/proc/irq\u0026quot;, \u0026quot;/proc/sys\u0026quot;, \u0026quot;/proc/sysrq-trigger\u0026quot; ] } } ","id":18,"section":"posts","summary":"\u003cp\u003eoci(open container initiative, 开放容器倡议) 主要有三个大的spec, runtime（容器运行时）、image（镜像）、distribution（分发）\u003c/p\u003e\n\u003ch1 id=\"oci-runtime-spec\"\u003eOCI Runtime Spec\u003c/h1\u003e\n\u003cp\u003e包含三方面：配置和打包定义（也就是bundle和config.json的schema）、执行环境、容器生命周期及相关操作\u003c/p\u003e","tags":["container","oci"],"title":"[container] 2.容器基础之oci runtime","uri":"https://wymli.github.io/2025/03/container-2.%E5%AE%B9%E5%99%A8%E5%9F%BA%E7%A1%80%E4%B9%8Boci-runtime/","year":"2025"},{"content":"后面开始用家里的windows主机开发和学习，换了新环境，配置环境很折磨，wsl虽说很方便，但是遇到各种坑，解决起来很费脑\nwsl2 配置 2025年wsl已经有了很多新的演进，在网络方便进步很多，原来wsl1如果要连接宿主机的代理，需要配宿主机的ip，但是宿主机的ip不固定，比较麻烦（不过也就是一个脚本的事，问题也不大）\nwsl2支持镜像网络模式，wsl和host可以共用网络地址了，也就是wsl里可以通过localhost访问host。\n配置如下，在windows的用户目录下创建 .wslconfig\nPS C:\\Users\\liweiming\u0026gt; cat .\\.wslconfig [wsl2] networkingMode=mirrored dnsTunneling=true firewall=true autoProxy=true [experimental] # requires dnsTunneling but are also OPTIONAL bestEffortDnsParsing=true 然后重启 wsl\n然后在wsl配置代理即可（这一步卡了很久，网上的文档都没有这一步，可能是我电脑的原因，反正windows的代理没自动生效到wsl上）：\nexport http_proxy=\u0026quot;http://localhost:7890\u0026quot; export https_proxy=\u0026quot;http://localhost:7890\u0026quot; VSCode 与 wsl 在wsl中尝试用 code . 的方式打开vscode，结果报错 Command 'code' not found， 看了下$PATH, 好家伙，/mnt/c/Users/liweiming/AppData/Local/Programs/Microsoft:Code/bin， 反正也不知道是哪一步错了，windows路径里的空格在linux都变成了:，不过也好解决，自己加下$PATH就好\n配置如下:\nexport PATH=\u0026quot;/mnt/c/Users/liweiming/AppData/Local/Programs/Microsoft VS Code/bin\u0026quot;:$PATH rootless containerd 安装 下载最新的nerdctl\nwget https://github.com/containerd/nerdctl/releases/download/v2.0.3/nerdctl-2.0.3-linux-amd64.tar.gz bash /nerdctl/extras/rootless/containerd-rootless-setuptool.sh install 这一步一直报错 Failed to start containerd.service: Unit dbus.socket not found.\n卡了较久，最后在文档https://rootlesscontaine.rs/getting-started/common/login/，找到要安装 user模式的 dbus\nsystemctl --user is-active dbus sudo apt-get install -y dbus-user-session systemctl --user start dbus 随后再执行一遍 bash /nerdctl/extras/rootless/containerd-rootless-setuptool.sh install 即可\n验证下安装：\n(base) liweiming@DESKTOP-4IDR6UQ:~$ nerdctl run hello-world:latest docker.io/library/hello-world:latest: resolved |++++++++++++++++++++++++++++++++++++++| index-sha256:bfbb0cc14f13f9ed1ae86abc2b9f11181dc50d779807ed3a3c5e55a6936dbdd5: done |++++++++++++++++++++++++++++++++++++++| manifest-sha256:03b62250a3cb1abd125271d393fc08bf0cc713391eda6b57c02d1ef85efcc25c: done |++++++++++++++++++++++++++++++++++++++| config-sha256:74cc54e27dc41bb10dc4b2226072d469509f2f22f1a3ce74f4a59661a1d44602: done |++++++++++++++++++++++++++++++++++++++| layer-sha256:e6590344b1a5dc518829d6ea1524fc12f8bcd14ee9a02aa6ad8360cce3a9a9e9: done |++++++++++++++++++++++++++++++++++++++| elapsed: 7.2 s total: 13.4 K (1.9 KiB/s) Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \u0026quot;hello-world\u0026quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ ","id":19,"section":"posts","summary":"\u003cp\u003e后面开始用家里的windows主机开发和学习，换了新环境，配置环境很折磨，wsl虽说很方便，但是遇到各种坑，解决起来很费脑\u003c/p\u003e\n\u003ch1 id=\"wsl2-配置\"\u003ewsl2 配置\u003c/h1\u003e\n\u003cp\u003e2025年wsl已经有了很多新的演进，在网络方便进步很多，原来wsl1如果要连接宿主机的代理，需要配宿主机的ip，但是宿主机的ip不固定，比较麻烦（不过也就是一个脚本的事，问题也不大）\u003cbr\u003e\nwsl2支持镜像网络模式，wsl和host可以共用网络地址了，也就是wsl里可以通过localhost访问host。\u003cbr\u003e\n配置如下，在windows的用户目录下创建 \u003ccode\u003e.wslconfig\u003c/code\u003e\u003c/p\u003e","tags":["wsl","containerd"],"title":"[install] wsl 和 containerd 环境准备踩坑","uri":"https://wymli.github.io/2025/03/install-wsl-%E5%92%8C-containerd-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/","year":"2025"},{"content":"Intro 对大部分的业务系统来说，分布式往往体现在微服务上，即多个服务之间的分布式网络调用。\n但是在分布式计算、分布式训练等特定领域，是需要真正的借助分布式机器进行并行计算或训练的，这一类应用也有几个经典的架构，或者说启动方式。\n架构（启动方式） 无常驻服务节点管理进程 就像正常的非服务类应用一样，你要运行就直接启动它。在分布式领域，通常各个节点进程的角色是不同的，比如会区分master和slave（worker）。\n在设计上，一般通过传入命令行参数的形式区分是master还是worker，并在代码里针对不同的角色运行不同的代码。当然，如果逻辑复杂，也可以独立出来专门的master应用和worker应用。\n比如，tensorflow的分布式计算就是典型的这类架构，通常通过在不同的机器上启动同一份py脚本，给这个脚本传入所有分布式节点的地址和本机的角色。\n有专门的常驻服务节点管理进程 简单来说，就是在各个节点上运行node manager，管理这个机器。我们要提交训练或计算任务，就像专门的api server提交，api server转发给node manager。这里api server和node manager其实也是master/worker的关系。\n前面的自己启动进程是非常粗糙的，要每次手动在所有机器上启动，还要传入节点地址等信息，容易出错。引入节点管理进程后，我们只需要提交任务即可，不需要管理机器了。并且，这一类节点管理应用会帮忙调度，不再是像前面自己启动时写死机器节点了。\n比如，spark standalone就是这样的结构，想要运行spark分布式计算任务时，首先要搭建spark集群，spark standalone就是一类spark 集群，它通过首先在各个节点手动运行节点管理进程（master和worker），然后在任一机器上通过spark-submit.sh脚本提交spark任务，对应的被调度到的node manager就会启动相应的进程。\n有泛化的常驻服务节点管理进程 前面的spark standalone只适用于spark，如果每个这种分布式应用都搭建一个node manager也麻烦，于是yarn出现了。yarn是一种hadoop集群内的资源调度器，原生支持大数据生态的分布式应用，通过自定义编写app master应用，也可以支持用户自己的分布式应用。\n在yarn里面，同样的，也是先在各个节点机器上启动yarn的node manager（worker）和api server（master）。为了解决不同应用的调度问题，yarn使用一种名叫application master的概念，所谓的application master就是对应具体应用的管理者，完成对具体应用的调度工作，是用户自己编写的，可以认为就是一种用户编写的yarn客户端，相当于k8s里的operator。yarn原生集成了spark，flink等的app master。\n要了解更多的信息，去了解 yarn client。\n","id":20,"section":"posts","summary":"\u003ch1 id=\"intro\"\u003eIntro\u003c/h1\u003e\n\u003cp\u003e对大部分的业务系统来说，分布式往往体现在微服务上，即多个服务之间的分布式网络调用。\u003c/p\u003e\n\u003cp\u003e但是在分布式计算、分布式训练等特定领域，是需要真正的借助分布式机器进行并行计算或训练的，这一类应用也有几个经典的架构，或者说启动方式。\u003c/p\u003e","tags":["distribute"],"title":"[distribute] 单应用分布式架构","uri":"https://wymli.github.io/2022/04/distribute-%E5%8D%95%E5%BA%94%E7%94%A8%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/","year":"2022"},{"content":"lmstfy 碰巧github给我推了这个任务队列，抽空读了下源码。如果第一次接触这种延时任务队列，还是挺有意思的。\n架构 lmstfy使用redis作为底层存储，使用redis的list的lpush,brpop完成任务的生产和消费，消费要阻塞的pop，避免轮询。lmstfy使用redis设计了多个模块，ready队列是其一，还有timer zset的延时队列用来处理延时的任务，以及死信队列处理消费失败的任务。\n假设称任务为task或job，下面统一称之为job。对于一个任务的提交（生产），它具有下面的生命周期：\n任务被加入任务池（redis kv实现），所有任务的body数据都以redis kv存储，而入queue入zset的都是任务的句柄或者说描述符或者说指针 如果任务是延时的，加入延时队列（timer zset），对这个延时队列的操作以lua脚本的形式存在，简单来看就是按时间tick，将到期的任务句柄取出，判断是加入ready队列还是死信队列，判断依据就是任务的retry值是否为0 如果任务是非延时的立即执行，则任务句柄直接加入ready队列，等待被brpop 消费时，通过brpop取得任务句柄，随后从任务池中取回任务payload/body信息 对于一个任务被消费，它具有下面的生命周期：\n任务句柄存在于ready队列头部，被pop出来 该任务句柄的retry数减一，并加入timer zset，防止客户端消费失败 根据任务句柄从任务池中取出任务payload/body，返回给客户端 对于一个任务被确认或删除，它具有下面的生命周期：\n任务在任务池中被删除 对于ready队列或延时队列（timer zset）中的任务句柄都不会被立刻删除 对于ready队列，再次消费时会因为没有在任务池中取到任务而跳过（根据任务消费流程，该句柄仍然会retry减一并进入timer zset。也许可以先检查任务池之后再提交timer zset，不过源代码是这样写的，也无伤大雅） 对于timer zset，再次tick时会检测到任务不存在于任务池而删除该句柄，从而该任务被彻底删除 对于延时队列，即timer zset，它具有下面的生命周期:\n客户端preload lua脚本到redis上 客户端启动NewTicker，每个时钟滴答都调用redis上的lua脚本，分发过期的任务到死信队列或者ready队列 timer zset以到期时间戳作为score(timestamp := time.Now().Unix() + int64(delaySecond))，这样只需要一个简单的zrangebyscore 'zset_name' 0 time.Now()就可以筛选出要到期执行的任务 如果该任务句柄对应的任务不在任务池，说明已被删除，或任务池中的任务过期，反之无论如何，该任务丢失了 如果任务池中存在该任务，查看任务句柄里的retry数 如果retry==0，则说明重试次数用完，加入死信队列 如果retry\u0026gt;0，说明还可以重试，加入ready队列 在timer zset中删除刚才筛选出的到期执行的任务 一般来说，任务句柄包含几个字段：\nnamespace queue retry jobID 前两个好理解，就是作用域，retry就是自动重试的剩余次数，jobID则用于在任务池中找到该任务。 对外API lmstfy对外暴露的典型API是Publish，Consume，Delete，Peek，还有一些操作死信队列的API。\n其中Delete就是ACK的意思，一个客户端通过Consume消费任务队列后，应该调用Delete删除该任务\nLua脚本 使用lua脚本的好处：如果采用Redis执行Lua脚本的方式实现多条指令，Lua脚本整体上在Redis中是原子的，并且在脚本执行期间，其他指令无法插入。并且Lua脚本编写简单，可以将一部分业务规则放入其中。而传统的与redis交互，即使是pipeline，也无法包含业务规则。\n","id":21,"section":"posts","summary":"\u003ch1 id=\"lmstfy\"\u003elmstfy\u003c/h1\u003e\n\u003cp\u003e碰巧github给我推了这个\u003ca href=\"https://github.com/bitleak/lmstfy\"\u003e任务队列\u003c/a\u003e，抽空读了下源码。如果第一次接触这种延时任务队列，还是挺有意思的。\u003c/p\u003e\n\u003ch2 id=\"架构\"\u003e架构\u003c/h2\u003e\n\u003cp\u003elmstfy使用redis作为底层存储，使用redis的list的\u003ccode\u003elpush\u003c/code\u003e,\u003ccode\u003ebrpop\u003c/code\u003e完成任务的生产和消费，消费要阻塞的pop，避免轮询。lmstfy使用redis设计了多个模块，ready队列是其一，还有timer zset的延时队列用来处理延时的任务，以及死信队列处理消费失败的任务。\u003cbr\u003e\n假设称任务为task或job，下面统一称之为job。对于一个任务的提交（生产），它具有下面的生命周期：\u003c/p\u003e","tags":["TaskQueue"],"title":"[task-queue] lmstfy","uri":"https://wymli.github.io/2022/04/task-queue-lmstfy/","year":"2022"},{"content":"Yarn Client ","id":22,"section":"posts","summary":"\u003ch1 id=\"yarn-client\"\u003eYarn Client\u003c/h1\u003e","tags":["BigData"],"title":"[BigData] yarn client","uri":"https://wymli.github.io/2022/04/big-data-yarn/","year":"2022"},{"content":"Spark 并行计算框架 支持流式或批式 spark提交有一个单独的spark-commit.sh脚本 批处理是spark core 流处理是spark streaming，这里的流在实现上是会传入一个窗口大小和下一个窗口的位移，来产生RDD，一个RDD就是一个窗口的小批次数据，所以spark streaming只是在批式spark core上包装了一下。 执行流程 一个spark 应用的流程是这样的：\n创建sparkcontext类 from pyspark.conf import SparkConf from pyspark.context import SparkContext conf = SparkConf() conf.setMaster(\u0026quot;local\u0026quot;).setAppName(\u0026quot;My app\u0026quot;) \u0026lt;- 这里master是local，表示本地模式，一般是local[N],表示N个线程。也可以是spark standalone或yarn sc = SparkContext(conf=conf) # 或直接 sc = SparkContext('local', 'my app') sparkcontext实例调用各种数据输入方法，生成RDD。典型的数据输入是hdfs，格式是text，比如 # 从hdfs读取textfile lines = sc.textFile(\u0026quot;hdfs://hadoop102:9000/fruit.txt\u0026quot;) print(lines.collect()) # rdd.collect(): Return a list that contains all of the elements in this RDD. 执行transformation算子，这种算子的典型代表就是map，flatmap，filter，distinct，union，reduceByKey等 from operator import add res = lines.flatmap(lambda x: x.split(\u0026quot;,\u0026quot;)).map(lambda x: (x,1)).reduceByKey(add) # rdd.flatmap: Return a new RDD by first applying a function to all elements of this RDD, and then flattening the results. 典型的例子就是将一行转成单词，最终从行的列表变成单词的列表。 # rdd.map: Return a new RDD by applying a function to each element of this RDD. 典型的例子就是将单词变成带计数，即apple =\u0026gt; (apple, 1) # rdd.reduceByKey: Merge the values for each key using an associative and commutative reduce function. 类似MR中的Combiner。这里reduceByKey需要传入的是针对相同key的reduce函数。所谓的key就是pair RDD中的第一个元素，即二元组x中的x[0]，换句话说，经过map后RDD自动变成了Pair RDD。而所谓的reduce函数的运行机制就是：将RDD的元素两两传入函数，返回一个新元素，并将新元素和下一个元素再一起两两传入函数，直到只剩下一个元素。 reduceByKey是Key范围内的reduce。计算机制和fold是一样的。 # 这里的operator.add 等价于 lambda a,b: a+b 执行action算子，这种算子的典型代表是reduce,foreach，saveAsTextFile，collect，count，top等 res.saveAsTextFile(\u0026quot;hdfs://...\u0026quot;) sc.stop() 执行action算子就意味提交job 名词解释 cite 任务视角：\nApplication：用户手写定义的应用，一个sparkcontext就是一个spark程序，用户编写的Spark应用程序,包括一个Driver和多个executors。 Job：一个spark app包含一个或多个Job，每遇到一个RDD的Action操作就生成一个新的Job。 Stage：一个Job分为一个或多个Stage，各个stage之间按照顺序执行。 Task：Task是被分配到一个Executor上的计算单元， 一个Stage分为多个Task。Task执行相同的程序逻辑，只是它们操作的数据不同。一般RDD的一个Partition对应一个Task。Stage将划分成多个可以并行计算的Task。 进程：\nDriver: 运行main()函数并创建SparkContext进程。比如由driver进程执行top函数进行内存排序 Executor：运行在worker node上执行具体的计算任务，存储数据的进程 数据视角：\nRDD -\u0026gt; partition -\u0026gt; record. Partition是Spark进行数据处理的基本单位，一般来说一个Partition对应一个Task，而一个Partition中通常包含数据集中的多条记录(Record)，一个RDD包括多个Partition。 宽窄依赖 Spark中RDD的高效与DAG（有向无环图）有很大的关系，在DAG调度中需要对计算的过程划分Stage，划分的依据就是RDD之间的依赖关系。RDD之间的依赖关系分为两种，宽依赖(wide dependency/shuffle dependency)和窄依赖（narrow dependency）\n窄依赖就是指父RDD的每个分区只被一个子RDD分区使用，子RDD分区通常只对应常数个父RDD分区，典型的如map，filter，union（常数个父RDD） 宽依赖就是指父RDD的每个分区都有可能被多个子RDD分区使用，子RDD分区通常对应父RDD所有分区，典型的如groupByKey\n注意上面所说的分区，是RDD-\u0026gt;Partition-\u0026gt;Record 这个关系里的分区。在Spark中以Partition为单位进行操作。在对stage从后往前拓展时，遇到窄依赖就将其加入stage，遇到宽依赖就断开，重新是一个stage。\ntransformation 算子和action 算子的区别 Transformation是lazy的，用于定义新的RDD；而Action启动计算操作，提交一个Job，并向用户程序（driver，yarn的appMaster）返回值或向外部存储写数据\n部署方式 我们需要cluster manager来管理机器，不同的cluster manager就是不同的部署方式\nspark standalone 这里standalone就是通过一种原生的非常plain的方式管理机器，即在对应的节点上手动启动管理进程。比如在master机器上启动./sbin/start-master.sh，在worker机器上启动./sbin/start-worker.sh。这样，机器就加入了spark集群。\nspark on yarn 前面spark standalone的方式比较笨且繁琐，如果有很多机器，有很多类似spark这样的分布式集群应用，那每台机器都要手动运行一下对应的manager process，很麻烦。\nyarn给出了一种统一的管理机器的方式，支持多种分布式集群应用，比如spark，flink这些大数据场景应用。换句话说，是将机器上的spark-worker进程换成了yarn的nodeManager进程，而这种nodeManager进程不仅支持spark，还支持flink等。\n对于spark on yarn，就让yarn帮助我们管理机器，所谓的管理机器呢，我的理解就是处在对应机器上运行的管理进程作为一个代理，是能够帮你分配资源，启动进程等等。此时，driver就是yarn的AppMaster。\n详细流程 yarn集群模式为例，部署模式也是cluster；参考 here\nspark deploy部署部分的代码在此处\nspark-submit.sh 脚本开始提交，参数master指定yarn，java代码指定jar包\u0026ndash;jar和主类名\u0026ndash;class（main函数在的类，这和java运行机制相关），其他语言如python/r，只要指定文件即可 spark-submit.sh 脚本调用scala org.apache.spark.deploy.SparkSubmit类，下称之为SparkSubmit进程 根据调用参数\u0026ndash;deploy=cluster,\u0026ndash;master=yarn，现在调用org.apache.spark.deploy.yarn.YarnClusterApplication， SparkSubmit进程创建一个YarnClient，提交Application给yarn集群的ResourceManager，提交成功后返回appid，如果spark.submit.deployMode=cluster\u0026amp;\u0026amp;spark.yarn.submit.waitAppCompletion=true， SparkSubmit进程会定期输出appId日志直到任务结束(monitorApplication(appId))，否则会输出一次日志然后退出。 这就是deploy=cluster模式，如果是deploy=client模式，就不需要提交。 YarnClient通过提交Application的过程 launcherBackend.connect() yarnClient.init(hadoopConf) yarnClient.start() logInfo(\u0026quot;Requesting a new application from cluster with %d NodeManagers\u0026quot; .format(yarnClient.getYarnClusterMetrics.getNumNodeManagers)) // Get a new application from our RM val newApp = yarnClient.createApplication() val newAppResponse = newApp.getNewApplicationResponse() appId = newAppResponse.getApplicationId() // The app staging dir based on the STAGING_DIR configuration if configured // otherwise based on the users home directory. val appStagingBaseDir = sparkConf.get(STAGING_DIR) .map { new Path(_, UserGroupInformation.getCurrentUser.getShortUserName) } .getOrElse(FileSystem.get(hadoopConf).getHomeDirectory()) stagingDirPath = new Path(appStagingBaseDir, getAppStagingDir(appId)) new CallerContext(\u0026quot;CLIENT\u0026quot;, sparkConf.get(APP_CALLER_CONTEXT), Option(appId.toString)).setCurrentContext() // Verify whether the cluster has enough resources for our AM verifyClusterResources(newAppResponse) // Set up the appropriate contexts to launch our AM val containerContext = createContainerLaunchContext(newAppResponse) val appContext = createApplicationSubmissionContext(newApp, containerContext) // Finally, submit and monitor the application logInfo(s\u0026quot;Submitting application $appId to ResourceManager\u0026quot;) yarnClient.submitApplication(appContext) launcherBackend.setAppId(appId.toString) reportLauncherState(SparkAppHandle.State.SUBMITTED) 在提交应用时，yarn客户端首先调用yarn.createApplication()获取newAppResponse（其中包括appID），随后构建容器和应用上下文appContext，最终提交应用yarn.submitApplication(appContext)，yarn客户端通过传入appContext真正提交应用。appContext包括容器启动上下文（containerContext = createContainerLaunchContext(newAppResponse)）和应用提交上下文（appContext = createApplicationSubmissionContext(newApp,containerContext)） 我们来看是如何构建容器启动上下文的，createContainerLaunchContext(newAppResponse)： if (isClusterMode) { Utils.classForName(\u0026quot;org.apache.spark.deploy.yarn.ApplicationMaster\u0026quot;).getName } else { Utils.classForName(\u0026quot;org.apache.spark.deploy.yarn.ExecutorLauncher\u0026quot;).getName } val commands = prefixEnv ++ Seq(Environment.JAVA_HOME.$$() + \u0026quot;/bin/java\u0026quot;, \u0026quot;-server\u0026quot;) ++ javaOpts ++ amArgs ++ Seq( \u0026quot;1\u0026gt;\u0026quot;, ApplicationConstants.LOG_DIR_EXPANSION_VAR + \u0026quot;/stdout\u0026quot;, \u0026quot;2\u0026gt;\u0026quot;, ApplicationConstants.LOG_DIR_EXPANSION_VAR + \u0026quot;/stderr\u0026quot;) 对于deploy=cluster的appMaster的容器启动命令简单来看就是bin/java -server org.apache.spark.deploy.yarn.ApplicationMaster --class … --jar ... 8. 应用通过yarnClient提交后，yarn集群某一个NodeManager收到ResourceManager的命令，启动ApplicationMaster进程。ApplicationMaster会启动driver。\nif (isClusterMode) { runDriver() } else { runExecutorLauncher() } 下面是runDriver()的流程，先另启动一个线程通过反射执行命令行中-–class指定的类（org.apache.spark.examples.SparkPi）中的main函数。同时在主线程会向ResourceManager作为AppMaster注册自己。 // 1. startUserApplication 启动用户应用main代码 val mainMethod = userClassLoader.loadClass(args.userClass) .getMethod(\u0026quot;main\u0026quot;, classOf[Array[String]]) val userThread = new Thread { override def run(): Unit = { mainMethod.invoke(null, userArgs.toArray) } } userThread.setContextClassLoader(userClassLoader) userThread.setName(\u0026quot;Driver\u0026quot;) userThread.start() // 2. 向rm注册am registerAM(host, port, userConf, sc.ui.map(_.webUrl), appAttemptId) // 3. 申请exector的资源 createAllocator(driverRef, userConf, rpcEnv, appAttemptId, distCacheConf) // createAllocator()函数内部 // 3.1 创建申请客户端 allocator = client.createAllocator( yarnConf, _sparkConf, appAttemptId, driverUrl, driverRef, securityMgr, localResources) // 3.2 申请资源并沟通对应的nm，执行exector容器 allocator.allocateResources() // allocateResources()函数内部 // 3.2.1 获取containers val allocateResponse = amClient.allocate(progressIndicator) val allocatedContainers = allocateResponse.getAllocatedContainers() // 3.2.1 筛选contaienrs，根据主机host，机架rack等信息筛选出要使用的containers matchContainerToRequest(allocatedContainer, ANY_HOST, containersToUse, remainingAfterOffRackMatches) // 3.2.3 启动容器 runAllocatedContainers(containersToUse) // runAllocatedContainers()内部 // 3.2.3.1 调用ExecutorRunnable for (container \u0026lt;- containersToUse) { new ExecutorRunnable( Some(container), conf, sparkConf, driverUrl, executorId, executorHostname, executorMemory, executorCores, appAttemptId.getApplicationId.toString, securityMgr, localResources, ResourceProfile.DEFAULT_RESOURCE_PROFILE_ID // use until fully supported ).run() } // 3.2.3.2 执行ExecutorRunnable.run()方法,沟通nodeManager def run(): Unit = { logDebug(\u0026quot;Starting Executor Container\u0026quot;) nmClient = NMClient.createNMClient() nmClient.init(conf) nmClient.start() startContainer() } def startContainer(){ val commands = prepareCommand() ctx.setCommands(commands.asJava) nmClient.startContainer(container.get, ctx) } def prepareCommand(){ val commands = prefixEnv ++ Seq(Environment.JAVA_HOME.$$() + \u0026quot;/bin/java\u0026quot;, \u0026quot;-server\u0026quot;) ++ javaOpts ++ Seq(\u0026quot;org.apache.spark.executor.YarnCoarseGrainedExecutorBackend\u0026quot;, \u0026quot;--driver-url\u0026quot;, masterAddress, \u0026quot;--executor-id\u0026quot;, executorId, \u0026quot;--hostname\u0026quot;, hostname, \u0026quot;--cores\u0026quot;, executorCores.toString, \u0026quot;--app-id\u0026quot;, appId, \u0026quot;--resourceProfileId\u0026quot;, resourceProfileId.toString) ++ userClassPath ++ Seq( s\u0026quot;1\u0026gt;${ApplicationConstants.LOG_DIR_EXPANSION_VAR}/stdout\u0026quot;, s\u0026quot;2\u0026gt;${ApplicationConstants.LOG_DIR_EXPANSION_VAR}/stderr\u0026quot;) } 这一套流程走下来，我觉得应该看看yarnclient~，即怎么与yarn交互。\n提交任务 https://spark.apache.org/docs/2.2.0/submitting-applications.html 通过名为spark-submit.sh的脚本，指定master的地址即可提交到spark standalone或yarn。\n其他 application driver\nSpark applications run as independent sets of processes on a cluster, coordinated by the SparkContext object in your main program (called the driver program). spark application是用户提交的作业 The driver program must listen for and accept incoming connections from its executors throughout its lifetime executor\nprocesses on worker node that run computations and store data for your application. Each application gets its own executor processes, which stay up for the duration of the whole application and run tasks in multiple threads. task\neach driver schedules its own tasks tasks from different applications run in different JVMs Specifically, to run on a cluster, the SparkContext can connect to several types of cluster managers (either Spark’s own standalone cluster manager, Mesos, YARN or Kubernetes), which allocate resources across applications. Once connected, Spark acquires executors on nodes in the cluster, which are processes that run computations and store data for your application. Next, it sends your application code (defined by JAR or Python files passed to SparkContext) to the executors. Finally, SparkContext sends tasks to the executors to run.\nYou can launch a standalone cluster ，或者是running on the Mesos or YARN cluster managers\nThe standalone cluster mode currently only supports a simple FIFO scheduler across applications\n一个application有很多 executors\n应用启动模式： For standalone clusters, Spark currently supports two modes. In client mode, the driver is launched in the same process as the client that submits the application. In cluster mode, however, the driver is launched from one of the Worker processes inside the cluster, and the client process exits as soon as it fulfills its responsibility of submitting the application without waiting for the application to finish.\n","id":23,"section":"posts","summary":"\u003ch1 id=\"spark\"\u003eSpark\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e并行计算框架\u003c/li\u003e\n\u003cli\u003e支持流式或批式\u003c/li\u003e\n\u003cli\u003espark提交有一个单独的spark-commit.sh脚本\u003c/li\u003e\n\u003cli\u003e批处理是spark core\u003c/li\u003e\n\u003cli\u003e流处理是spark streaming，这里的流在实现上是会传入一个窗口大小和下一个窗口的位移，来产生RDD，一个RDD就是一个窗口的小批次数据，所以spark streaming只是在批式spark core上包装了一下。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"执行流程\"\u003e执行流程\u003c/h2\u003e\n\u003cp\u003e一个spark 应用的流程是这样的：\u003c/p\u003e","tags":["BigData"],"title":"[BigData] spark","uri":"https://wymli.github.io/2022/04/big-data-spark/","year":"2022"},{"content":"大数据 未来工作或多或少要接触大数据，学习下。\nglossary hadoop， 可以认为大数据平台就是hadoop平台/hadoop集群的代名词 hadoop集群作为基础设施，主要包括存储和调度。存储是hdfs（hadoop distributed file system），调度是yarn（yet another resource negotiater），在计算方面，一般是和用户强相关的，执行的是用户传入的Job，在计算框架上，一般有MapReduce/Spark/Flink等。使用这些分布式计算框架实现的作业，当被yarn调度从而运行时，一般称之为“XX On Yarn”，比如\u0026quot;Spark On yarn\u0026quot; Hdfs hdfs是一个流式的分布式的文件存储系统 存的是文件，但不是以文件为单位分布式副本存储；而是将文件切分成多个小块block（一个block 128MB），每个block将按照一定的副本策略存在多个机器上。 hdfs的架构主要分为NameNode和DataNode，DataNode存储文件块数据，NameNode存储元数据 元数据包括1.目录树信息 2.文件到块的映射 3.块到DataNode的映射 hdfs还包括secondaryNameNode，不过这个进程不是很重要，他的工作主要合并日志，NameNode对于写文件操作，一般不是直接进行随机内存访问的直接修改磁盘上的持久化的文件目录数和映射关系（称作fsimage），而是将写操作以日志追加的方式append到一个叫做edit.log的文件中，类似于各种AOF，WAL，secondaryNameNode的工作就是合并fsimage和edit.log（按道理来说，这个合并应该直接让NameNode分出一个线程来合并就完事了，但是这里独立了一个进程，优劣性可以再讨论） hdfs是流式的，这意味着文件只能追加，不能修改。一次写入，多次读。 在写操作时，先写到本地临时文件，当文件大小达到一个块后，开始以4KB为一个packet发送给第一个DataNode，第一个DataNode会接受并转发给第二个DataNode（递归形式），当文件全部写完后，文件才可见。 Yarn Yarn是资源管理调度器，所谓的资源是硬件资源，包括内存，CPU，磁盘，网络等，以容器的形式交付给应用 我感觉就是k8s+docker的感觉，提供统一的nodeManager和容器资源交付。 架构上是资源管理器（分为资源调度器和应用程序管理器）+节点管理器 资源调度器根据需要的资源声明交付容器 应用程序管理器管理应用的提交，与资源调度器协商资源等 节点管理器，顾名思义，节点代理，实际上的工作者，分配容器资源，启动工作进程等。 每个任务的提交需要三个东西 应用的Master程序（ApplicationMaster），比如MapReduceApplicationMaster，类似于k8s中CRD Operator的感觉，比如spark中的driver就是这种appMaster程序（也就是spark的main程序，包含sparkcontext） 应用的Master程序的启动程序，估计是启动脚本一类的。 用户程序，比如用户自己编写的MapReduce程序 我比较好奇容器是怎么交付的，可以深究一下\nMapReduce 没啥，一个计算框架呗，将输入输出的过程分为： Input 无状态Map，比如map，flatmap， filter，foreach 有状态Reduce，比如reduceby，sortby，group， fold Output 用户只需要在特定的阶段编写自己的代码即可 本质上就是提供对单个元素操作，以及对一群元素操作的api，可以看看spark.rdd暴露的api HBase 宽列NoSQL 逻辑上表可以看成是稀疏行的数据库，但物理上表按列族存储 Table -\u0026gt; Region -\u0026gt; Store 一张表在行方向上会划分为多个Region（一开始只有一个Region，行多了就划分多个Region），不同的Region在不同的RegionServer上存放，一般一个RS可以放10-1000个Region，每个Region的元数据包括1.表名 2.首行 3.末行。由于有首末行，很容易知道一个将要插入的行应该插入哪个Region，联系哪个RegionServer Region是分布式存储的最小单元，所以一行数据会放在一个节点（RegionServer）上，但在节点机器上，不同列族的存储是分开的。 Region由多个Store构成，一个Store就是一个列族，包含MemTable和SSTable。 存储上的结构有待研究，一般是二进制自己封装个block，一个block包含rowkey，ts，columnFamily，column，value等，然后各个block按rowkey排序，相同的rowkey的不同column会排到一起。 Hive Hive是一个工具，将HiveQL转成MapReduce任务（也可以是spark任务）,一个简单的例子是HBase不支持SQL，所以可以使用HiveQL操作HBase Hive建立在hdfs或相关生态之上（比如hbase） Hive在普通的查询语句之前，要先建表 关于建表，数据存储，可以看看这个。 简单来说就是，hive建立的表是一种虚拟的表，相当于只是一种元数据schema。表里的数据是存在hdfs上的，当你建完表之后，就会在hive对应的hdfs路径里自动创建一个该表的文件夹，你需要自己把你的数据文件拷贝进去。然后就可以通过hql查询了。后续应该是直接把数据存到hive对应的hdfs里。 hive还支持一种external表，可以指定对应的数据存储的hdfs路径，而不需要将数据放到hive对应的路径里面。 一般来说，文件里的一行就是一个record，在行里面，需要指定列分隔符来划分列。 Hive表Hbase表映射 通过\u0026quot;hbase.columns.mapping\u0026quot;设置映射关系，按position一对一，:key可以省略，cf0:indexId代表映射到hbase的cf0列族的indexId列（没有写对应的hive的列明，因为按位置顺序一对一映射，也就是hive中的indexId）\n如果是外部表，数据就是存在hbase 如果有设置\u0026quot;hbase.mapred.output.outputtable\u0026quot;，往hive插入数据也会插入hbase，否则就是单向的hbase到hive的映射 如果想将hive的people表的内容输出到hbase的hbase_people表，可以创建一个hive的hive_people表作为中继，如下面的代码，然后执行插入insert overwrite table hive_people select * from people where age = 17;\nCREATE EXTERNAL TABLE hbase_table_2(key int, indexId string, muMac string) STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler' WITH SERDEPROPERTIES (\u0026quot;hbase.columns.mapping\u0026quot; = \u0026quot;:key,cf0:indexId,cf0:muMac\u0026quot;) TBLPROPERTIES(\u0026quot;hbase.table.name\u0026quot; = \u0026quot;default:index1\u0026quot;); create table hive_people ( id int, name string, age string, sex string, edu string, country string, telPhone string, email string ) stored by 'org.apache.hadoop.hive.hbase.HBaseStorageHandler' with serdeproperties (\u0026quot;hbase.columns.mapping\u0026quot; = \u0026quot; :key, basic_info:name, basic_info:age, basic_info:sex, basic_info:edu, other_info:country, other_info:telPhone, other_info:email \u0026quot;) tblproperties(\u0026quot;hbase.table.name\u0026quot; = \u0026quot;default:hbase_people\u0026quot;,\u0026quot;hbase.mapred.output.outputtable\u0026quot; = \u0026quot;default:hbase_people\u0026quot;); 可以考虑hive的可视化连接工具dbeaver\nSpark 并行计算框架 支持流式(spark streaming)或批式(spark core) spark streaming 会将流处理成一个个窗口，所以其实底层还是批式的spark core 部署方式有spark standalone， spark on yarn 参看大数据系列下一篇专门介绍spark的文章 ","id":24,"section":"posts","summary":"\u003ch1 id=\"大数据\"\u003e大数据\u003c/h1\u003e\n\u003cp\u003e未来工作或多或少要接触大数据，学习下。\u003c/p\u003e\n\u003ch1 id=\"glossary\"\u003eglossary\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003ehadoop， 可以认为大数据平台就是hadoop平台/hadoop集群的代名词\u003c/li\u003e\n\u003cli\u003ehadoop集群作为基础设施，主要包括存储和调度。存储是hdfs（hadoop distributed file system），调度是yarn（yet another resource negotiater），在计算方面，一般是和用户强相关的，执行的是用户传入的Job，在计算框架上，一般有MapReduce/Spark/Flink等。使用这些分布式计算框架实现的作业，当被yarn调度从而运行时，一般称之为“XX On Yarn”，比如\u0026quot;Spark On yarn\u0026quot;\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"hdfs\"\u003eHdfs\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003ehdfs是一个流式的分布式的文件存储系统\u003c/li\u003e\n\u003cli\u003e存的是文件，但不是以文件为单位分布式副本存储；而是将文件切分成多个小块block（一个block 128MB），每个block将按照一定的副本策略存在多个机器上。\u003c/li\u003e\n\u003cli\u003ehdfs的架构主要分为NameNode和DataNode，DataNode存储文件块数据，NameNode存储元数据\n\u003cul\u003e\n\u003cli\u003e元数据包括1.目录树信息 2.文件到块的映射 3.块到DataNode的映射\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ehdfs还包括secondaryNameNode，不过这个进程不是很重要，他的工作主要合并日志，NameNode对于写文件操作，一般不是直接进行随机内存访问的直接修改磁盘上的持久化的文件目录数和映射关系（称作fsimage），而是将写操作以日志追加的方式append到一个叫做edit.log的文件中，类似于各种AOF，WAL，secondaryNameNode的工作就是合并fsimage和edit.log（按道理来说，这个合并应该直接让NameNode分出一个线程来合并就完事了，但是这里独立了一个进程，优劣性可以再讨论）\u003c/li\u003e\n\u003cli\u003ehdfs是流式的，这意味着文件只能追加，不能修改。一次写入，多次读。\u003c/li\u003e\n\u003cli\u003e在写操作时，先写到本地临时文件，当文件大小达到一个块后，开始以4KB为一个packet发送给第一个DataNode，第一个DataNode会接受并转发给第二个DataNode（递归形式），当文件全部写完后，文件才可见。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"yarn\"\u003eYarn\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eYarn是资源管理调度器，所谓的资源是硬件资源，包括内存，CPU，磁盘，网络等，以容器的形式交付给应用\u003c/li\u003e\n\u003cli\u003e我感觉就是k8s+docker的感觉，提供统一的nodeManager和容器资源交付。\u003c/li\u003e\n\u003cli\u003e架构上是资源管理器（分为资源调度器和应用程序管理器）+节点管理器\n\u003cul\u003e\n\u003cli\u003e资源调度器根据需要的资源声明交付容器\u003c/li\u003e\n\u003cli\u003e应用程序管理器管理应用的提交，与资源调度器协商资源等\u003c/li\u003e\n\u003cli\u003e节点管理器，顾名思义，节点代理，实际上的工作者，分配容器资源，启动工作进程等。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e每个任务的提交需要三个东西\n\u003cul\u003e\n\u003cli\u003e应用的Master程序（ApplicationMaster），比如MapReduceApplicationMaster，类似于k8s中CRD Operator的感觉，比如spark中的driver就是这种appMaster程序（也就是spark的main程序，包含sparkcontext）\u003c/li\u003e\n\u003cli\u003e应用的Master程序的启动程序，估计是启动脚本一类的。\u003c/li\u003e\n\u003cli\u003e用户程序，比如用户自己编写的MapReduce程序\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003e我比较好奇容器是怎么交付的，可以深究一下\u003c/p\u003e","tags":["BigData"],"title":"[BigData] 大数据入门","uri":"https://wymli.github.io/2022/04/big-data-hadoop%E7%9B%B8%E5%85%B3%E5%85%A5%E9%97%A8/","year":"2022"},{"content":"tensorflow入门 intro tensorflow采用基于数据流图的模型设计方法。\n基础平台层软件设计模式： 库模式和框架模式。库模式下，平台层软件以静态和动态的开发库存在，主程序(main)入口和控制流程掌握在用户手中，比如pytorch，numpy，tensorflow。框架模式下，平台层软件以可执行文件的形式存在，以后端守护进程独立运行，程序的入口和整体流程由框架控制，比如spark，mapreduce。\ntensorflow的计算核心是c++代码，称为运行时核心库，典型的是通过pip安装tensorflow后部署到site-packages的动态链接库文件，包括三个模块：分布式运行时，公共运行时，算子核函数。核心库的外层就是各个语言的API。\n公共运行时：实现数据流图计算的基本逻辑 分布式运行：在公共运行时的基础上实现数据流图的跨进程协同计算逻辑 算子核函数：包含图上具体操作节点的算法实现代码 python包管理工具\nanaconda pip virtualenv python软件发布的新格式是wheel（whl），用于取代过时的egg包格式。\nCUDA：Compute Unified Device Architecture\n数据流图的编程范式是声明式编程，与之相比的是结构化编程，面向对象编程\n数据流图被定义为用节点和有向边描述数学运算的有向无环图\n数据流图中的节点通常是各类操作（operation），比如数学运算，数据填充，结果输出，变量读写等，每个节点上的操作都需要分配具体的物理设备以确定在哪里计算（CPU，GPU等） 数据流图中的有向边描述了节点间的输入输出关系，边上流动的是代表高维数据的张量，故命名为TensorFlow 基于梯度下降法优化求解的机器学习问题，分为两个计算阶段：\n前向图求值 用户编写代码完成，包括定义模型的目标函数，损失函数，输入输出数据的形状和数据类型等 后向图求梯度 由TensorFlow的优化器自动生成，主要功能是计算模型参数的梯度值，并用梯度值高性对应的模型参数。 数据流图的主要概念\n节点： 前向图中的节点统一称为操作，根据功能分为三类 计算节点（Operation类）：无状态的计算或控制操作，数学函数或表达式，比如MatMul，BiasAdd，SoftMax，大多数节点都是这种类型。 计算节点不需要显式构造Operation实例，一般都通过tf提供的各种操作函数，比如add，multiply等 存储节点（Variable类）：有状态的变量操作，存储模型参数的变量，比如ReLu Layer的权重参数W和偏差b 变量节点不是一个简单的节点，而是多个子节点构成的子图，通常由四个子节点构成： 变量初始值（Initial Value）：无状态操作 更新变量值的操作（Assign）：无状态操作 读取变量值的操作（Read）：无状态操作 变量操作：有状态操作，实际就是变量存储的实体，数据存在这个节点 数据节点（Placeholder类）：占位符，比如Input和Label，用来描述输入输出的形状和类型，在执行时，占位符要填充对应的数据。 在实际执行时，需要将数据填充（feed）到数据节点，比如sess.run(y,feed_dict{x:rand_array})，通过feed_dict传入。这里run的第一个参数代表要取出的变量的值（要计算的变量的值，会打印在stdout） 后向图中的节点也分为三类： 梯度值：经过前向图计算得出的模型参数的梯度 更新模型参数的操作：定义了如何将梯度值更新到对应的模型参数 更新后的模型参数：与前向图中的模型参数一一对应，但却是更新后的参数值，用于模型的下一轮训练 前向图和后向图唯一的连接就是梯度，前向图根据模型参数和输入数据前向计算得到梯度，后向图通过梯度更新得到新的模型参数 有向边 数据流图中的有向边用于定义操作之间的关系，分为两类 数据边：传输数据，绝大多数流动着张量的边都是这类 控制边：定义控制依赖，通过设置节点的前置依赖来决定相关节点的执行顺序 所有的节点都通过数据边或控制边连接，入度为0的节点没有前置依赖，可以立即执行；反之要等待前置依赖的系欸但执行结束后才能执行。 数据流图的执行顺序由库决定，与用户定义顺序无关，与节点之间的逻辑依赖关系和运行时库的实现机制有关\n数据流图上的节点执行顺序的实现借鉴了拓扑排序的设计思想： 创建一个map存储节点和入度的映射，创建一个入度为0的节点的待执行队列 扫描map，将入度为0的节点入队 执行，并将执行完的节点的出度节点的入度减1 重新扫描map，将入度为0的节点入队并执行，并将出度节点的入度递减，不断重复 TensorFlow中的数据载体是张量，用张量统一表示所有数据，分为Tensor和SparseTensor（解决高维稀疏数据的内存占用）\n张量的阶代表所描述数据的最大维度，是描述数据在高维空间的维数。定义每一阶的长度的可以唯一确定一个张量的形状。\n0阶张量：标量 1阶张量：向量 2阶张量：矩阵 3阶张量：\u0026hellip; 张量在数据定义上是一个句柄，存储张量的元信息和指向数据的指针，而不实际存储数据，这是为了实现嗯内存复用，一个前置操作的输出值被输入到多个后置操作时，无需重复存储多个输出值。当张量不再被引用后，内存将被释放，通过引用计数，就像GC一样。\n构造张量的参数，也就是张量的属性，即t1=Tensor(dtype,shape,graph,...)\ndtype：张量传输数据的类型 shape：张量传输数据的形状 graph：张量所属的数据流图 name： 张量在数据流图中的名字 op： 生成该张量的前置操作 value_index：张量在该前置操作的所有输出值中的索引 一般情况，不需要使用Tensor()来构造张量，可以通过更高级的API或通过操作（比如add）来间接创建张量\na = tf.constant(1.0) b = tf.add(a,a) 会话Session：就是真正执行数据流图计算的上下文，需要create，run，close。在tf2.0中，删除了Session。\nTensorFlow 1.X需要用户使用tf.*里的API手动构建计算图。然后用session.run()传入输入tensor并且计算某些输出tensor。TensorFlow 2.X默认是Eager执行模式，我们在定义一个Operation的时候会动态构造计算图并且马上计算。 这样的好处就是我们的代码就像在执行普通的Python代码，Graph和Session等实现细节概念都被隐藏在后面了。 Eager执行的另外一个好处就是不再需要tf.control_dependencies了(如果不知道也没有关系，以后不会再用到了)，因为Tensorflow的计算图是按照Python代码的顺序执行。 优化器：为用户实现了自动计算模型参数梯度值的功能。tf的优化器根据前向图的计算拓扑和损失值，利用链式求导法则依次求出每个模型参数在给定数据下的梯度值，并将其更新到对应的模型参数以完成一个训练步骤。优化器是tf的训练工具。\n优化器自动生成后向图，即gradients子图 分布式架构 分布式训练分为PS-worker架构和Ring-allreduce架构，前者是中心化非对称的，后者是去中心化对称的全worker架构\n这种架构不是C/S架构，而是类似于SPARK，只是将单进程变成多进程在多个服务器运行而已。对于Spark，yarn或原生的spark-standalone提供了集群管理，让你可以一键在多机构建多进程任务，所以非常类似于C/S架构了，但不管怎么说，他其实只是集群的节点管理器帮你启动进程而已。对于tf来说，也是一样，不过tf目前来说没有实现集群节点管理，都是手动在多机启动进程，通过在同一份代码里预置PS和worker的操作，并在启动进程时指明是PS还是worker 计算形态： 推理态：只前向计算 训练态：执行前向图的推理计算和后向图的梯度计算参数更新 分布式架构：PS-Worker，解决了大规模参数在分布式存储和更新时的一致性问题 模型的所有参数唯一的存储在PS的内存中，当参数过大时，就分布式的存在多个PS中 模型训练过程中的计算（包括前向图推理和后向图梯度计算）都由worker完成 不同的worker的数据流图都是相同的，只是填充的数据不同，从而数据并行 训练数据一般存储在分布式文件系统中，比如hdfs 分布式模型的单步训练过程： worker从PS拉取模型参数，各worker拉取的参数一样 worker从hdfs读取不同批次的批数据，各worker读取的数据不同 worker执行前向图计算和后向图计算梯度 worker将梯度推送到PS上 PS汇总梯度，求出梯度的均值，并更新模型参数 PS-worker架构的思想是分离模型和训练，PS负责模型参数的存储、分发、汇总、更新；Worker负责推理计算和梯度计算。 分布式训练一般采用数据并行加速模型训练 数据并行分为两类： 图内复制（in-graph replication）：单进程内的数据并行，即单机多卡，对应pytorch的dp 图间复制（between-graph replication）：多进程，跨机器分布式训练 参数更新机制： 异步训练（asynchronous training）：每个worker独立训练，计算出梯度后按照一定策略等待特定时间发生后进行模型参数更新，也可以直接立即更新，主要看异步更新策略，而不需要等待其他worker完成训练计算梯度 同步训练（synchronous training）：每个worker独立训练计算梯度上报梯度并等待从PS拉取最新的模型参数，PS会等待所有worker计算完后再汇总更新模型参数，计算快的worker要等待慢worker计算 同步训练比异步训练收敛速度快，训练步数少。异步训练单步快，但容易受单批数据的影响，训练步数多。 同步训练机制： 副本是模型训练过程中单独处理一份批数局的抽象 并行副本数：单步训练中用户希望的并行数据个数 实际副本数：单步训练中实际参与计算的worker数 如果并行副本数大于实际副本数，代表计算快的worker会单步计算多个批次；如果小于，则代表个别worker不需要训练 同步优化器，以M个模型参数，N个并行副本数为例 梯度聚合器：存储梯度值的队列，有多少个模型参数就有多少个梯度队列。对于每个模型参数，都存在一个长度为N的梯度队列，共M个队列 同步标记队列：存储同步标记的队列，全局一条队列。同步标记决定worker是否能够参与梯度计算，有多少个并行副本数队列就有多少个同步标记，只有拿到同步标记的worker才能拿到最新的模型参数。这个同步标记（sync token）实际是一个表示global_step全局训练步数（第几步）的值。worker会首先拿到该代表全局训练步数的token，更新自己的本地训练步数，然后从PS获取最新的模型参数，计算梯度。 每一次上报的梯度和下发的模型参数都会附带训练步数的字段，以保证不会串数据。对于PS来说，梯度聚合器在收集梯度时会校验收到的梯度的训练步数是不是当前的全局训练步数（版本号的作用），否则丢弃。Worker上传完梯度后，会去阻塞的领取同步标记队列中的标记，由于已经领完，只能等待全局进入下一步训练（如果是能者多劳，并行副本数大于实际副本数，那么快worker能在同步标记队列中领到标记，并继续计算）。PS更新完参数后，会更新全局训练步数+1，并按并行副本数入队同步标记队列。 异步训练机制： 每个worker计算出的梯度值上报后，PS更新参数 不同的worker进行参数的拉取和更新时，tf内部的锁机制保证模型参数的数据一致性 异步训练的一个典型问题就是次优解，比如worker1和worker2同时拉取参数，计算，worker1先上报更新参数，比如是向左的梯度，然后worker2上报，也是向左的梯度，但此时参数已经更新过了，导致两次向左，可能就向左过头了 TensorFlow Serving 生产系统中，模型以推理态运行，我们需要打通模型训练到发布的全流程 ","id":25,"section":"posts","summary":"\u003ch1 id=\"tensorflow入门\"\u003etensorflow入门\u003c/h1\u003e\n\u003ch2 id=\"intro\"\u003eintro\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003etensorflow采用基于数据流图的模型设计方法。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e基础平台层软件设计模式： 库模式和框架模式。库模式下，平台层软件以静态和动态的开发库存在，主程序(main)入口和控制流程掌握在用户手中，比如pytorch，numpy，tensorflow。框架模式下，平台层软件以可执行文件的形式存在，以后端守护进程独立运行，程序的入口和整体流程由框架控制，比如spark，mapreduce。\u003c/p\u003e","tags":["Tensorflow"],"title":"[tensorflow-arch] 入门","uri":"https://wymli.github.io/2022/04/tensorflow-intro/","year":"2022"},{"content":"输出version到文件 version=`git log --date=iso --pretty=format:\u0026quot;%cd @%H\u0026quot; -1` if [ $? -ne 0 ]; then version=\u0026quot;unknown version\u0026quot; fi compile=`date +\u0026quot;%F %T %z\u0026quot;`\u0026quot; by \u0026quot;`go version` if [ $? -ne 0 ]; then compile=\u0026quot;unknown datetime\u0026quot; fi describe=`git describe --tags 2\u0026gt;/dev/null` if [ $? -eq 0 ]; then version=\u0026quot;${version} @${describe}\u0026quot; fi cat \u0026lt;\u0026lt; EOF | gofmt \u0026gt; pkg/utils/version.go package utils const ( Version = \u0026quot;$version\u0026quot; Compile = \u0026quot;$compile\u0026quot; ) EOF cat \u0026lt;\u0026lt; EOF \u0026gt; bin/version version = $version compile = $compile EOF 或\nupdate-version: @echo \u0026quot;package goqlc\u0026quot; \u0026gt; $(shell pwd)/version.go @echo \u0026quot;\u0026quot;\u0026gt;\u0026gt; $(shell pwd)/version.go @echo \u0026quot;const GITREV = \\\u0026quot;\u0026quot;$(GITREV)\u0026quot;\\\u0026quot;\u0026quot; \u0026gt;\u0026gt; $(shell pwd)/version.go @echo \u0026quot;const VERSION = \\\u0026quot;\u0026quot;$(VERSION)\u0026quot;\\\u0026quot;\u0026quot; \u0026gt;\u0026gt; $(shell pwd)/version.go @echo \u0026quot;const BUILDTIME = \\\u0026quot;\u0026quot;$(BUILDTIME)\u0026quot;\\\u0026quot;\u0026quot; \u0026gt;\u0026gt; $(shell pwd)/version.go @echo \u0026quot;const MAINNET = true\u0026quot; \u0026gt;\u0026gt; $(shell pwd)/version.go 升级pkg #!/bin/bash echo \u0026quot;\u0026gt; run: go mod tidy\u0026quot; go mod tidy pkg_arg=$1 pkg_name_in_gomod=($(cat go.mod | grep \u0026quot;${pkg_arg}\u0026quot;)) if [ -z ${pkg_name_in_gomod} ] then echo \u0026quot;\u0026gt; find ${pkg_arg}: not found\u0026quot; exit else echo \u0026quot;\u0026gt; grep ${pkg_arg}: ${pkg_name_in_gomod[@]}\u0026quot; fi pkg=${pkg_name_in_gomod[0]} version=${pkg_name_in_gomod[1]} read -p \u0026quot;update(y/n)?\u0026quot; is_update case ${is_update} in n*) exit ;; esac update_msg=($(go get -u ${pkg} 2\u0026gt;\u0026amp;1 | grep upgraded)) if [ ${#update_msg[@]} -eq 0 ] then echo \u0026quot;\u0026gt; nothing to update\u0026quot; exit else version_updated=${update_msg[${#update_msg[@]}-1]} echo \u0026quot;\u0026gt; updated: ${version} ==\u0026gt; ${version_updated}\u0026quot; fi ","id":26,"section":"posts","summary":"\u003ch2 id=\"输出version到文件\"\u003e输出version到文件\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-shell\"\u003eversion=`git log --date=iso --pretty=format:\u0026quot;%cd @%H\u0026quot; -1`\nif [ $? -ne 0 ]; then\n    version=\u0026quot;unknown version\u0026quot;\nfi\n\ncompile=`date +\u0026quot;%F %T %z\u0026quot;`\u0026quot; by \u0026quot;`go version`\nif [ $? -ne 0 ]; then\n    compile=\u0026quot;unknown datetime\u0026quot;\nfi\n\ndescribe=`git describe --tags 2\u0026gt;/dev/null`\nif [ $? -eq 0 ]; then\n    version=\u0026quot;${version} @${describe}\u0026quot;\nfi\n\ncat \u0026lt;\u0026lt; EOF | gofmt \u0026gt; pkg/utils/version.go\npackage utils\nconst (\n    Version = \u0026quot;$version\u0026quot;\n    Compile = \u0026quot;$compile\u0026quot;\n)\nEOF\n\ncat \u0026lt;\u0026lt; EOF \u0026gt; bin/version\nversion = $version\ncompile = $compile\nEOF\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e或\u003c/p\u003e","tags":["Script"],"title":"[脚本] 脚本","uri":"https://wymli.github.io/2021/07/%E8%84%9A%E6%9C%AC/","year":"2021"},{"content":"设计模式-多步骤构造器 [TOC]\n想像这样一个场景,我们有一个工人类,工人可以吃饭,工作,睡觉\ntype worker interface{ eat() work() sleep() } 但是如何获得一个工人呢?常见的我们有一个New函数用于构造:\ntype workerImpl struct{ } var _ worker = new(workerImpl) func NewWorker() workerImpl { return \u0026amp;workerImpl{} } 注意这里使用的常见的技巧有:\n返回实例,接收接口 编译器断言某个结构体是否实现某接口 但是假如我们的workerImpl给构造是多步骤的呢? 比如,一个worker的构建需要\n注册 签到 培训 验收 培训完后,我们对之前的步骤验收,一个worker就可以任意的调用eat,work,sleep了\n方案1: worker 我们可以直接把前置条件耦合在worker的成员函数里,但显然,一个真正的worker只应该有eat/work/sleep这三个成员函数,其他的成员函数不应该属于worker\nw := workerImpl{} w.Register() w.CheckIn() w.Study() w.Verify() w.Work() w.Eat() w.Sleep() 这显然很丑陋,并且不符合逻辑,我们\n1: 无法控制用户对Register,CheckIn,Study,Verify的调用顺序 2: 也无法保证用户在Verify后不再调用这些前置条件函数 方案2: builder 为了解决问题2,我们独立出一个builder构造类来专门做构造工作\nb := workerBuilder{} b.Register() b.CheckIn() b.Study() worker := b.Build() 这样,build()后返回的workerImpl,可以只实现eat/sleep/work三个方法.\ntype workerBuilder struct{ registerInfo, checkInInfo , studyInfo string } func (wb workerBuilder) Build() *workerImpl{ check(wb.registerInfo) check(wb.checkInInfo) check(wb.studyInfo) return \u0026amp;workerImpl{} } 但是我们仍然没有解决register,checkin,study的调用顺序问题,用户也许先调用Study再Register\n方案3: 柯里化,返回下一步的构造函数 什么是柯里化? 简单来说柯里化就是将一个函数多个参数变成多个函数一个参数,通过返回闭包函数的形式来引用之前的参数\ncheckIn := RegisterWorker() study := checkIn(\u0026quot;1\u0026quot;) verify := study(\u0026quot;B\u0026quot;) worker := verify(\u0026quot;1\u0026quot;) 如此一来,我们就很好的指定了下一步该调用哪个步骤\n注意,每一步返回的函数都是一个闭包,这样就可以在全链路中传递registerInfo, checkInInfo , studyInfo string\n比如:\ntype checkIn func(checkInCode string) study type study func(studyClass string) verify type verify func(verifyCode string) workerImpl func RegisterWorker() checkIn { registerInfo := registerF() return func(checkInCode string) study{ checkInInfo := checkInF(registerInfo,checkInCode) return func(studyClass string) verify{ studyInfo := studyF(checkInInfo, studyClass) return func(verifyCode string) workerImpl{ if ok := verifyF(studyInfo , verifyCode);ok{ return workerImpl{...} } return nil } } } } 有时候,我们需要一些信息暴露出来,这也简单,函数返回即可\nfunc RegisterWorker() (string, checkIn) { registerInfo := registerF() return registerInfo , func(checkInCode string) study{ // ... } } 这很好的使得用户调用代码简单了,但是随之带来一个问题,在多步骤构建过程中,代码会有较多缩进\n不过只要我们将各个步骤的业务代码抽象成函数(指上例中的register(),checkIn(registerInfo),study(checkInInfo)等函数),只在柯里化中调用一个函数,然后返回下一个构建函数,还是可以接收的\n方案4: 装饰函数以避免callback hell 用函数wrap\u0026lt;装饰器decorate\u0026gt;代替闭包匿名函数\ntype checkIn func(checkInCode string) study type study func(studyClass string) verify type verify func(verifyCode string) workerImpl func RegisterWorker() checkIn { registerInfo := registerF() return checkInWrap(registerInfo) } func checkInWrap(ri *registerInfo) checkIn{ return func(checkInCode string) study{ checkInInfo := checkInF(ri,checkInCode) return studyWrap(checkInfo) } } func studyWrap(ci *checkInInfo) study{ return func(studyClass string) verify{ studyInfo := studyF(ci, studyClass) return verifyWrap(studyInfo) } } func verifyWrap(si *studyInfo)verify{ return func(verifyCode string) workerImpl{ if ok := verifyF(si , verifyCode);ok{ return workerImpl{...} } return nil } } 原理:我们之前使用闭包的原因就是为了获取registerInfo,checkInInfo,studyInfo这些数据,所以也可以使用wrap把他们包起来,作为函数参数传入,效果是一样的\n其实闭包就相当于匿名函数,这里的wrap就是具名函数,匿名函数天然获取外部数据引用,具名函数通过显式传参来获取引用.\n","id":27,"section":"posts","summary":"\u003ch1 id=\"设计模式-多步骤构造器\"\u003e设计模式-多步骤构造器\u003c/h1\u003e\n\u003cp\u003e[TOC]\u003c/p\u003e\n\u003cp\u003e想像这样一个场景,我们有一个工人类,工人可以吃饭,工作,睡觉\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003etype worker interface{\n    eat()\n    work()\n    sleep()\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e但是如何获得一个工人呢?常见的我们有一个New函数用于构造:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003etype workerImpl struct{\n}\n\nvar _ worker = new(workerImpl)\n\nfunc NewWorker() workerImpl {\n    return \u0026amp;workerImpl{}\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cblockquote\u003e\n\u003cp\u003e注意这里使用的常见的技巧有:\u003c/p\u003e","tags":["Golang","DesignPattern"],"title":"[Go] 多步骤构造器","uri":"https://wymli.github.io/2021/07/go-%E5%A4%9A%E6%AD%A5%E9%AA%A4%E6%9E%84%E5%BB%BA/","year":"2021"},{"content":"关于redis的大部分事情 非常不错: https://redis.io/topics/data-types-intro redis的数据结构: Binary-safe strings. Lists: collections of string elements sorted according to the order of insertion. They are basically linked lists. Sets: collections of unique, unsorted string elements. Sorted sets, similar to Sets but where every string element is associated to a floating number value, called score. The elements are always taken sorted by their score, so unlike Sets it is possible to retrieve a range of elements (for example you may ask: give me the top 10, or the bottom 10). Hashes, which are maps composed of fields associated with values. Both the field and the value are strings. This is very similar to Ruby or Python hashes. Bit arrays (or simply bitmaps): it is possible, using special commands, to handle String values like an array of bits: you can set and clear individual bits, count all the bits set to 1, find the first set or unset bit, and so forth. HyperLogLogs: this is a probabilistic data structure which is used in order to estimate the cardinality of a set. Don\u0026rsquo;t be scared, it is simpler than it seems\u0026hellip; See later in the HyperLogLog section of this tutorial. Streams: append-only collections of map-like entries that provide an abstract log data type. They are covered in depth in the Introduction to Redis Streams. hyperloglog计数(计算集合大小)的误差 less than 1% , 最多 12KB的空间 redis的value最多512MB, 但是经验表明100MB就比较慢了 redis server-assisted client side caching 很明显,我们有时候要在机器上做localcache,比如常见的bigcache 如何保证本地缓存和redis数据的一致性是一个问题 简单场景,对实时性要求不高,给本地缓存设置一个过期时间即可 复杂场景,使用redis的pub/sub系统来发送失效消息(类似基于失效的缓存一致性模型) 但是这个发大了太多倍写流量,对每个写,都要发失效消息给每个订阅的client,但很可能那个client其实没有缓存该数据 redis实现: tracking模式: redis存储客户端请求过哪些key,当这个key变动时,发送失效消息给客户端; 客户端需要显式传送CLIENT TRACKING ON指令来开启tracking 实际上server维护了固定大小的全局一张表,当满时,淘汰旧的key,发送invalid消息,这造成了不必要的流量,但有限减少了server的内存开销 broadcasting模式: 客户端决定订阅哪些前缀,server维护一个前缀表,当某个key被修改,server则发往所有订阅了该前缀的client invalid消息,而不管client是否之前read了这个key redis cluster 主从读写分离, 写只由master写,读均摊到各个slave? redis 附加组件module 比如RedisBloom - Probabilistic Datatypes Module for Redis, 提供了布隆过滤器,topk等数据结构用于大数据流处理 使用: 在redis.conf中的loadmodule字段配置 /${dir}/redisbloom.so , 该.so的获得一般是通过clone 源代码,然后make ","id":28,"section":"posts","summary":"\u003ch1 id=\"关于redis的大部分事情\"\u003e关于redis的大部分事情\u003c/h1\u003e\n\u003col\u003e\n\u003cli\u003e非常不错: \u003ca href=\"https://redis.io/topics/data-types-intro\"\u003ehttps://redis.io/topics/data-types-intro\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eredis的数据结构:\n\u003cul\u003e\n\u003cli\u003eBinary-safe strings.\u003c/li\u003e\n\u003cli\u003eLists: collections of string elements sorted according to the order of insertion. They are basically \u003cem\u003elinked lists\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eSets: collections of unique, unsorted string elements.\u003c/li\u003e\n\u003cli\u003eSorted sets, similar to Sets but where every string element is associated to a            floating number value, called \u003cem\u003escore\u003c/em\u003e. The elements are always taken sorted by their score, so unlike Sets it is possible to retrieve a range of elements (for example you may ask: give me the top 10, or the bottom 10).\u003c/li\u003e\n\u003cli\u003eHashes, which are maps composed of fields associated with values. Both the field and the value are strings. This is very similar to Ruby or Python hashes.\u003c/li\u003e\n\u003cli\u003eBit arrays (or simply bitmaps): it is possible, using special commands, to  handle String values like an array of bits: you can set and clear individual bits, count all the bits set to 1, find the first set or unset bit, and so forth.\u003c/li\u003e\n\u003cli\u003eHyperLogLogs: this is a probabilistic data structure which is used in order to estimate the cardinality of a set. Don\u0026rsquo;t be scared, it is simpler than it seems\u0026hellip; See later in the HyperLogLog section of this tutorial.\u003c/li\u003e\n\u003cli\u003eStreams: append-only collections of map-like entries that provide an abstract log data type. They are covered in depth in the \u003ca href=\"https://redis.io/topics/streams-intro\"\u003eIntroduction to Redis Streams\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ehyperloglog计数(计算集合大小)的误差 less than 1% ,  最多 12KB的空间\u003c/li\u003e\n\u003cli\u003eredis的value最多512MB, 但是经验表明100MB就比较慢了\u003c/li\u003e\n\u003cli\u003eredis server-assisted client side caching\n\u003col\u003e\n\u003cli\u003e很明显,我们有时候要在机器上做localcache,比如常见的bigcache\u003c/li\u003e\n\u003cli\u003e如何保证本地缓存和redis数据的一致性是一个问题\n\u003col\u003e\n\u003cli\u003e简单场景,对实时性要求不高,给本地缓存设置一个过期时间即可\u003c/li\u003e\n\u003cli\u003e复杂场景,使用redis的pub/sub系统来发送失效消息(类似基于失效的缓存一致性模型)\n\u003col\u003e\n\u003cli\u003e但是这个发大了太多倍写流量,对每个写,都要发失效消息给每个订阅的client,但很可能那个client其实没有缓存该数据\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eredis实现:\n\u003col\u003e\n\u003cli\u003etracking模式: redis存储客户端请求过哪些key,当这个key变动时,发送失效消息给客户端; \u003ccode\u003e客户端需要显式传送CLIENT TRACKING ON指令来开启tracking\u003c/code\u003e\n\u003col\u003e\n\u003cli\u003e实际上server维护了固定大小的全局一张表,当满时,淘汰旧的key,发送invalid消息,这造成了不必要的流量,但有限减少了server的内存开销\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003ebroadcasting模式: 客户端决定订阅哪些前缀,server维护一个前缀表,当某个key被修改,server则发往所有订阅了该前缀的client invalid消息,而不管client是否之前read了这个key\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eredis cluster\n\u003col\u003e\n\u003cli\u003e主从读写分离, 写只由master写,读均摊到各个slave?\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eredis 附加组件module\n\u003col\u003e\n\u003cli\u003e比如RedisBloom - Probabilistic Datatypes Module for Redis, 提供了布隆过滤器,topk等数据结构用于大数据流处理\u003c/li\u003e\n\u003cli\u003e使用: 在redis.conf中的loadmodule字段配置 /${dir}/redisbloom.so , 该.so的获得一般是通过clone 源代码,然后make\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e","tags":["Database","redis"],"title":"[DB] redis","uri":"https://wymli.github.io/2021/07/db-redis/","year":"2021"},{"content":"单测 单测在业务开发的重要性中不言而喻,在常见的epc规范中,一般的存量覆盖率要求达到50%,增量覆盖率要求达到80%.\n当然,这个很教条,我们一般只测有意义的目录,对于像config目录,dao目录测试的必要性不是很高\n常用的单测脚本:\ngo test ./... -coverprofile=cover.out -covermode=conut -gcflags=all=-l -v 排除掉某些路径: go test $(go list ./... | grep -v \u0026quot;/neverTest\u0026quot;) -coverprofile=cover.out -covermode=conut -gcflags=all=-l -v [TOC]\n打桩 最完美的开发方式当然是依赖注入,但是很多时候我们并没有这么完美的设计,或者简单的业务其实也不值得去多么精心设计,所以不可避免的在单测中要用上打桩框架,运行时替换目标函数/变量的值\n其实现原理就是改变目标被替换函数的跳转地址,使其跳转到替换函数上来\nMonkey implements monkeypatching by rewriting the running executable at runtime and inserting a jump to the function you want called instead. This is as unsafe as it sounds and I don\u0026rsquo;t recommend anyone do it outside of a testing environment.\n只能在单测中使用\n三大框架 目前业界在用的,基本就是三大框架\nmonkey 优点: 使用简单 缺点: 不支持序列结果 go get -u -v bou.ke/monkey 打桩普通函数 monkey.Patch(\u0026lt;target function\u0026gt;, \u0026lt;replacement function\u0026gt;) monkey.Patch(fmt.Println, func(a ...interface{}) (n int, err error) { s := make([]interface{}, len(a)) for i, v := range a { s[i] = strings.Replace(fmt.Sprint(v), \u0026quot;hell\u0026quot;, \u0026quot;*bleep*\u0026quot;, -1) } return fmt.Fprintln(os.Stdout, s...) }) 打桩成员函数 monkey.PatchInstanceMethod(\u0026lt;type\u0026gt;, \u0026lt;name\u0026gt;, \u0026lt;replacement\u0026gt;) monkey.PatchInstanceMethod(reflect.TypeOf(d), \u0026quot;Dial\u0026quot;, func(_ *net.Dialer, _, _ string) (net.Conn, error) { return nil, fmt.Errorf(\u0026quot;no dialing allowed\u0026quot;) }) 在原函数调用和新函数调用之间切换 monkey.PatchGuard guard = monkey.PatchInstanceMethod(reflect.TypeOf(http.DefaultClient), \u0026quot;Get\u0026quot;, func(c *http.Client, url string) (*http.Response, error) { guard.Unpatch() defer guard.Restore() if !strings.HasPrefix(url, \u0026quot;https://\u0026quot;) { return nil, fmt.Errorf(\u0026quot;only https requests allowed\u0026quot;) } return c.Get(url) }) 因为我们只在单测中使用patch,所以parchGuard的使用场景较少\ngomonkey go get github.com/agiledragon/gomonkey 使用上差别不大\nfunc ApplyFunc(target, double interface{}) *Patches func ApplyFuncSeq(target interface{}, outputs []OutputCell) *Patches func ApplyFuncVar(target, double interface{}) *Patches func ApplyFuncVarSeq(target interface{}, outputs []OutputCell) *Patches func ApplyGlobalVar(target, double interface{}) *Patches func ApplyMethod(target reflect.Type, methodName string, double interface{}) *Patches func ApplyMethodSeq(target reflect.Type, methodName string, outputs []OutputCell) *Patches 使用示例:\n// func rpc(name string) (string, error) outputs := []gomonkey.OutputCell{ {Values: gomonkey.Params{\u0026quot;1\u0026quot;, nil}}, {Values: gomonkey.Params{\u0026quot;2\u0026quot;, nil}}, {Values: gomonkey.Params{\u0026quot;3\u0026quot;, nil}}, } gomonkey.ApplyFuncSeq(rpc, outputs) gomock 需要搭配mockgen使用,针对接口的定义直接生成一个mock实现\n此处略,不够轻量.\n虽然一般根据proto文件生成桩代码时也会一起用mockgen生成mock代码,但其实一般还是不太用这个.\n用gomonkey足以适用大部分场景\n面对接口 我们没办法mock接口,也就是说,如果a是接口变量,那么它的成员函数我们是没办法mock的,我们只能mock b的成员函数,b是a的具体实现,比如:\ntype a interface{ Say func() } func NewA() a{ return \u0026amp;default{} } func Test_x(...){ // x := NewA() // gomonkey.ApplyMethod(reflect.Typeof(x),\u0026quot;Say\u0026quot;,...) // useless b := ... gomonkey.ApplyFunc(NewA , func()a{return \u0026amp;b}) gomonkey.ApplyMethod(reflect.Typeof(b),\u0026quot;Say\u0026quot;,...) // ok } 当然一般这种返回接口的,都会提供NewMockA这个函数供我们调用\n这也涉及一个设计原则: 返回实例,接收接口;\n即函数返回值应该是某个实例,函数的参数应该是某个接口\n断言 一般的,我们适用表驱动的单测,所以assert就不是那么重要了,一般我们只判断一下函数结果是不是相等即可\ngoconvey https://github.com/smartystreets/goconvey\n非常适合做行为测试,但是我们一般好像都只是做一下结果测试\ntesttify \u0026quot;github.com/stretchr/testify/assert\u0026quot; func TestSomething(t *testing.T) { // assert equality assert.Equal(t, 123, 123, \u0026quot;they should be equal\u0026quot;) } ","id":29,"section":"posts","summary":"\u003ch1 id=\"单测\"\u003e单测\u003c/h1\u003e\n\u003cp\u003e单测在业务开发的重要性中不言而喻,在常见的epc规范中,一般的存量覆盖率要求达到50%,增量覆盖率要求达到80%.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e当然,这个很教条,我们一般只测有意义的目录,对于像config目录,dao目录测试的必要性不是很高\u003c/p\u003e","tags":["Golang","ut"],"title":"[Go] 单测","uri":"https://wymli.github.io/2021/06/go-%E5%8D%95%E6%B5%8B/","year":"2021"},{"content":"推荐系统 utility matrix效用矩阵,横轴是用户,纵轴是商品,矩阵元素是打分\n推荐系统的三个核心步骤:\n收集效用矩阵中的打分 从已知的打分中预测未知的打分 评估预测性能 Gathering Ratings 我们可以显式让用户打分或付钱让它们打分,也可以从它们的行为推测分数,比如它们经常观看,或购买\n但是utility matrix是稀疏的,大多数人对大多数item都是没有打分的,并且新用户和新item都是没有值的\n我们主要介绍三种方法:\n基于内容的 协同的 基于潜在因子的 基于内容的推荐 主要思想: 仅考虑用户自己,我们向用户推荐这样的商品,这些商品和用户之前的高打分商品类似\n比如电影,我们已知用户的一些高打分电影,于是向用户推荐同一个导演,演员等等的电影\nItem profile 因此,我们需要为每个item建立一个profile,profile是一些特征的集合,比如电影就是导演,演员,剧本作者等等,网页就是一些关键字集合\n对于文本网页来说,如何选择重要的关键字特征呢?\n我们使用 TF-IDF score,当一个关键字在该网页出现的越多,在其他网页出现的越少,我们就认为该关键字的TF-IDF指标高,更能代表该doc\nTF-IDF score: $$ w_{ij} = TF_{ij} * IDF_i $$ 其中: $$ TF_{ij} = \\frac{f_{ij}}{max_kf_{kj}} , IDF_i = log\\frac{N}{n_i} $$ f_ij 表示term/feature i 在 doc/item j中的频率,n_i表示有多少个doc提到了term i,N是总的doc数\nUser profile 它已打分的一些item的加权平均数据\n推荐 给定user profile x和item profile i,我们通过余弦相似度来判断是否相似\npros \u0026amp; cons 优点:\n不需要其他user的信息 能够按用户的口味推荐 能够推荐新的或不流行的item 可解释性 缺点:\n寻找合适的feature去构建item profile是较难的 对于新用户,没有user profile,无法推荐 过于专一化,绝不推荐user的content profile之外的item,用户也许想有不同的兴趣 协同过滤 我们首先找到N个其他user,这些user对item的打分与user x的打分是类似的,我们基于这N个用户的打分来预测x的打分,所以叫协同\n寻找相似的user jaccard 相似度 如果我们不考虑具体的打分多少,而只考虑有没有打分,然后可以对集合计算jaccard相似度\ncos 相似度 我们将未打分的item视作0,于是一个user对应的item就是一个向量,计算余弦即可\npearson 互相关系数 皮尔森互相关系数,具体公式见ppt,这是统计里面相关性检验常用的方法\n协同过滤 假设utility矩阵是user x item的\nuser-user 协同过滤 即只考虑一列,通过一列上的其他相似user的值来预测自己,N代表与那些对i打过分的user中的与x最相似的k个user,s_xy代表x与y的相似度 $$ r_{xi} = \\frac{\\sum_{y∈N}s_{xy}*r_{yi}}{\\sum_{y∈N}s_{xy}} $$\nitem-item 协同过滤 即只考虑一行,通过一行上的其他相似item的值来预测自己 $$ r_{xi} = \\frac{\\sum_{j∈N}s_{ij}*r_{xi}}{\\sum_{j∈N}s_{ij}} $$\npros \u0026amp; cons 优点:\n不需要选择feature,对所有类型的item都适用 缺点\n冷启动 first rater,对于未被打分过的新item,不能推荐 popularity bias,一般会倾向于推荐热门的item,而不是对味的item ","id":30,"section":"posts","summary":"\u003ch1 id=\"推荐系统\"\u003e推荐系统\u003c/h1\u003e\n\u003cp\u003eutility matrix效用矩阵,横轴是用户,纵轴是商品,矩阵元素是打分\u003c/p\u003e\n\u003cp\u003e推荐系统的三个核心步骤:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e收集效用矩阵中的打分\u003c/li\u003e\n\u003cli\u003e从已知的打分中预测未知的打分\u003c/li\u003e\n\u003cli\u003e评估预测性能\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"gathering-ratings\"\u003eGathering Ratings\u003c/h2\u003e\n\u003cp\u003e我们可以显式让用户打分或付钱让它们打分,也可以从它们的行为推测分数,比如它们经常观看,或购买\u003c/p\u003e","tags":null,"title":"recommend system","uri":"https://wymli.github.io/2021/04/datamining-recsys/","year":"2021"},{"content":"locality sensitive hashing 位置敏感哈希,这是一种hash算法,当两个对象被hash到同一个桶中时,我们认为这两个对象是可能相似的,然后去检查这两个对象的相似性,最后得出答案,这避免了对所有对象两两之间进行O(N^2)的比较\n寻找相似的文章 graph LR; a(docs)--\u0026gt;|shingling|b(k-shingles)--\u0026gt;|min-hashing|c(signature matrix)--\u0026gt;|lsh|d(buckets) shingling shingling是一个取样过程,最终得到k-shingle的集合,即每个shingle含有k个token,token可以是char,word等,一般可以用word\nshingle的方法是,维护一个k大小的窗口,从文档开头开始,取样,然后向后移动一个token,继续取样,重复上述过程\n假设doc是\u0026quot;abcab\u0026quot;,以k=2,token=char来shingle,则得到{ab,bc,ca,ab} -\u0026gt; {ab,bc,ca}(忽略重复的)\n假设doc是\u0026quot;a rose is a rose is a rose\u0026quot;,以k=4,token=word来shingle,则得到{ (a,rose,is,a), (rose,is,a,rose), (is,a,rose,is),(a,rose,is,a),(rose ,is ,a ,rose) } -\u0026gt; { (a,rose,is,a), (rose,is,a,rose), (is,a,rose,is) }\n现在我们有了两个doc的k-shingle集合,一种朴素的想法是直接计算这两个集合的jaccard相似度即可,这需要O(N^2)的复杂度\nmin-hashing 在保留相似性的情况下,将大的shingle的集合hash成小的signature\nif sim(C1,C2) is high, then with high prob. h(C1) = h(C2)\nif sim(C1,C2) is low, then with high prob. h(C1) ≠ h(C2)\nPr[ hmin(A) = hmin(B) ] = J(A,B)\n不是所有的相似性度量都能找到何时的hash函数,但是当使用jaccard时,min-hashing就是一个合适的hash函数\n首先我们在shingling可以得到一个shingles矩阵(行是shingle,列是doc),我们定义一次min-Hashing是这样的,首先生成一个随机的全排列,然后将每一列按这个全排列进行重新排列,然后寻找第一个为1的行号,这个行号就是minHashing的结果(至于这个行号是选择映射后的还是映射前的,其实无所谓)\n进行多次minHashing,我们得到了一个signature matrix,每一行就是相应的列的一次minHashing的结果\n比如一列是(1100011),排列向量是(2376154),那么结果是(0111100),排列向量代表着映射后的位置\n一般可能hash100次,即最终的signature矩阵有100行\nLSH 我们认为两个doc之间如果jaccard的相似度大于0.8,就是相似的\nLSH哈希函数的目的是将一些doc映射到一个桶中,我们认为一个桶内的doc就是可能相似的备选对(candidate pair),然后去check这些备选对即可\n在lsh中,一列被分为b个band,一个band包含r行,我们每次对一个band进行hash(一列hash到一个桶,并且只有当band完全相同时,才会hash到一个桶),对于hash到一个桶内的不同列,我们认为其是备选对,check它们真正的相似性\n继续hash下一个band,重复操作\n因此,对于hash到一个桶内的不同列,它们至少是有一个band是完全相同的,假设sim(c1,c2)=0.8,也就是c1,c2两列的相似度为0.8,也就是每个signature相似的概率为0.8,那么一个band完全相同的概率为(0.8)^r\n这个hash函数的选取,只需要保证,必须是完全相同才能映射到一个桶中\n","id":31,"section":"posts","summary":"\u003ch1 id=\"locality-sensitive-hashing\"\u003elocality sensitive hashing\u003c/h1\u003e\n\u003cp\u003e位置敏感哈希,这是一种hash算法,当两个对象被hash到同一个桶中时,我们认为这两个对象是可能相似的,然后去检查这两个对象的相似性,最后得出答案,这避免了对所有对象两两之间进行O(N^2)的比较\u003c/p\u003e","tags":["dataMining","LSH"],"title":"[dataMining] LSH","uri":"https://wymli.github.io/2021/04/datamining-lsh/","year":"2021"},{"content":"[c] 符号与链接 我们知道,一个可执行文件的生成过程经历了一些步骤:\n预处理-\u0026gt;编译-\u0026gt;汇编-\u0026gt;链接\n最终的步骤,是将不同的.o目标文件链接在一起,形成一个可执行文件,不同的.o文件将会引用其他.o文件内的变量或函数,那么它们是怎么找到对应的变量或函数的地址的呢?\n程序装载 一个程序是怎么装载进内存的呢? 很显然,当我们在bash下直接输入程序名时,该程序就被启动了,比如\u0026quot;./a\u0026quot;,就启动了当前路径下的程序a\n但是我们知道,实际上shell也是一个程序,这其实是在一个程序下去启动另一个程序\n实际上,会首先调用fork(),然后在子进程中中进行系统调用\u0026quot;execve()\u0026quot;,执行新的程序,而父进程则\u0026quot;waitpid\u0026quot;等待子进程结束(父进程就是bash,借此我们也可以自己实现一个简单的shell)\n因此,程序被执行/被装载进内存依赖一个系统调用: \u0026ldquo;execve()\u0026rdquo;\n静态链接 这种链接方法会将静态链接库和自己的代码合在一起生成一个较大的可执行文件\n动态链接 程序可以调用不存在于静态文件中的函数或变量\n加载时 称为隐式动态链接\n常规的链接手段,当使用诸如\u0026quot;gcc a.c -o a.out -lpthread\u0026quot;时,这个libpthread.so就会在程序加载时一起链接加载到内存\n好处是,静态可执行程序是不需要包含整个.so动态链接库的\n运行时 称为显式动态链接\n还可以在程序中显式的加载动态链接库,这个在windows系统编程中是常见的,比如go语言中加载win32的api\ndll := syscall.NewLazyDLL(\u0026quot;kernel32.dll\u0026quot;) messageBox , _ := syscall.GetProcAddress(dll, \u0026quot;MessageBoxW\u0026quot;) 通过GetProcAddress显式调用函数\n","id":32,"section":"posts","summary":"\u003ch1 id=\"c-符号与链接\"\u003e[c] 符号与链接\u003c/h1\u003e\n\u003cp\u003e我们知道,一个可执行文件的生成过程经历了一些步骤:\u003c/p\u003e\n\u003cp\u003e预处理-\u0026gt;编译-\u0026gt;汇编-\u0026gt;链接\u003c/p\u003e\n\u003cimg src=\"https://dlonng.com/images/gcc.png\" alt=\"gcc\" style=\"zoom: 50%;\" /\u003e\n\u003cp\u003e最终的步骤,是将不同的.o目标文件链接在一起,形成一个可执行文件,不同的.o文件将会引用其他.o文件内的变量或函数,那么它们是怎么找到对应的变量或函数的地址的呢?\u003c/p\u003e","tags":["c"],"title":"[c] 符号与链接","uri":"https://wymli.github.io/2021/04/c-%E7%AC%A6%E5%8F%B7%E4%B8%8E%E9%93%BE%E6%8E%A5/","year":"2021"},{"content":"TodoList sysmon线程 eBPF和ipvs : ref kafka client, 看看sarama,了解kafka客户端能获得哪些东西,server api暴露了哪些东西 kv db, 比如etcd的boltdb多读少写, lsm-tree的多写少读 etcd ,consul 的分布式共识 ","id":33,"section":"posts","summary":"\u003ch1 id=\"todolist\"\u003eTodoList\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003esysmon线程\u003c/li\u003e\n\u003cli\u003eeBPF和ipvs : \u003ca href=\"https://mp.weixin.qq.com/s?__biz=MzU1MzY4NzQ1OA==\u0026amp;mid=2247494326\u0026amp;idx=1\u0026amp;sn=82db83a0c03f45d1258f9563b5e465e7\u0026amp;chksm=fbedaa7bcc9a236df2dfae59f4f0400e6f3d15d747eaf66248a8bc9e3dda260a7cf203c6404e\u0026amp;xtrack=1\u0026amp;scene=90\u0026amp;subscene=93\u0026amp;sessionid=1617852418\u0026amp;clicktime=1617852482\u0026amp;enterid=1617852482\u0026amp;ascene=56\u0026amp;devicetype=android-29\u0026amp;version=2800023b\u0026amp;nettype=WIFI\u0026amp;abtest_cookie=AAACAA%3D%3D\u0026amp;lang=zh_CN\u0026amp;exportkey=A%2BaD1VoeZK%2BNcCdBAeTSRpU%3D\u0026amp;pass_ticket=ruwUaHgmNx%2FW6lI59EtPJWAVZNtV2JsX1zGoRFgjLCnzopLmGt361yB46zNl%2BcPs\u0026amp;wx_header=1\"\u003eref\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003ekafka client, 看看sarama,了解kafka客户端能获得哪些东西,server api暴露了哪些东西\u003c/li\u003e\n\u003cli\u003ekv db, 比如etcd的boltdb多读少写, lsm-tree的多写少读\u003c/li\u003e\n\u003cli\u003eetcd ,consul 的分布式共识\u003c/li\u003e\n\u003cli\u003e\u003c/li\u003e\n\u003c/ul\u003e","tags":["Todo"],"title":"TodoList","uri":"https://wymli.github.io/2021/04/a2todo-todo-list/","year":"2021"},{"content":"深入kafka 在此前的系列中,其实对于kafka集群和zk集群的区分很模糊,数据似乎有时是存在某个broker中的,又有时是存在zk中的\nkafka成员 kafka使用zk来维护集群成员的信息.\n","id":34,"section":"posts","summary":"\u003ch1 id=\"深入kafka\"\u003e深入kafka\u003c/h1\u003e\n\u003cp\u003e在此前的系列中,其实对于kafka集群和zk集群的区分很模糊,数据似乎有时是存在某个broker中的,又有时是存在zk中的\u003c/p\u003e\n\u003ch2 id=\"kafka成员\"\u003ekafka成员\u003c/h2\u003e\n\u003cp\u003ekafka使用zk来维护集群成员的信息.\u003c/p\u003e","tags":["Kafka"],"title":"[mq] kafka4 工作原理","uri":"https://wymli.github.io/2021/04/mq-kafka4-%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/","year":"2021"},{"content":"Intro 官方文档： https://zookeeper.apache.org/doc/r3.4.14/\nzookeeper是一种分布式协调服务(也就是说常称的注册中心),分布式应用正在运行的一组系统称为集群，而在集群中运行的每台机器被称为节点\n服务器在整个集群中，有三种角色，分别是\nLeader 处理写请求，事务调度和处理 Follower 处理读请求，转发写请求给leader，参与leader选举 Observer 同follower，但不参与leader选举 主从和主备\n主从： 主节点分配调度任务，从节点执行任务 主备： 主节点作为日常工作节点，当主节点宕机后，备份节点成为主节点 实际上，我们使用的是主从和主备的结合，从节点不仅会执行任务，也会选举成为主节点\n注意,采用主备模式的集群（比如kafka的某个主分区和备份分区），会有数据同步这个概念，即备份节点从主节点同步数据。\n但是zk中，写是下发到从节点的，但它们的写提交是类似的，都要等大部分节点完成写/同步后，才算写的完成\n这两者的区别，更像是主动和被动的区别，同步是从节点主动，而消息议案是主节点主动\nGuarantees Sequential Consistency - Updates from a client will be applied in the order that they were sent. Atomicity - Updates either succeed or fail. No partial results. Single System Image - A client will see the same view of the service regardless of the server that it connects to. Reliability - Once an update has been applied, it will persist from that time forward until a client overwrites the update. Timeliness - The clients view of the system is guaranteed to be up-to-date within a certain time bound. APIS zk 只支持7种操作，这里的node指的是znode\ncreate : creates a node at a location in the tree delete : deletes a node exists : tests if a node exists at a location get data : reads the data from a node set data : writes data to a node get children : retrieves a list of children of a node sync : waits for data to be propagated connection Clients connect to a single ZooKeeper server. The client maintains a TCP connection through which it\nsends requests, gets responses, gets watch events, sends heart beats. If the TCP connection to the server breaks, the client will connect to a different server.\nznode znode： zookeeper data node\nzk以类似目录的形式来组织数据，client要想找到想要的数据，需要先提供数据的路由地址（比如/app/1/p）, 和目录不同之处在于目录本身也能存数据，而不只是文件才能存数据\n好像比较，其他的注册中心可能采用键值的形式，而不是路由的形式\n小知识： gin的路由是基于radix数的\nznode结构 Znodes maintain a stat structure that includes version numbers for data changes, ACL changes, and timestamps, to allow cache validations and coordinated updates.\nEach time a znode\u0026rsquo;s data changes, the version number increases. For instance, whenever a client retrieves data it also receives the version of the data.\nACL: Each node has an Access Control List (ACL) that restricts who can do what.\n数据读 Read requests are serviced from the local replica of each server database.\nRequests that change the state of the service, write requests, are processed by an agreement protocol.\n数据写 As part of the agreement protocol all write requests from clients are forwarded to a single server, called the leader.\nThe rest of the ZooKeeper servers, called followers, receive message proposals from the leader and agree upon message delivery.\nfollower收到写请求-\u0026gt;follower转发给leader-\u0026gt;leader发送消息提案给follower-\u0026gt;follower返回ack，表示接收消息写\n数据更新 Updates are logged to disk for recoverability, and writes are serialized to disk before they are applied to the in-memory database.\nWAL : write ahead log,在写数据之前先写log，这里和数据库的区别是，数据是驻留在内存的，而log是在磁盘的\n顺序 zab要求满足如下的顺序（都要满足）\n全序（total order） If message a is delivered before message b by one server, then every server that delivers a and b delivers a before b. 这里的deliver message，可以理解为消息被client看见，即开始分发这个消息给client 因果序（causal order） If message a causally precedes message b and both messages are delivered, then a must be ordered before b. 因果序有两种：\nIf two messages,a and b, are sent by the same server and a is proposed before b,we say that a causally precedes b; 由同一个server发送导致的消息顺序 If a leader changes, any previously proposed messages causally precede messages proposed by the new leader. 由leader变更导致的消息顺序 原子广播Zab ref： https://www.datadoghq.com/pdf/zab.totally-ordered-broadcast-protocol.2008.pdf\nZab协议下的服务有两种状态\n广播 恢复 当一个新的服务开启，或leader宕机后，服务进入恢复状态，直到新的leader出现并且存在法定人数的follower与leader的状态同步，此后服务进入广播状态\n对于服务器，也同样具有这两种状态，当一个新的服务器进入集群时，首先进入恢复状态，直到与leader同步，然后进入广播状态（当新server加入时，虽然它自己是恢复状态，但整个服务仍是广播状态）\n写提交（write commit） 这是一种__两阶段提交__协议\na leader proposes a request, collects votes, and finally commits\nleader收到写请求后，将其作为消息议案（message proposal）广播给follower，follower在自己的in-memory database写这个消息后，返回ack给leader，当leader收到法定人数的ack后立马提交，而无需等待所有的follower的ack. 提交操作会广播commit消息给所有的follower，follower收到commit后，client就能从它那里读该消息了（当然，提交后client可以立即从leader那里读消息）\n但是commit是没有ack的，如果leader自己commit后立马宕机了，follower都不知道这个消息commit了怎么办？\n消息顺序性 Zab使用TCP协议，该协议本身就提供了一个FIFO通道（使用序号来排序），所以对端将会按发端发送的顺序接收消息\nzxid 每个被propose的消息都会被赋予一个单调递增的唯一id，称为zxid. 为了保证因果序，消息也会按照zxid进行排序\n恢复 a recovery procedure is necessary to elect a new leader and bring all servers to a correct state\n两个原则：\n当一个消息在一个服务器上可见（被commit），那么它就应该在所有服务器上可见 一个被跳过的消息应该维持其被跳过的状态 否则就会违背消息顺序性 当leader收到来自法定人数的follower的commit后，该消息就在leader身上commit了，然后准备向follower广播这个commit，这时，leader宕机了，只有部分follower收到了这个commit\n后续的leader被选举出来，follower首先会和leader同步状态，如果这个leader收到了那个消息的commit，那么其他follower应该提交这个消息，如果它没有收到，其他follower就应该取消对该消息的提交\n在实现上，这是借助zxid实现的，zxid的低32位是递增的uid，高32位是与epoch相关的uid，没选举一次leader就会一轮\n当上一次宕机的leader重新上线，它将作为follower，此时的leader将会检查follower的最进提交的消息的epoch，和自己的epoch里的最近提交的消息比对，并告诉follower删除那条提交\n","id":35,"section":"posts","summary":"\u003ch1 id=\"intro\"\u003eIntro\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e官方文档： \u003ca href=\"https://zookeeper.apache.org/doc/r3.4.14/\"\u003ehttps://zookeeper.apache.org/doc/r3.4.14/\u003c/a\u003e\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003ezookeeper是一种分布式协调服务(也就是说常称的注册中心),分布式应用正在运行的一组系统称为\u003cstrong\u003e集群\u003c/strong\u003e，而在集群中运行的每台机器被称为\u003cstrong\u003e节点\u003c/strong\u003e\u003c/p\u003e","tags":["zookeeper"],"title":"[zk] zk1 intro","uri":"https://wymli.github.io/2021/04/zk-zk1-intro/","year":"2021"},{"content":"kafka3 consumer [TOC]\n消费组 往群组里增加消费者是横向伸缩消费能力的主要方式\n消费组内的消费者可以订阅不同的topic,这意味着不是所有的消费者都能接收到某个topic的消息,而必须要订阅\n因此逻辑上消费者的查找关系是: 消费组\u0026ndash;\u0026gt;订阅了该消息的消费者们\u0026ndash;\u0026gt;消费者\n分区再均衡 由于我们可能动态的增加和缩减消费组内的消费者(因为一个消费者是一个进程,增加一个进程是理所当然的),所以,分区与消费者的对应关系需要变化\n在再均衡期间,消费者无法读取消息,会有短时间内的消息队列不可用\n由于分区消费offset是由消费者维护的,当由新的消费者接替时,将会丢失offset,这时需要去zk/broker同步offset,也会增加一些开销\n群组协调器 某个broker将会被指定为某个消费组的协调器,不同的消费组可以有不同的协调器.\n消费者将会往协调器发送心跳heartbeat,来维持消费者和消费组的从属关系以及和分区的对应(所有权)关系.\n消费组会在消费消息或提交偏移量时发送心跳,如果消费者较长时间未发送心跳,协调器就认为该消费者宕机,便触发一次再平衡\n分区分配过程 无论是再分配还是初始分配过程,都是一样的,针对给定的分区和消费者,均匀分配所有权关系\n该分配过程由消费组的群主承担,第一个加入消费组的消费者自动成为群主.群主从协调器那里获得群组成员列表和分区数,并给每个分区分配一个消费者.分配完毕后,群主将结果发送给协调器,协调器再将每个消费者的分配情况发送给消费者,消费者只能看见自己被分配的分区\n创建kafka消费者 创建消费者需要指定:\nbootstrap.servers,比如:\u0026ldquo;broker1:9092,broker2:9092\u0026rdquo; bootstrap.servers也就是broker-list,但不需要包含所有的broker,客户端会做一个搜索,搜出所有的broker,一般指定两个,防止其中一个宕机 group-id,即所属的消费组 反序列化器 订阅主题 consumer可以通过列表或正则的方式订阅主题\n注意: 同一个Group中的不同Consumer实例可以订阅不同的Topic\n即:订阅是消费者的行为,而不是消费组的行为\n轮询 kafka是pull类型的消息队列,需要消费者自身定期轮询broker\n轮询不只是包含消息拉取,还包含查找群组协调器并加入该组,接收分配的分区,以及后续的再平衡过程,以及心跳的发送\n消息提交和偏移量 kafka不会像其他__JMS__队列一样,需要消费者在消费成功后返回ack,这是因为偏移量offset是由消费者自己维护的.\njms指java message service,是一种消息队列api规范\n为了保证分区再平衡或消费者宕机后的消息偏移量丢失,消费者仍然需要以一种方式去向消息队列提交偏移量\n具体操作是,消费者往一个叫__\u0026quot;_consumer_offset\u0026quot;__的特殊主题上发送消息,消息包含该消费者消费分区的偏移量\n自动提交 消费者可以设置自己的提交方式为自动提交,默认下,每过5s,消费者就会把当前偏移量提交,间隔可以由某个参数设置,但是注意,提交操作是在轮询操作中的,而不是真正的定时任务,所以,提交间隔可能大于设置的参数.\n自动提交一般以配置文件的方式设置\n但显然,提交的offset总是要落后于当前offset的,再平衡后,消息将会被重复处理\n手动同步提交 调用consumer.commitSync()来提交当前poll()返回的最新的offset\n手动异步提交 同步提交会阻塞进程,可以使用consumer.commitAsync()来避免对程序吞吐量的降低\n错误处理 我们在poll_loop里面,将会使用异步的提交,但是如果发生错误要退出进程了,将会在退出前使用同步提交同步一次offset\n再均衡回调 当消费者订阅一个主题时,允许其传入一个再均衡处理器的回调类 ,该处理器需要实现两个函数\nonPartitionsAssigned onPartitionsRevoked 当由于新消费者加入或旧消费者退出导致的再平衡时,该处理器将会被执行.一般的,我们借助这个处理器来提交当前处理的offset\n在go中,其实可以定义两个接口,一个实现onPartitionsAssigned,一个实现onPartitionsRevoked,然后传入的时候,参数形式是interface{},内部再断言一下就可以了\n可以参考rpcx的插件开发,它会将所有的插件无差别的注册在一起,以interface{}存储,然后使用的时候,我们在一个特定的地方需要调用一个特定的插件,此时便遍历所有插件断言能否转成特定的插件\n流指针改变 我们说消息队列是一种伪流,因为我们仍然可以操作流指针,使之回退或前进,相当于文件流指针的用法,通过seek方法改变当前读取位置\n优雅退出 我们可能希望能在其他线程关闭所有的或一些消费者,在go语言里这是简单的,只需要一个经典的for{select{}}即可\n对于信号,我们也要捕捉,因为在关闭前,我们需要做一些收尾工作,比如首先停止poll,但是对正在处理的消息,我们仍然要等它处理完成,然后提交offset.最后退出\n独立消费者 有时候,我们可能不想让消费者加入某个消费组,而只是让他独立存在,这时候我们可以手动分配分区\n前面我们订阅分区是通过consumer.subscribe(\u0026quot;topic\u0026quot; , rebalanceHandler),消费组的id是在创建consumer时指定的.\n手动分配分区时,首先去查询某个topic的所有分区列表partitionInfos = consumer.partitionsFor(\u0026quot;topic\u0026quot;),然后遍历列表,组合成assign api要求的数据形式,最后调用assign.\n注意consumer.assign(partitions)中,这个partitions是类似于[]TopicPartition一样的数组,TopicPartition是{topic,partition}是结构,因此,这是为了能订阅不同主题的不同partition而设计的.\n","id":36,"section":"posts","summary":"\u003ch1 id=\"kafka3-consumer\"\u003ekafka3 consumer\u003c/h1\u003e\n\u003cp\u003e[TOC]\u003c/p\u003e\n\u003ch2 id=\"消费组\"\u003e消费组\u003c/h2\u003e\n\u003cp\u003e往群组里增加消费者是横向伸缩消费能力的主要方式\u003c/p\u003e\n\u003cp\u003e消费组内的消费者可以订阅不同的topic,这意味着不是所有的消费者都能接收到某个topic的消息,而必须要订阅\u003c/p\u003e","tags":["Kafka"],"title":"[mq] kafka3 consumer","uri":"https://wymli.github.io/2021/04/mq-kafka3-consumer/","year":"2021"},{"content":"安装kafka 我们知道apt-get install只能安装某个版本的软件,这取决于在软件源那里的最新软件版本,你可以使用apt-get search搜索看有没有自己想要的版本\n一般的,为了安装特定的版本,或自己没有root权限,我们需要自己手动下载安装包编译,或解压\n[TOC]\n安装zookeeper 首先安装zk\n解压 对于.tar.gz格式的压缩包,使用tar -zxvf 轻松解压\n对于.zip格式的压缩包,需要使用unzip\n默认安装目录 一般的,程序会被安装到/usr/local/\n所以我们执行如下的命令:\ntar -zxf zookeeper-3.4.6.tar.gz mv zookeeper-3.4.6 /usr/local/zookeeper usr目录,也许可以理解成user shared resource,总之就是只读资源目录的意思\n如果是配置文件,一般放在/etc目录\neditable text configuration 如果是日志文件或数据文件,一般放在/var目录\nvariable,可变数据,即需要常更新写入的日志 创建配置 可以使用__here document__的用法,即使用cat \u0026gt; file \u0026lt;\u0026lt; EOF来在终端写入一个多行文本\ncat \u0026gt; /usr/local/zookeeper/conf/zoo.cfg \u0026lt;\u0026lt; EOF \u0026gt; tickTime=2000 \u0026gt; dataDir=/var/lib/zookeeper \u0026gt; clientPort=2181 \u0026gt; EOF 配置说明 zookeeper是一个分布式数据库,基于某种一致性协议进行节点同步\n当节点个数有一半不可提供服务时,zookeeper就不对外提供服务(即如果有多数节点能提供服务,zookeeper就能提供服务)\n因此,一般建议配置奇数个节点,比如3个节点,则允许坏1台;5个节点,允许坏2台;一般不建议大于7,因为会增加一致性协议同步的负担 TickTime 服务器会主动的轮询自身集群的状态,这个间隔就是ticktime,一切的其他与时间有关的任务,比如从节点与主节点最大的不同步时间,比如从节点和主节点初始化连接的超时时间\n这样好处是,在底层实现上,我们的确是以一定的时间间隔来轮询的.\n通信端口与选举端口 对内,zk集群内节点会暴露两个端口,一个是用于通信的端口,一个是用于leader选举的端口\n对外,整个zk暴露一个clientPort,用于客户端的连接\nPaxos\u0026amp;ZAB协议 paxos是Lesile Lamport于1990年提出的基于消息传递且具有高容错特性的一致性算法\nzookeeper的一致性算法并没有完全采用paxos,而是使用了一种称为zookeeper atomic broadcast(ZAB,zookeeper原子消息广播协议)\nPaxos是通用算法,ZAB是非通用的专用于zk的一致性算法\nleader\u0026amp;follower\u0026amp;observer 在zookeeper中,节点有三种类型:\nleader follower observer 其中,leader和follower称为公民,用于计算存活节点;follower和observer称为learner.\nleader只有一个,为客户端和follower提供读写服务.leader也可以拒绝客户端的连接,而只向follower提供写服务.\nfollower只提供读服务,对于写请求,会统一转发到leader,由leader进行统一的调度\n对于写操作,leader接收到来自follower的写请求后,向所有follower转发写请求,当有过半follower返回ack后,则在leader服务器上提交写请求,代表写成功. 对于那些在leader提出但未提交的写事务,则会被丢弃\n以上只是简略的一个介绍,其目的是知道这些名词,详细介绍应该去看书,或者zk系列文章\n注意zookeeper需要设置三个端口,分别用于接收客户端请求clientPort,节点间通信peerPort和节点间选举leaderPort.\n安装Broker 解压后移动到/usr/local即可(因为/usr/local是在path的)\n当然,kafka还要求设置log目录和JAVA_HOME环境变量\ntar -zxf kafka_2.11-0.9.0.1.tgz mv kafka_2.11-0.9.0.1 /usr/local/kafka mkdir /tmp/kafka-logs export JAVA_HOME=/usr/java/jdk1.8.0_51 启动脚本启动服务器:\n/usr/local/kafka/bin/kafka-server-start.sh -daemon /usr/local/kafka/config/server.properties 创建topic并打印信息\nreplication-factor=1 表示复制因子为1,即每个partition只有一个副本(这个副本,不是指额外的拷贝,而是算自身的,所以如果你想一个leader,一个follower,则应该设置复制因子为2)\n--zookeeper localhost:2181 首先连接到zk,然后指定主题名--topic test,然后指定动作:create或describe\n/usr/local/kafka/bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic test --replication-factor 1 --partitions 1 \u0026gt; Created topic \u0026quot;test\u0026quot;. /usr/local/kafka/bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test 生产者向对应topci生产消息\n这里Test Message 1\\nTest Message 2是自己的输入,使用ctrl-D输入EOF 这里:9092是kafka默认监听的端口,因此生产者其实不需要指定zk /usr/local/kafka/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test Test Message 1 Test Message 2 ^D 消费者从对应topic消费消息\n/usr/local/kafka/bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning Test Message 1 Test Message 2 ^C Consumed 2 messages 很奇怪,为什么一会是连接zk,一会是连接kafka呢?\n","id":37,"section":"posts","summary":"\u003ch1 id=\"安装kafka\"\u003e安装kafka\u003c/h1\u003e\n\u003cp\u003e我们知道apt-get install只能安装某个版本的软件,这取决于在软件源那里的最新软件版本,你可以使用apt-get search搜索看有没有自己想要的版本\u003c/p\u003e","tags":["Kafka"],"title":"[mq] kafka1.5 install","uri":"https://wymli.github.io/2021/04/mq-kafka1.5-install/","year":"2021"},{"content":"kafka producer 参考kafka技术内幕:图文详解kafka源码设计和实现\n本节主要讲关于kafka的生产者相关的事情,比如同步与异步的api调用,底层的网络通信框架(比如rpc)\n回顾 在kafka1 intro中,我们知道了典型的kafka架构,我们有producer,broker,consumer,connector(目前我们对connecter还基本没有什么了解)\nbroker就是所谓的消息中心,它是分布式的,并且是partition相关的分布式.\n一个topic有多个partition,每个partition仅与一个消费组中的消费者关联,topic将会在多个broker中存在,作为备份,那么就会有主从之分,但是主从区分的粒度不是topic,而是partition.这样可以保证broker的负载均衡,因为消费者只会读写主partition,从partition将会作为另类的消费者去读写主partition来同步.\n同步与异步api 同步api将会造成阻塞,而异步api立即返回.\n这里我们主要关注设计,异步api需要传入回调函数,用于在broker返回ack后执行,显然,这需要新开一个线程,监视网络入包.\n无论是同步还是异步api,其下一层应该都调用同样api,事实上,kafka的producer.send()方法会返回一个future,如果调用future.get(),那么自然阻塞.\n注意异步api要设计 传入回调函数\n分区路由 对于给定key的消息,我们先对key散列,然后对分区数取模,这样就能保证同一个key的消息能发送到同一个partition\n对于未指定key的消息,我们采用轮询partition的方法\n这里的轮询指round-robin,也就是顺序循环,说成轮询其实不太好\n显然还可以有更多的路由算法,比如如果分区数与消费者数不匹配,那么显然有一些分区的负担低一点,这时候可以更多的往该分区发送消息(基于加权的路由,可以参考nginx的加权平滑路由算法)\n为什么要增加分区路由,而不增加一个负载均衡器,producer将信息发往负载均衡器,然后由负载均衡器进行消息的路由呢?\n主要是这因为:\n一台负载均衡器负责所有producer的转发路由,负担较重 从producer到load balancer,再从load balancer到broker,是位于一个网络中的,于是造成了两倍的网络开销 消息缓冲 kafka设计了消息缓冲器RecordAccumulater,当producer调用send方法后,首先会向accumulater追加消息,如果收集器满了,就唤醒sender线程,异步发送消息\n记录(消息)是按批发送的,目的也是为了减少io次数,网络开销\n在kafka的设计中,accumulater是一个双端链表,每个链表节点是一个固定长度的数组,代表一批. 显然,有多少个分区,就有多少个链表.\n发送线程 一种朴素的方法就是迭代accumulater的所有链表,直接往分区的主副结点发送.\n另一种较高效的方法是先将分区按其主副结点分组(即不同的分区的leader可能在同一个broker),那么这时候将这两个分区打包发送,又减少了网络开销\n我想到的一种方式就是accumulater维护一个map\u0026lt;brokerId , [ ]accumulater_partition\u0026gt;,记录节点到分区的映射,sender线程只需要遍历这个map,即可完成对partition的分组\n在kafka的设计中,sender线程并不真正发送数据,这是因为网络连接需要更多的封装和抽象,sender线程仅准备好一次连接发送的所有数据\n网络连接 NetworkClient对象提供了对客户端和服务端之间通信的封装,包括连接建立,发送请求,读取响应等.\n为了保障服务器性能,在网络连接对象中,我们限制了对同一broker的连接数为1,即当上一次send还未收到ack时,这次的对同一broker的connect将会被禁止\n从源码阅读上看,清晰度完全不如go啊\n","id":38,"section":"posts","summary":"\u003ch1 id=\"kafka-producer\"\u003ekafka producer\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e参考kafka技术内幕:图文详解kafka源码设计和实现\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e本节主要讲关于kafka的生产者相关的事情,比如同步与异步的api调用,底层的网络通信框架(比如rpc)\u003c/p\u003e","tags":["Kafka"],"title":"[mq] kafka2 producer","uri":"https://wymli.github.io/2021/03/mq-kafka2-producer/","year":"2021"},{"content":"虚拟内存virtual memory 什么是虚拟内存,应该不用多言.本质就是一个逻辑的虚拟地址空间,这些地址空间中,有的地址真正的对应到了物理内存的地址,有的地址却是对应到了磁盘上的地址(通过swap交换换页进入物理内存).\n对进程来说,虚拟内存屏蔽了底层的物理内存和外存,为进程提供简洁易用的接口.\n进程持有的虚拟地址会经过内存管理单元(mmu,memory management unit)转变为物理地址,然后访问物理内存.\n主存的随机访问速度是磁盘的100K倍,但是顺序访问速度却只是磁盘的10倍(因此某些服务比如kafka,redis在持久化时,会采用aof文件顺序写)\n虚拟页 虚拟内存以页作为基本组织单位,一般一个页4KB.\n页有三种状态:\n未分配 未缓存 已缓存 显然,其中未缓存和已缓存都代表已分配.未缓存指的是该虚拟内存指向了磁盘上的地址,尚未交换到物理内存,而已缓存指的是已加载到物理内存\n当用户访问未被缓存的物理页时,触发缺页中断,于是被访问页被加载到物理内存上\n页表存储了虚拟内存到物理内存的映射,每个PCB都有一个页表指针,即每个进程都拥有一个自己的页表\n交换区 磁盘上不是所有空间都能被虚拟地址空间映射的,我们专门在磁盘上划分了一个交换区.这里的数据可以被页面调度或交换\n页面调度和交换 页面调度指的是物理内存上的单个物理页是否和磁盘上交换区的物理页交换(页面swap)\n交换一般指整个进程的交换,是一种进程状态,表示整个进程在内存中的映像都换到了外存\n不过一般来说,一次页面调度也是一次页的交换\n无图无真相 cat /proc/cpuinfo address sizes : 39 bits physical, 48 bits virtual liwm29@lwm:/mnt/c/WINDOWS/system32$ free total used free shared buff/cache available Mem: 6399360 72100 6284536 68 42724 6180340 Swap: 2097152 0 2097152 liwm29@lwm:/mnt/c/WINDOWS/system32$ cat /proc/meminfo MemTotal: 6399360 kB MemFree: 6253264 kB MemAvailable: 6164212 kB Buffers: 9564 kB Cached: 49864 kB SwapCached: 0 kB Active: 23280 kB Inactive: 38232 kB Active(anon): 2156 kB Inactive(anon): 8 kB Active(file): 21124 kB Inactive(file): 38224 kB Unevictable: 0 kB Mlocked: 0 kB SwapTotal: 2097152 kB SwapFree: 2097152 kB Dirty: 252 kB Writeback: 0 kB AnonPages: 2056 kB Mapped: 4092 kB Shmem: 68 kB Slab: 27232 kB SReclaimable: 13536 kB SUnreclaim: 13696 kB KernelStack: 1808 kB PageTables: 168 kB NFS_Unstable: 0 kB Bounce: 0 kB WritebackTmp: 0 kB CommitLimit: 5296832 kB Committed_AS: 7256 kB VmallocTotal: 34359738367 kB VmallocUsed: 0 kB VmallocChunk: 0 kB Percpu: 1888 kB AnonHugePages: 0 kB ShmemHugePages: 0 kB ShmemPmdMapped: 0 kB HugePages_Total: 0 HugePages_Free: 0 HugePages_Rsvd: 0 HugePages_Surp: 0 Hugepagesize: 2048 kB Hugetlb: 0 kB DirectMap4k: 17408 kB DirectMap2M: 3446784 kB DirectMap1G: 4194304 kB 共享内存 我们知道线程(pthread_create)之间是共享全局变量的,而进程(fork)之间是不共享的,这是为什么呢?\n其内部就是虚拟内存有关,当调用fork后,子进程会copy父进程的页表,所以此时它们指向了同样的物理内存空间,如果使用clone(),使用CLONE_VM 参数,那么它们就真的共享同一个内存空间了,否则的化,会触发写时复制\npage cache 虚拟内存将主存看成是磁盘的缓存,所以叫cache\nDRAM与SRAM dram指内存,sram指cpu与内存之间的高速缓存,比如L1 cache,L2 cache\u0026hellip;\nPage cache \u0026amp; Disk buffer 首先是cache和buffer的区别\ncache是缓存,加快读的速率 buffer是缓冲,主要是为了减少io次数,进行批量读和批量写 In computing, a page cache, sometimes also called disk cache,[1] is a transparent cache for the pages originating from a secondary storage device such as a hard disk drive (HDD) or a solid-state drive (SSD). The operating system keeps a page cache in otherwise unused portions of the main memory (RAM), resulting in quicker access to the contents of cached pages and overall performance improvements. A page cache is implemented in kernels with the paging memory management, and is mostly transparent to applications.\nUsually, all physical memory not directly allocated to applications is used by the operating system for the page cache. Since the memory would otherwise be idle and is easily reclaimed when applications request it, there is generally no associated performance penalty and the operating system might even report such memory as \u0026ldquo;free\u0026rdquo; or \u0026ldquo;available\u0026rdquo;.\nThe disk buffer is physically distinct from and is used differently from the page cache typically kept by the operating system in the computer\u0026rsquo;s main memory. The disk buffer is controlled by the microcontroller in the hard disk drive, and the page cache is controlled by the computer to which that disk is attached. The disk buffer is usually quite small, ranging between 8 and 256 MiB, and the page cache is generally all unused main memory. While data in the page cache is reused multiple times, the data in the disk buffer is rarely reused\n也就是说,对于主存没有直接分配的内存,那么就都是作为page cache存在(注意区分malloc和read)\n也就是说,主存有两个功能,一个是作为进程的存储空间(malloc),一个是作为磁盘的page cache\n所谓的那些零拷贝技术里面常讲的内核缓冲区,其实就是page cache\n","id":39,"section":"posts","summary":"\u003ch1 id=\"虚拟内存virtual-memory\"\u003e虚拟内存virtual memory\u003c/h1\u003e\n\u003cp\u003e什么是虚拟内存,应该不用多言.本质就是一个逻辑的虚拟地址空间,这些地址空间中,有的地址真正的对应到了物理内存的地址,有的地址却是对应到了磁盘上的地址(通过swap交换换页进入物理内存).\u003c/p\u003e","tags":null,"title":"[sys] 虚拟内存与缓存缓冲","uri":"https://wymli.github.io/2021/03/sys-virtmempage-cachebuffer-cache/","year":"2021"},{"content":"kafka1 intro 部分参考\nkafka技术内幕:图文详解kafka源码设计和实现 kafka权威指南 https://zhuanlan.zhihu.com/p/68052232 kafka是一种流式数据处理平台(消息队列的进阶版,即除了完成的消息的转发外,还可以处理消息)\n消息队列的三大功能:\n异步 解耦 流量削峰 kafka作为流式数据处理平台的三大功能\n消息队列(消息系统) 数据存储(容错,对等待转发的数据备份到持久化内存) 实时流式处理数据 其中最重要的,应该是解耦这个功能,因为无论是异步还是削峰,一个进程内的并发队列都能做到,每必要独立为一个分布式消息系统服务器.只有解耦,独立成了一个服务器,才能方便的给不同的后端提供服务,比如传统的消费者,比如流量监控程序,比如机器学习数据采集器等等\n这里,我个人倾向于将producer视作前端,broker视作中端,consumer视作后端\n原先的架构,监控程序或消费程序,直接与数据生产者打交道,当有各式各样不同的生产者时,又有各式各样不同的消费者时,对应关系将会错综复杂\n于是我们在生产者和消费者之间增加一个用于解耦泛化订阅关系的信息队列,所有的消息统一发忘消息队列,所有的监控程序统一从消息队列取数据(通过订阅不同的topic)\n消息系统 两种常见模型\n点对点 发布订阅topic kafka使用消费组(consumer group)的概念,将其合并(消费组之间广播,消费组内部点对点)\n注意: 消费组是用于负载均衡的,指的是同一个消费组内的消费者是会接收到同一topic的不同消息的,即消息队列虽然会将消息广播给所有订阅它的消费组,但不会将消息广播给同一消费组的所有消费者,而是发送给消费组内的一个消费者(也就是负载均衡),至于发送给哪个消费者,与分区有关,详见后文\n存储系统 如果收到的消息只是存在于内存中,那么断电后会造成消息丢失.因此,对于还未持久化的数据,不能认定为消息成功被消息队列接收.\n为了保证可靠存储,消息生产者的生产请求应该是停等协议,必须收到消息队列已持久化消息的信息后(ACK),才认为生产成功. 因此生产过程是阻塞的.\n流式处理 对于流式数据平台,仅仅有消息的发布订阅,持久化存储备份是不够的,还要有实时流式处理功能.\n所谓流式处理,可以参照reactiveX这个库,它是一种类似于函数式编程里面常见的处理过程,比如映射,聚合,连接等等\n在实际处理中,由于是网络通信,还可能面临乱序数据等问题\nAPI kafka中有五个核心概念:\nproducer consumer broker connector,用于连接数据库,持久化备份,或者读取静态数据进行流处理 processor,进行流处理 kafka实现: 基本概念 分区partition kafka是一个分布式的消息队列,kafka集群由多个消息代理服务器(broker server)组成.\n每个消息都有一个topic,表示消息的类别.每个topic会有多个订阅它的消费组,这个消费组会有多个消费者.当生产者发布消息后,所有的消费组都会收到消息,但是只会发送给消费组内的一个消费者.\nkafka集群为每个topic都维护了一个分布式的分区日志文件(partition),物理意义上,主题可以看作分区的日志文件(partitioned log),这时因为生产者生产的消息会首先作为日志持久化到分区上(类似于redis的append-only file)(事实上,对于这种流式消息的持久化,也只能使用日志形式的追加).每个分区都是一个有序的,不可变的记录序列.分区中的每个消息都会按照到达的时间顺序被分配一个单调递增的偏移量offset,这个偏移量用于定位当前分区的一条消息(你可以想象成数组,偏移量就是下标)\n当消费者来取消息时,由消费者自己维护消息消费的偏移量\n在kafka的设计中,每个topic会有多个分区,每个分区唯一匹配该topic对应的各个消费组中的一个消费者. 不同分区之间的偏移量从0开始,独立互不影响.发布到topic的每条消息都包含key-value-timestamp,到达指定分区后都会被分配一个自增的偏移量,并持久化到分区日志文件.\n每个topic的每个分区都会有副本存在,每个副本都独立位于不同的broker,并且其中一个副本是leader,其他的副本是follower\n写数据只往leader写,然后主从更新,这是常见的读写分离优化. 往往,同一topic的不同partition的leader位于不同的机器上\n因此,一般的,会将分区数设置为消费组内的消费者数,这样一个消费者唯一对应一个分区.如果以随机策略,那么生产者生产了该topic的消息,随机放在一个分区,然后消费组内与该分区对应的消费者去消费该分区,视为该消费组的消费.\n当分区数与消费者数不等时,要满足一个分区只能对应一个消费者.即当分区数较多时,消费者可以对应多个分区,当分区数较少时,消费组内必然有消费者无对应分区\n如果多个客户端都期望收到所有的消息,那么它们应该属于不同的消费组,并订阅该topic\n消息有序性 只有单个分区内才保证消息的有序性,这是指消费该分区的消费者读取处理消息的顺序将总是和分区内的顺序是一致的\n不同分区之间的消息有序性不保证,这是指某个消息虽然后到达某个分区,但却先被对应的消费者消费\n如果想保证某些信息的强有序性,我们需要给该系列消息设置相同的键,使之映射到相同的分区. 或者更极端的,仅设置一个分区.\n磁盘组织 partition就是一个一个的文件夹,每个partition的文件夹下面会有多个segment文件,每个segment文件包含三个文件\n.index文件 .log文件 .timeindex文件 前面我们说了,message是以partition log的方式作为aof持久化的,所以消息其实存在.log文件中,,index文件和.timeindex文件是顾名思义的,都是索引文件\nTODO: 具体的方式涉及持久化那章,目前还没找到完整的书,待更\n生产模式 同一topic的不同partition之间是一层负载均衡,同一消费组的消费者之间也是一层负载均衡\n对于生产者,它需要决定将消息写到对应topic的哪个分区,比如可以使用随机,轮询,平滑加权平均,一致性hash等手段(也就是rpc框架里的路由算法,也就是负载均衡算法). 当它确定了分区后,便去查询该分区对应的leader所属的broker,因为只有leader可写.\n前面说过,生产者生产消息是一个阻塞的过程,需要收到消息队列(也就是broker)的ack. 实际上,有三种生产模式\n按照如下图的工作流程:\n生产者可以在2后直接返回(完全异步) 生产者可以在3后直接返回(阻塞,主持久化) 生产者可以在6后直接返回(阻塞,主从同步持久化) 消费模型 消息的消费模式有两种:\n推送push 拉取pull 如果使用推送模式,则会增加broker消息代理服务器的负担,这是因为服务器应该为每个消息都记录消费状态,只要当收到消费者返回的ACK后,服务器才能有信心的将消息状态置为已消费,而在broker中,消息是大量的,维护这些状态的负担是较大的.此外,不同消费者消费的进度是不同的,需要额外存储各个消费者的进度.\n简单来看,broker需要记录:\n消息状态,是否已消费(比如,是否已被所有订阅的消费组消费) 不同消费者的消费进度(offset) 不同消费者的消费速率和broker的推送速率要对等 于是,Kafka采用拉取模型,有消费者自己记录消费状态,此时,消息是无状态的,broker不需要记录消息是否被处理过(但为了方便,其实还是会记录,这里只是说不记录也不影响主要功能).每个消费者独立且顺序的读取与自己相对应的那些分区的消息(典型情况下,分区与消费者是一对一的)\n此时,由消费者自己维护的消息状态,其实是一个指针或偏移量offset,记录自己下一个要消费的位置.生产者最新写入的消息对消费者是不可见的,必须备份后才会更新watermark(最高水位),watermark存在的意义即是限制消费者的消费(颇有点len和cap的感觉).\n简单来看,customer需要记录:\n消费进度offset 这里的备份详见后文的副本与容灾,简单来说就是一个消息只有被所有从副本同步后(称为消息的提交),才能够被消费者看见从而消费,表现上就是watermark的增加\n事实上,也可能同时将offset记录在zk上,以确保消费者的宕机不会丢失消费记录位置\nkafka不会像有些消息队列一样,当消息被所有消费组消费后,就立马删掉消息.而是会将生产者发布的所有消息保存在kafka集群,无论消费者是否已经消费.用户需要设置保留时间来清理过期数据.\n这样的一个好处是,消费者可以通过更改自己的offset来消费以前的消息.(比如消费者逻辑出错,导致的回滚)\n分布式模型 这里的分布式模型,也就是主从模型. 一个topic的不同partition在不同的broker上都将维护一个同样的副本.其中一个节点作为leader(主副本),其他节点作为follower(从副本).读写操作都只会打到leader上,当leader故障时,某个follower晋升为leader.\n不是读写分离,而是读写都施加到leader上.\n一个topic不同的partition在同一台broker上,有的是leader,有的是follower,有效减轻了一台broker的负担\n单个broker可以处理数千个分区和每秒百万级别的消息量\n分区路由 生产者需要自己决定将消息发送到哪个分区,然后再去寻找该分区的leader所在的broker的ip\n当消息没有键时,将采用轮询的方式;当消息有键时,将通过某种手段将相同的键发到相同的分区(很显然,一种hash方法)\n每个broker将会保存一份关于主题分区leader的metadata(元数据),这样就不需要一个统一的服务注册中心了. 生产者在生产消息之前,首先向任意一个broker申请元数据,以此确定每条消息的目的地\n这里似乎表述有误,虽然原文说是每个broker维护一份metadata,但是其他地方又说是zookeeper作为统一的注册中心维护一份metadata,我个人倾向于是zk维护,代价低\n副本与容错 不同分区的主副本应该均匀地分配到各个服务器上,在主从同步上,从副本同步消息的过程和消费者消费消息的过程是一致的,只不过从副本会将消息写到自己的分区日志文件.\n节点存活 节点存活必须满足两个条件:\n节点与zookeeper保持会话 节点作为备份副本时,其备份进度不能落后主副本太多 此时,称其状态为in-sync,这些节点的集合为ISR(in-sync-replicas).\n如果一个副本挂掉,没有响应或备份进度落后太多,那么主副本就会将其从ISR中移出,直到该从从副本赶上备份进度\n消息提交 一个消息只有被ISR中的所有broker都持久化到本地的分区日志文件后,才被认为消息提交.只有消息被提交后,才能被消费者消费.如此而来,对消费者来说,消息是永不丢失的.\n如果新生产的消息能立即被消费者看见,那么如果主副本宕机了,这些消息到底有没有被成功消费呢?如果没有,就需要生产者重新生产一份,这增加了很多额外的成本.不如直接设计成只有消息提交了才算生产成功\n优化技术 零拷贝技术 显然,消息已经被持久化到了磁盘上,从磁盘上读取文件发送到消费者处,需要使用send_file,避免从内核态到用户态的拷贝与切换.\n批量生产 在某些实时性要求不强(实际上,超时时间是极短)的任务中,生产者可以先尝试在内存中收集足够的数据,然后在一次请求中一次性发送一批消息(并会设置一个超时时间)\n比如: 消息大小达到64B,就立刻发送,否则100ms后也立刻发送\n批量消费 消费者理所当然的也可以一次接收一批数据,但是如果partition中消息数量不够呢?\n消费者需要不断轮询broker(这时拉取式的缺点),解决方法是允许拉取请求是阻塞式,长轮询的,直到有足够的一批数据.\n为什么选择kafka 支持消费组的概念,一个消息只会被一个消费组消费一次 partition的概念,并发度较高 消息默认持久化,可消费历史消息 可伸缩性,轻松拓展broker数量 使用场景 用户行为跟踪 前端会将用户的行为,比如页面点击量等,作为消息发送到消息中心 传统的传递业务消息 度量指标 也就是监控,收集系统度量指标 提交日志 将数据库的更新发布到kafka上,应用程序订阅特定topic来实时同步 流处理 下一章: kafka2 生产者\n","id":40,"section":"posts","summary":"\u003ch1 id=\"kafka1-intro\"\u003ekafka1 intro\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e部分参考\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003ekafka技术内幕:图文详解kafka源码设计和实现\u003c/li\u003e\n\u003cli\u003ekafka权威指南\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/68052232\"\u003ehttps://zhuanlan.zhihu.com/p/68052232\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\u003c/blockquote\u003e\n\u003cp\u003ekafka是一种流式数据处理平台(消息队列的进阶版,即除了完成的消息的转发外,还可以处理消息)\u003c/p\u003e","tags":["Kafka"],"title":"[mq] kafka1 intro","uri":"https://wymli.github.io/2021/03/mq-kafka1-intro/","year":"2021"},{"content":"荐读 unix domain sockets vs. internet sockets\n简单说来,就是internet socket(使用AF_INET地址族),即使是dial本机localhost来通信,其也会经历一个完整的网络流程(虽然是通过lo网卡),也会收到syn,ack包,只是碰巧在解析的过程中,机器发现了这个包是要路由到本机的,于是借助lo网卡回来,本质仍然是一种尽力交付\n但是unix domain socket不同,它是专用于做本机ipc的,是一种可信交付,它直接将数据写到recv socket 的buffer,而不需要header,checksum这些东西\n","id":41,"section":"posts","summary":"\u003cp\u003e荐读 \u003ca href=\"https://lists.freebsd.org/pipermail/freebsd-performance/2005-February/001143.html\"\u003eunix domain sockets vs. internet sockets\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e简单说来,就是internet socket(使用AF_INET地址族),即使是dial本机localhost来通信,其也会经历一个完整的网络流程(虽然是通过lo网卡),也会收到syn,ack包,只是碰巧在解析的过程中,机器发现了这个包是要路由到本机的,于是借助lo网卡回来,本质仍然是一种尽力交付\u003c/p\u003e","tags":["sys","socket"],"title":"[sys] unix domain socket","uri":"https://wymli.github.io/2021/03/sys-unix-domain-socket/","year":"2021"},{"content":"列举我心目中的go的优点 实现开源,源代码可以很方便的通过代码跳转去追踪,而不像c/c++都是链接库,或者只能追踪到头文件 现代的包管理go get/go mod,类似pip一样方便的包安装,但是也有很多不足,经常被人诟病 但就我个人使用上,感觉还是比较方便 类,结构与方法分离. 这在阅读源代码时很方便清爽,不必被各种inline函数搞得眼花缭乱 虽然go严格并没有类的概念 方便的方法函数拓展,只需要新写一个方法即可,不需要改动任何原来的代码 简洁的语法,不必把时间花费在底层理解上,但这也导致了无法极度的优化,不过相信大多数程序员都没有那么强,仍然利大于弊,不同的语言用来解决不同领域的问题 go的文档是直接放在一页的,直接ctrf-f搜索,很方便 待更 ","id":42,"section":"posts","summary":"\u003ch1 id=\"列举我心目中的go的优点\"\u003e列举我心目中的go的优点\u003c/h1\u003e\n\u003col\u003e\n\u003cli\u003e实现开源,源代码可以很方便的通过代码跳转去追踪,而不像c/c++都是链接库,或者只能追踪到头文件\u003c/li\u003e\n\u003cli\u003e现代的包管理go get/go mod,类似pip一样方便的包安装,但是也有很多不足,经常被人诟病\n\u003col\u003e\n\u003cli\u003e但就我个人使用上,感觉还是比较方便\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e类,结构与方法分离. 这在阅读源代码时很方便清爽,不必被各种inline函数搞得眼花缭乱\n\u003col\u003e\n\u003cli\u003e虽然go严格并没有类的概念\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e方便的方法函数拓展,只需要新写一个方法即可,不需要改动任何原来的代码\u003c/li\u003e\n\u003cli\u003e简洁的语法,不必把时间花费在底层理解上,但这也导致了无法极度的优化,不过相信大多数程序员都没有那么强,仍然利大于弊,不同的语言用来解决不同领域的问题\u003c/li\u003e\n\u003cli\u003ego的文档是直接放在一页的,直接ctrf-f搜索,很方便\u003c/li\u003e\n\u003cli\u003e待更\u003c/li\u003e\n\u003c/ol\u003e","tags":["Golang"],"title":"[Other] Go优点","uri":"https://wymli.github.io/2021/03/other-go%E4%BC%98%E7%82%B9/","year":"2021"},{"content":"字节二面 算法题: 二叉树中的最长距离 又拉跨了,太久没做题了,做了很久 并发和并行的区别 讲讲go的协程调度 GMP模型,balabala讲一堆,提到了netpoller,触发linux io复用剧情 讲到了steal机制,面试官问我为什么在全局队列未空的时候要去steal呢? 回答,应该不会吧,毕竟其他p的g可能不在一个核上,会增加cahce缺失率 讲讲linux的io复用 select/poll/epoll select和epoll的区别 说了些常见的,比如select用链表不限制fd个数,但是触发后要遍历所有fd,epoll只需要遍历已经激活的fd,数组的前n个 似乎不是面试官想要的,让我回去再看看 提到epoll只返回激活的fd的个数,问我怎么设计这个数据结构 其实没搞懂想问什么,于是我balabal扯了一堆 讲讲docker 一种linux容器 虚拟化,轻量级,隔离 dockerfile可以很方便的构建容器镜像 讲讲TCP的分包 tcp是面向流的协议 基于长度 基于分隔符 分隔符和内容冲突了怎么办? 转义 这里可以参考http协议,使用\\r\\n来分隔,对于body,会使用base64编码转义成文本字符,header和body之间有两个\\r\\n来区分 配对 比如json,xml这种,但显然面临注入的风险,也要转义 定长 对于简单的报文,直接定长即可 看我实验室的经历,问我知道哪些机器学习算法 讲了些简单的 怎么对垃圾邮件分类 首先肯定是要特征工程,将邮件编码为欧氏空间中的一个点(向量,embedding),然后就是加标签之类的,丢到算法里面fit参数,我只懂些皮毛 问我svm怎么分类 没搞懂要问什么,以为要讲原理,我说一个分类间隔,支持向量啥啥啥的,反正我不懂,瞎扯一堆 最后说只需要怎么使用 那不是直接丢进去fit参数就行了嘛,重点在特征工程,分词那些吧,没搞懂面试官的逻辑 其他,忘了,暂时只想起来这么多 ","id":43,"section":"posts","summary":"\u003ch1 id=\"字节二面\"\u003e字节二面\u003c/h1\u003e\n\u003col\u003e\n\u003cli\u003e算法题: 二叉树中的最长距离\n\u003col\u003e\n\u003cli\u003e又拉跨了,太久没做题了,做了很久\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e并发和并行的区别\u003c/li\u003e\n\u003cli\u003e讲讲go的协程调度\n\u003col\u003e\n\u003cli\u003eGMP模型,balabala讲一堆,提到了netpoller,触发linux io复用剧情\u003c/li\u003e\n\u003cli\u003e讲到了steal机制,面试官问我为什么在全局队列未空的时候要去steal呢?\n\u003col\u003e\n\u003cli\u003e回答,应该不会吧,毕竟其他p的g可能不在一个核上,会增加cahce缺失率\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e讲讲linux的io复用\n\u003col\u003e\n\u003cli\u003eselect/poll/epoll\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eselect和epoll的区别\n\u003col\u003e\n\u003cli\u003e说了些常见的,比如select用链表不限制fd个数,但是触发后要遍历所有fd,epoll只需要遍历已经激活的fd,数组的前n个\u003c/li\u003e\n\u003cli\u003e似乎不是面试官想要的,让我回去再看看\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e提到epoll只返回激活的fd的个数,问我怎么设计这个数据结构\n\u003col\u003e\n\u003cli\u003e其实没搞懂想问什么,于是我balabal扯了一堆\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e讲讲docker\n\u003col\u003e\n\u003cli\u003e一种linux容器\u003c/li\u003e\n\u003cli\u003e虚拟化,轻量级,隔离\u003c/li\u003e\n\u003cli\u003edockerfile可以很方便的构建容器镜像\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e讲讲TCP的分包\n\u003col\u003e\n\u003cli\u003etcp是面向流的协议\u003c/li\u003e\n\u003cli\u003e基于长度\u003c/li\u003e\n\u003cli\u003e基于分隔符\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e分隔符和内容冲突了怎么办?\n\u003col\u003e\n\u003cli\u003e转义\n\u003col\u003e\n\u003cli\u003e这里可以参考http协议,使用\\r\\n来分隔,对于body,会使用base64编码转义成文本字符,header和body之间有两个\\r\\n来区分\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e配对\n\u003col\u003e\n\u003cli\u003e比如json,xml这种,但显然面临注入的风险,也要转义\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e定长\n\u003col\u003e\n\u003cli\u003e对于简单的报文,直接定长即可\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e看我实验室的经历,问我知道哪些机器学习算法\n\u003col\u003e\n\u003cli\u003e讲了些简单的\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e怎么对垃圾邮件分类\n\u003col\u003e\n\u003cli\u003e首先肯定是要特征工程,将邮件编码为欧氏空间中的一个点(向量,embedding),然后就是加标签之类的,丢到算法里面fit参数,我只懂些皮毛\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e问我svm怎么分类\n\u003col\u003e\n\u003cli\u003e没搞懂要问什么,以为要讲原理,我说一个分类间隔,支持向量啥啥啥的,反正我不懂,瞎扯一堆\u003c/li\u003e\n\u003cli\u003e最后说只需要怎么使用\n\u003col\u003e\n\u003cli\u003e那不是直接丢进去fit参数就行了嘛,重点在特征工程,分词那些吧,没搞懂面试官的逻辑\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e其他,忘了,暂时只想起来这么多\u003c/li\u003e\n\u003c/ol\u003e","tags":["Interview","ByteDance"],"title":"[Interview] ByteDance2","uri":"https://wymli.github.io/2021/03/interview-bytedance2/","year":"2021"},{"content":"grpc grpc是一种rpc框架,先不管其实现或特点.首先我们明确,不管是什么rpc框架,其最终目标都是让用户能够在应用层轻松的调用远程的函数,就像在本机上调用一样.\n如果你还不知道这个,请移步另一个文章[rpc] intro,以及[rpc] net-rpc\ngRPC是Google公司基于Protobuf开发的跨语言的开源RPC框架。gRPC基于HTTP/2协议设计，可以基于一个HTTP/2链接提供多个服务，对于移动设备更加友好\ndesc 很明显了,grpc使用protobuf作为序列化协议,基于http/2作为通信协议\n","id":44,"section":"posts","summary":"\u003ch1 id=\"grpc\"\u003egrpc\u003c/h1\u003e\n\u003cp\u003egrpc是一种rpc框架,先不管其实现或特点.首先我们明确,不管是什么rpc框架,其最终目标都是让用户能够在应用层轻松的调用远程的函数,就像在本机上调用一样.\u003c/p\u003e","tags":["rpc"],"title":"[rpc] grpc","uri":"https://wymli.github.io/2021/03/rpc-grpc/","year":"2021"},{"content":"什么是RPC? rpc: remote procedure call,顾名思义,指的就是远程过程调用,在大多数语境下,过程指的都是函数\n在传统的单体服务中,所有的函数都写在一个进程映像里,我们调用函数只需要跳转到对应的代码段即可.\n但是单体服务已经注定是不可行的了,解耦是永恒的话题.操作系统已经从传统的宏内核演变成微内核,原先非必要的函数都以服务的形式作为进程运行在主机上.\n随着互联网的发展,微服务也逐渐大放光彩.在同一主机上不同的服务可以通过各种各样的ipc手段进行通信,但在web领域,位于不同主机的服务之间只能通过网络通信.\n事实上,网络过程中的通信是复杂的,但我们仍然希望远程过程调用就像原来本机单进程内的函数调用一样简单,那么那些底层复杂的一些操作有谁来完成呢?\n这就是rpc框架提供的封装,在用户层,我们只需要使用简单的call(),即可在客户端调用服务端的函数,并可以根据不同期望选择同步或异步调用方式.至于底层的协议,序列化,路由,限流,熔断,降级等操作,都被rpc框架隐藏了.\nRPC严格来说不是一个协议,它代表的只是一种风格,即调用远程函数来完成本地任务的这种风格,其底层使用的网络协议,可以是自研的,那么就可以称之为rpc协议,但实际上,也完全可以承载在现有的应用层协议上,比如HTTP. 本质上,你只需要让服务端知道你要调用哪个函数即可,通信协议只是手段,不是目的\n关于rpc框架 如果想了解rpc框架需要哪些功能,可以看我的rpc系列的另一篇文章: [rpc] rpcx\n也可以看看 [rpc] grpc和 [rpc] net-rpc, 分别介绍了内置的rpc框架和google的grpc\n","id":45,"section":"posts","summary":"\u003ch1 id=\"什么是rpc\"\u003e什么是RPC?\u003c/h1\u003e\n\u003cp\u003erpc: remote procedure call,顾名思义,指的就是远程过程调用,在大多数语境下,过程指的都是函数\u003c/p\u003e\n\u003cp\u003e在传统的单体服务中,所有的函数都写在一个进程映像里,我们调用函数只需要跳转到对应的代码段即可.\u003c/p\u003e","tags":["rpc"],"title":"[rpc] intro","uri":"https://wymli.github.io/2021/03/rpc-intro/","year":"2021"},{"content":"net/rpc 如下是一段极简的net/rpc代码, client.Call()代表这是一个同步的rpc,如果是异步,net/rpc提供了client.Go()方法,典型的实现是返回一个chan,当异步完成时,这个chan就会读出消息(当然,net/rpc的Go()不是完全这样实现的,但也差不多)\n示例代码 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;net\u0026quot; \u0026quot;net/rpc\u0026quot; \u0026quot;time\u0026quot; ) type ServiceA struct{} func (a *ServiceA) A(req int, reply *int) error { fmt.Println(\u0026quot;server recv:\u0026quot;, req) *reply = 2 return nil } func server() { ls, err := net.Listen(\u0026quot;tcp\u0026quot;, \u0026quot;:9090\u0026quot;) if err != nil { panic(err) } rpc.Register(new(ServiceA)) for { rpc.Accept(ls) } } func main() { go server() time.Sleep(1 * time.Second) client, err := rpc.Dial(\u0026quot;tcp\u0026quot;, \u0026quot;:9090\u0026quot;) if err != nil { panic(err) } var ax int err = client.Call(\u0026quot;ServiceA.A\u0026quot;, 1, \u0026amp;ax) if err != nil { panic(err) } fmt.Println(\u0026quot;client: recv:\u0026quot;, ax) } 服务注册 通过rpc.Register()注册某个对象,该对象的所有导出方法都会被识别\n事实上,一个过程需要满足下面的条件才能被成功注册:\n对象是导出的 对象的方法是导出 该方法只接受两个参数并返回error,一个是请求参数,一个是返回值,其中第二个reply应该是指针的形式. rpc.Register(new(ServiceA)) // 或 rpc.Register(\u0026amp;ServiceA{}) 服务调用 通过类名+方法名来调用函数\nerr = client.Call(\u0026quot;ServiceA.A\u0026quot;, 1, \u0026amp;ax) 编解码 net/rpc使用了gob作为编解码器\n在使用时屏蔽了所有底层的输入输出,简单的encode,decode即可还原出想要的结构体,完全不需要在意分包之类的细节\ntype gobClientCodec struct { rwc io.ReadWriteCloser dec *gob.Decoder enc *gob.Encoder encBuf *bufio.Writer } codec := \u0026amp;gobClientCodec{conn, gob.NewDecoder(conn), gob.NewEncoder(encBuf), encBuf} func (c *gobClientCodec) WriteRequest(r *Request, body interface{}) (err error) { if err = c.enc.Encode(r); err != nil { return } if err = c.enc.Encode(body); err != nil { return } return c.encBuf.Flush() } func (c *gobClientCodec) ReadResponseHeader(r *Response) error { return c.dec.Decode(r) } func (c *gobClientCodec) ReadResponseBody(body interface{}) error { return c.dec.Decode(body) } 通信机制 net/rpc并没有采用典型的一个req一个resp的形式,而是在创建client时,就开启一个goroutine去监听recvbuff,对读到数据包,解析出其中的一个seq字段,用来和当初的req对应,因此,当发送rpc请求的时候,字段会包含seq\n本机使用一个map来存储映射关系,Call 结构体就代表一个调用过程,实际上调用Go()方法的异步调用就会返回/*Call,我们需要判断call.Done来识别调用的完成\npending map[uint64]*Call type Call struct { ServiceMethod string // The name of the service and method to call. Args interface{} // The argument to the function (*struct). Reply interface{} // The reply from the function (*struct). Error error // After completion, the error status. Done chan *Call // Receives *Call when Go is complete. } 数据结构 type Request struct { ServiceMethod string // format: \u0026quot;Service.Method\u0026quot; Seq uint64 // sequence number chosen by client next *Request // for free list in Server } type Response struct { ServiceMethod string // echoes that of the Request Seq uint64 // echoes that of the request Error string // error, if any. next *Response // for free list in Server } 发送 err := client.codec.WriteRequest(\u0026amp;client.request, call.Args) 接收 response = Response{} err = client.codec.ReadResponseHeader(\u0026amp;response) call := client.pending[response.Seq] err = client.codec.ReadResponseBody(call.Reply) call.Done \u0026lt;- call func (client *Client) Call(serviceMethod string, args interface{}, reply interface{}) error { call := \u0026lt;-client.Go(serviceMethod, args, reply, make(chan *Call, 1)).Done return call.Error } ","id":46,"section":"posts","summary":"\u003ch1 id=\"netrpc\"\u003enet/rpc\u003c/h1\u003e\n\u003cp\u003e如下是一段极简的net/rpc代码, \u003ccode\u003eclient.Call()\u003c/code\u003e代表这是一个同步的rpc,如果是异步,net/rpc提供了\u003ccode\u003eclient.Go()\u003c/code\u003e方法,典型的实现是返回一个chan,当异步完成时,这个chan就会读出消息(当然,net/rpc的Go()不是完全这样实现的,但也差不多)\u003c/p\u003e","tags":["rpc"],"title":"[rpc] net/rpc","uri":"https://wymli.github.io/2021/03/rpc-net-rpc/","year":"2021"},{"content":"Buddy system linux底层使用buddy-system+slab\nslab位于buddy-system的上层\n伙伴系统是一种基于二分的动态分区算法,一开始他有k大小的空间,当有新的内存申请到达时,他会对k进行二分,直到满足那个大小恰好是最合适的大小时,返回给用户.比如,申请18KB内存,伙伴系统最初是128KB,那么会一直二分成32KB,16KB,发现16\u0026lt;18,所以返回给用户32KB的大小,这造成了很大的内部碎片\n伙伴系统的合并机制只能合并由同一个区块分裂的子区块,对于相邻的由不同区块分裂的子区块,不能合并\nref\nIn a buddy system, the entire memory space available for allocation is initially treated as a single block whose size is a power of 2. When the first request is made, if its size is greater than half of the initial block then the entire block is allocated. Otherwise, the block is split in two equal companion buddies. If the size of the request is greater than half of one of the buddies, then allocate one to it. Otherwise,one of the buddies is split in half again. This method continues until the smallest block greater than or equal to the size of the request is found and allocated to it\nIn this method, when a process terminates the buddy block that was allocated to it is freed. Whenever possible, an unmallocated buddy is merged with a companion buddy in order to form a larger free block. Two blocks are said to be companion buddies if they resulted from the split of the same direct parent block.\n这里,A=70K代表分配A, A ends代表回收A\n如何实现 逻辑很清楚了,现在的问题是怎么去记录哪些区块是分配了的,哪些是没分配的呢?\n如果单纯的是一个内存池的话,我们可以直接再申请一个内存空间去存储bitmap,来代表分配回收情况. 当然也可以直接在这片内存上划出一个区域放置bitmap\n但bitmap只适合固定分区的情况,对于动态分区,还要维护分区的大小\nfrom wiki\nTypically the buddy memory allocation system is implemented with the use of a binary tree to represent used or unused split memory blocks. The \u0026ldquo;buddy\u0026rdquo; of each block can be found with an exclusive OR of the block\u0026rsquo;s address and the block\u0026rsquo;s size.\n建议阅读:\nhttps://people.kth.se/~johanmon/ose/assignments/buddy.pdf https://www.cs.au.dk/~gerth/papers/actainformatica05.pdf find buddy 我们知道,每一个区块都有一个唯一的buddy(伙伴),并且有一个很快速的方法可以得到其伙伴的首地址\n如果一个区块a大小是2^k,首地址是\u0026amp;a,那么它的伙伴就一定是\u0026amp;a+2^k或\u0026amp;a-2^k,因为伙伴之间的大小一定是相等的.\n\u0026amp;a+2^k或\u0026amp;a-2^k,等价于直接flip(\u0026amp;a,k+1),翻转第k+1位(从右边开始数,从1开始计数)[前提是一定的内存对齐条件]\n隐式free-list 所谓的隐式free-list,指的是node不维护指针,而只维护自己的大小,由于内存的连续性,自己的首地址+大小,便找到了下一个node,每个node有一个标志位决定其是否已被分配\n显式free-list 隐式free-list的缺点是我们要遍历所有的node去寻找未分配的node\n显式free-list则显式的使用指针作为其头部字段,将所有的未分配的node连在一起\n变长分配 现在我们认为一个free-list就存储一个特定大小的node的节点集合,对于不同的大小,我们使用不同的free-list\n对于每个内存区域区块的大小,我们预先定义好,但是并不是按2的n次幂 ,因为这样会造成严重的内部碎片(比如需要65,却分配了128)\n因此,free-list其实是某种静态分配策略,而buddy则是半动态的\n","id":47,"section":"posts","summary":"\u003ch3 id=\"buddy-system\"\u003eBuddy system\u003c/h3\u003e\n\u003cp\u003elinux底层使用buddy-system+slab\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eslab位于buddy-system的上层\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e伙伴系统是一种基于二分的动态分区算法,一开始他有k大小的空间,当有新的内存申请到达时,他会对k进行二分,直到满足那个大小恰好是最合适的大小时,返回给用户.比如,申请18KB内存,伙伴系统最初是128KB,那么会一直二分成32KB,16KB,发现16\u0026lt;18,所以返回给用户32KB的大小,这造成了很大的内部碎片\u003c/p\u003e","tags":[],"title":"[mem] Buddy system","uri":"https://wymli.github.io/2021/03/mem-buddyfreelist/","year":"2021"},{"content":"TCMalloc thread-caching malloc\n顾名思义,这个malloc算法是与thread有关的,直观理解上,就是每个thread单独维护一个内存池,这样,各个thread之间的malloc操作就不会相互造成锁的竞争了\n不同的malloc算法,就是不同的内存池算法,一是为了减少从os申请内存的次数,二也要增加分配给用户的速度\n但是注意,os本身其实也有不同的内存分配算法\nPrerequisite 要了解比较高阶的tcmalloc,我们首先要知道传统的内存分配算法,比如伙伴关系,slab,隐式free-list,显式free-list等(slab应该也是一种free-list),基于bitmap的等等\n可以看看这个回答, 这个答主给出了从简单到复杂的内存池设计\nTCMalloc 实际上,官网的文档已经讲的相对很清楚了: tcmalloc\n实现细节 重命名 #define TCMALLOC_ALIAS(tc_fn) \\ __attribute__((alias(#tc_fn), visibility(\u0026quot;default\u0026quot;))) extern \u0026quot;C\u0026quot; { void* malloc(size_t size) noexcept TCMALLOC_ALIAS(TCMallocInternalMalloc); void free(void* ptr) noexcept TCMALLOC_ALIAS(TCMallocInternalFree); } alias可用于完成的函数调用的重命名,此时,调用malloc,将会重定向到TCMallocInternalMalloc\n但是__attribute__((alias(...)))是gcc的拓展,对于其他编译器,最差的情况也不过是覆盖掉这个weak symbol而已(也就是重定义redefine)\n只有弱符号才可被覆盖,如果是强符号(一般的函数名),则会panic报错函数重定义\nextern \u0026quot;C\u0026quot; { void* malloc(size_t s) noexcept { return TCMallocInternalMalloc(s); } void free(void* p) noexcept { TCMallocInternalFree(p); } } 对于不同的libc,有不同的实现,甚至对不同的编译器,操作系统都有不同的实现:\n// Every libc has its own way of doing this, and sometimes the compiler\n// matters too, so we have a different file for each libc, and often\n// for different compilers and OS\u0026rsquo;s.\n我们常用的是glibc+gcc,也就是都属于gnu\nTCMallocInternalMalloc extern \u0026quot;C\u0026quot; ABSL_CACHELINE_ALIGNED void* TCMallocInternalMalloc( size_t size) noexcept { // Use TCMallocInternalMemalign to avoid requiring size % // alignof(std::max_align_t) == 0. TCMallocInternalAlignedAlloc enforces this // property. return TCMallocInternalMemalign(alignof(std::max_align_t), size); } extern \u0026quot;C\u0026quot; void* TCMallocInternalMemalign(size_t align, size_t size) noexcept { ASSERT(absl::has_single_bit(align)); return fast_alloc(MallocPolicy().AlignAs(align), size); } fast_alloc template \u0026lt;typename Policy, typename CapacityPtr = std::nullptr_t\u0026gt; static inline void* ABSL_ATTRIBUTE_ALWAYS_INLINE fast_alloc(Policy policy, size_t size, CapacityPtr capacity = nullptr) { // If size is larger than kMaxSize, it's not fast-path anymore. In // such case, GetSizeClass will return false, and we'll delegate to the slow // path. If malloc is not yet initialized, we may end up with cl == 0 // (regardless of size), but in this case should also delegate to the slow // path by the fast path check further down. uint32_t cl; bool is_small = Static::sizemap().GetSizeClass(size, policy.align(), \u0026amp;cl); if (ABSL_PREDICT_FALSE(!is_small)) { return slow_alloc(policy, size, capacity); } // When using per-thread caches, we have to check for the presence of the // cache for this thread before we try to sample, as slow_alloc will // also try to sample the allocation. #ifdef TCMALLOC_DEPRECATED_PERTHREAD ThreadCache* const cache = ThreadCache::GetCacheIfPresent(); if (ABSL_PREDICT_FALSE(cache == nullptr)) { return slow_alloc(policy, size, capacity); } #endif // TryRecordAllocationFast() returns true if no extra logic is required, e.g.: // - this allocation does not need to be sampled // - no new/delete hooks need to be invoked // - no need to initialize thread globals, data or caches. // The method updates 'bytes until next sample' thread sampler counters. if (ABSL_PREDICT_FALSE(!GetThreadSampler()-\u0026gt;TryRecordAllocationFast(size))) { return slow_alloc(policy, size, capacity); } // Fast path implementation for allocating small size memory. // This code should only be reached if all of the below conditions are met: // - the size does not exceed the maximum size (size class \u0026gt; 0) // - cpu / thread cache data has been initialized. // - the allocation is not subject to sampling / gwp-asan. // - no new/delete hook is installed and required to be called. ASSERT(cl != 0); void* ret; #ifndef TCMALLOC_DEPRECATED_PERTHREAD // The CPU cache should be ready. ret = Static::cpu_cache().Allocate\u0026lt;Policy::handle_oom\u0026gt;(cl); #else // !defined(TCMALLOC_DEPRECATED_PERTHREAD) // The ThreadCache should be ready. ASSERT(cache != nullptr); ret = cache-\u0026gt;Allocate\u0026lt;Policy::handle_oom\u0026gt;(cl); #endif // TCMALLOC_DEPRECATED_PERTHREAD if (!Policy::can_return_nullptr()) { ASSUME(ret != nullptr); } SetClassCapacity(ret, cl, capacity); return ret; } 略复杂,没看懂\nSlab class TcmallocSlab { public: struct Slabs { std::atomic\u0026lt;int64_t\u0026gt; header[NumClasses]; void* mem[((1ul \u0026lt;\u0026lt; Shift) - sizeof(header)) / sizeof(void*)]; }; private: struct Header { // All values are word offsets from per-CPU region start. // The array is [begin, end). uint16_t current; // Copy of end. Updated by Shrink/Grow, but is not overwritten by Drain. uint16_t end_copy; // Lock updates only begin and end with a 32-bit write. uint16_t begin; uint16_t end; // Lock is used by Drain to stop concurrent mutations of the Header. // Lock sets begin to 0xffff and end to 0, which makes Push and Pop fail // regardless of current value. bool IsLocked() const; void Lock(); }; Slabs* slabs_ = nullptr; } 算了,折磨人\n","id":48,"section":"posts","summary":"\u003ch1 id=\"tcmalloc\"\u003eTCMalloc\u003c/h1\u003e\n\u003cp\u003ethread-caching malloc\u003c/p\u003e\n\u003cp\u003e顾名思义,这个malloc算法是与thread有关的,直观理解上,就是每个thread单独维护一个内存池,这样,各个thread之间的malloc操作就不会相互造成锁的竞争了\u003c/p\u003e","tags":[],"title":"[mem] tcmalloc","uri":"https://wymli.github.io/2021/03/mem-tcmalloc/","year":"2021"},{"content":"排序算法 稳定性 假定在待排序的记录序列中，存在多个具有相同的关键字的记录，若经过排序，这些记录的相对次序保持不变，即在原序列中，r[i]=r[j]，且r[i]在r[j]之前，而在排序后的序列中，r[i]仍在r[j]之前，则称这种排序算法是稳定的；否则称为不稳定的\n堆排序、快速排序、希尔排序、直接选择排序是不稳定的排序算法\n基数排序、冒泡排序、直接插入排序、折半插入排序、归并排序是稳定的排序算法\n快排 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;math/rand\u0026quot; \u0026quot;reflect\u0026quot; \u0026quot;sort\u0026quot; ) func swap(a []int, i, j int) { a[i], a[j] = a[j], a[i] } func partition(a []int) int { r := rand.Int() % len(a) swap(a, r, len(a)-1) // j指针遍历数组a // i指针 a[:i]均是比a[len(a)-1]小的数 i, j := 0, 0 for j \u0026lt; len(a)-1 { if a[j] \u0026lt; a[len(a)-1] { swap(a, i, j) i++ } j++ } swap(a, i, len(a)-1) return i } func qsort(a []int) { if len(a) == 0 { return } mid := partition(a) qsort(a[:mid]) qsort(a[mid+1:]) } func main() { a := []int{rand.Int(), rand.Int(), rand.Int(), rand.Int(), rand.Int(), rand.Int(), rand.Int(), rand.Int()} b := make([]int, len(a)) copy(b, a) sort.Ints(a) qsort(b) fmt.Println(reflect.DeepEqual(a, b)) } 归并 // 此处其实可以充分利用a,b的有序性 func merge(a, b []int) { len := len(a) + len(b) a = a[:len] qsort(a) } func msort(a []int) { if len(a) == 0 || len(a) == 1{ return } left := a[:len(a)/2] right := a[len(a)/2:] msort(left) msort(right) merge(left, right) } ","id":49,"section":"posts","summary":"\u003ch1 id=\"排序算法\"\u003e排序算法\u003c/h1\u003e\n\u003ch2 id=\"稳定性\"\u003e稳定性\u003c/h2\u003e\n\u003cp\u003e假定在待排序的记录序列中，存在多个具有相同的关键字的记录，若经过排序，这些记录的相对次序保持不变，即在原序列中，r[i]=r[j]，且r[i]在r[j]之前，而在排序后的序列中，r[i]仍在r[j]之前，则称这种排序算法是稳定的；否则称为不稳定的\u003c/p\u003e","tags":["Algorithm"],"title":"[Algorithm] sort","uri":"https://wymli.github.io/2021/03/alg-sort/","year":"2021"},{"content":"设计模式 聊聊我熟悉的设计模式\n首先,推荐一下这门课: https://time.geekbang.org/column/intro/100039001\n我看了目录,确实很有吸引力,可惜太贵了:(\n创建型 用于创建类型\n单例 单例模式常用于创建全局唯一变量,大多数时候都增加了耦合,降低了可测试性\n直接使用sync.Once,只调用一次是由once变量保证的\ntype Once struct { done uint32 m Mutex } 使用示例:\npackage singleton var ( once sync.Once GlobalStatus map[string]string ) func New() singleton { once.Do(func() { GlobalStatus = make(map[string]string) }) return GlobalStatus } 实现:\nfunc (o *Once) Do(f func()) { // Note: Here is an incorrect implementation of Do: //\tif atomic.CompareAndSwapUint32(\u0026amp;o.done, 0, 1) { //\tf() //\t} if atomic.LoadUint32(\u0026amp;o.done) == 0 { o.doSlow(f) } } func (o *Once) doSlow(f func()) { o.m.Lock() defer o.m.Unlock() if o.done == 0 { defer atomic.StoreUint32(\u0026amp;o.done, 1) f() } } 注释说的很清楚,一个简单的CAS是不行的!\n我们必须在f()调用完后,再将o.done置位\n工厂 以根据不同的文件名后缀创建不同的解析器为例\n简单工厂 直接根据不同的后缀,返回不同的解析器实例\n工厂方法 直接根据不同的后缀,返回不同的解析器工厂,由该工厂去创建解析器实例\n实现上,一般用map存各个解析器工厂\n好处: 如果要添加新的解析器,只需要在map中添加即可,而不需要改变逻辑代码\n抽象工厂 直接根据不同的后缀,返回不同的解析器工厂,该解析器工厂可以创建不同类的解析器\n即不仅是不同类产品,同类产品本身也有区别\n比如解析器,分为json parser,xml parser\u0026hellip; 对于json parser本身,还分为fast json parser, portable json parser..等\n","id":50,"section":"posts","summary":"\u003ch1 id=\"设计模式\"\u003e设计模式\u003c/h1\u003e\n\u003cp\u003e聊聊我熟悉的设计模式\u003c/p\u003e\n\u003cp\u003e首先,推荐一下这门课: \u003ca href=\"https://time.geekbang.org/column/intro/100039001\"\u003ehttps://time.geekbang.org/column/intro/100039001\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e我看了目录,确实很有吸引力,可惜太贵了:(\u003c/p\u003e\n\u003ch2 id=\"创建型\"\u003e创建型\u003c/h2\u003e\n\u003cp\u003e用于创建类型\u003c/p\u003e\n\u003ch3 id=\"单例\"\u003e单例\u003c/h3\u003e\n\u003cp\u003e单例模式常用于创建全局唯一变量,大多数时候都增加了耦合,降低了可测试性\u003c/p\u003e","tags":["Arch"],"title":"[arch] design pattern","uri":"https://wymli.github.io/2021/03/arch-design-pattern/","year":"2021"},{"content":"关于RMW与Atomic LD/ST [TOC]\n事情的起因是我在记录自己学习设计模式的过程时,看了sync.Once的源码,其实以前也看了很多遍,但今天一看,突然发现自己不是很懂atomic.LoadUint32()的意义,于是促成了这篇文章\natomic.LoadUint32() 关于atomic.LoadUint32意义在哪里?和普通的读有什么区别?\n原子性: 要么发生,要么不发生\n荐读:\nhttp://www.1024cores.net/home/lock-free-algorithms/so-what-is-a-memory-model-and-how-to-cook-it\nhttps://preshing.com/20130618/atomic-vs-non-atomic-operations/\n原子指令分类 有两类原子指令:\nRMW: read-modify-write compare and swap(CAS) 或相似的load-linked/store-conditional, LL/SC(解决了CAS的ABA问题) fetch and add(FAA) atomic.AddUint32(\u0026amp;sum, 1) 为什么有个fetch?因为要更改值,必须先加载到寄存器或ALU,再更改,所以先fetch loads and stores 即关于load和store的原子性 atomic.LoadUint32() atomic.StoreUint32() 对于RMW类指令,很好理解,可以解决经典的对线程对sum++的竞态问题(比如使用FAA),那么load\u0026amp;store这两个指令呢?\n在一些stackoverflow的回答中,我了解到,对于内存对齐的32位数,是自然提供原子读写的,通过这个,我们大概了解到原子读写是指的能否一次性通过总线把数据从内存中读写出来,但是,如果不提供原子性,危害在哪里?\n原子性缺失证明 双MOV 证实: 对如下代码使用386的32位指令集架构,在amd64下交叉编译,可以看到,一个return语句确实分成了两个汇编指令\n对go语言,交叉编译异常简单,只要设置GOOS和GOARCH即可\nfunc b() uint64 { var a uint64 = 0 a = 0x900000008 return a } 0x0012 00018 (a.go:6) MOVL $8, \u0026quot;\u0026quot;.~r0+4(SP) 0x001a 00026 (a.go:6) MOVL $9, \u0026quot;\u0026quot;.~r0+8(SP) 非原子单条汇编指令 在一些cpu架构上(即一些指令集上),即使只有单条指令,也无法保证原子性\n比如 ARMv7 指令\n// 将r0,r1两个32位数存在r2指向的内存上的64数 strd r0, r1, [r2] On some ARMv7 processors, this instruction is not atomic. When the processor sees this instruction, it actually performs two separate 32-bit stores under the hood\n原子性保证 原子写:\nWhen an atomic store is performed on a shared variable, no other thread can observe the modification half-complete,保证数据一次写完,防止其他线程读到半更新数据 常见于32位机器写64位数,只能分成2个MOV指令,破坏了原子性 原子读:\n保证一次读完数据,防止在两次读的间隙数据又被更改 缺失危害 这种data race的后果:\n未提供原子写 同时写: the upper 32 bits from one thread, the lower 32 bits from another. 一读一写: any thread executing on a different core could read sharedValue at a moment when only half the change is visible,读到其他线程写了一半的数据 未提供原子读 一读多写: 读到的数据类似于同时写,上4字节来自一个线程,下4字节来自另一个线程 过程是: w1-\u0026gt;r_hi32-\u0026gt;w2-\u0026gt;r_lo32 解决方法 对共享变量这种会产生多线程读写data race的情况(不同于普通的竞态,data race是如上所说,更底层的竞态)\n因此,对于存在data race的共享变量,需要在__语言层面__提供__原子读写__,即对共享变量使用atomic rd/wr而不是plain rd/wr\n对于现代体系架构,原子读写是默认支持的,除非你在32位机器上存储64位数,或是对共享atomic.Value的读写,这时,需要显式使用相关package的函数支持\natomic.Value可能承载一个很大的结构体,比如sync.map里面,内置的built-in map是用atomic.Value实现的\n在底层原子读写指令的实现,要么是锁cache line ,要么是锁总线(优先锁住cache行)\nCAS cas的缺点: 可能会造成活锁和ABA问题\n活锁: 虽然大家都在不断尝试,外界看起来也都在运行,但是没有一个人成功 ABA问题: 这不是__CAS本身的问题__,而是在使用CAS时常见的错误用法 因为使用CAS,你需要先加载旧值,oldVar = *addr,再CAS(addr,oldVar,newVar) 再加载旧值和CAS之间,如果addr被人改了又改回去,你是无法识别的,这会导致newVar也许已经失效(如果是典型的链表场景) 如果要解决这个问题,可能需要加上版本号之类的\nC++的addr.compare_exchange_weak(oldVar,newVar)当cmp失败时,会将oldVar置为新值,这可以很方便的让人写出CAS LOOP\ndo{ // do something about oldValue and get newValue } while (!shared.compare_exchange_weak(oldValue, newValue)); 但是遗憾的是Go语言的func CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool)\t虽然提供了非侵入式的接口,但old值是不会改变的\nLL/SC 对于load-link/store-conditional指令,可以有效解决ABA问题\noldVar = LL(addr) // dosomthing ok = SC(addr , newVar) 一旦在本线程LL后SC前,只要有其他线程访问了这个addr,就导致SC的false\n锁 Futex fast userspace mutx\nA futex consists of a kernelspace wait queue that is attached to an atomic integer in userspace.\n查了很久,也没弄懂到底是个啥,如果按照上面这个wiki的定义,我倾向于说go的built-in mutex就是一种futex\ntype Mutex struct { state int32 sema uint32 } state是位于用户态空间的,用于无竞态时的快速上锁\nsema则用于竞态时的阻塞\n这样的锁也称为lightweight mutex ref\n总结 竞态 宏观竞态race condition 读写过程作为整体不原子,用RMW解决 微观竞态data race 读写本身不原子,用原子读写解决 默认原子读写 it’s common knowledge that on all modern x86, x64, Itanium, SPARC, ARM and PowerPC processors, plain 32-bit integer assignment is atomic as long as the target variable is naturally aligned\n处理器架构 处理器位数\n386,i386(intel386),80386 都指intel的32位处理器\namd64,intel64,x86-64,x64 都指intel的64位处理器\n处理器架构\nx86\nx86,x86-32,IA32: x86是对Intel 8086、80186、80286、80386以及80486的架构的泛称,如今又称为x86-32,或IA-32 amd64,intel64,x86-64,x64: 由AMD公司所开发,基于IA32/x86-32架构 IA64\nIA-64: IA-64是一种崭新的系统，和x86架构完全没有相似性；不应该把它与x86-64/x64弄混 单独说x86,就是指x86-32/IA32/386/I386,单指32位intel处理器\n如果是说x86-64,会说x64或amd64/intel64\n","id":51,"section":"posts","summary":"\u003ch1 id=\"关于rmw与atomic-ldst\"\u003e关于RMW与Atomic LD/ST\u003c/h1\u003e\n\u003cp\u003e[TOC]\u003c/p\u003e\n\u003cp\u003e事情的起因是我在记录自己学习设计模式的过程时,看了sync.Once的源码,其实以前也看了很多遍,但今天一看,突然发现自己不是很懂atomic.LoadUint32()的意义,于是促成了这篇文章\u003c/p\u003e","tags":["Atomic"],"title":"[atomic] atomic","uri":"https://wymli.github.io/2021/03/atomic-atomic/","year":"2021"},{"content":"总结一下在c语言中遇到的诸多Tricks 柔性数组 一个典型的柔性数组如下所示,数组本身是不占空间的\nstruct skipnode { int key; int value; struct sk_link link[0]; }; struct skipnode *node = malloc(sizeof(*node) + level * sizeof(struct sk_link)); 关于柔性数组也可以看看redis的sds,也是用这个数组实现的\n搭配Union 柔性数组也可以搭配Union联合体\nunion node { node* next; char data[0]; }; 这样,这个node既可以充当链表节点,指向下一个链表. 也可以使用data指向malloc后的分配的内存.\n从成员还原出首地址 本质是我们需要知道偏移量,但我们不可能知道,这时可以借助编译器帮我们计算\n完整代码是:\n#define list_entry(ptr, type, member) \\ ((type *)((char *)(ptr) - (size_t)(\u0026amp;((type *)0)-\u0026gt;member))) 首先计算偏移量\noffset = (size_t)(\u0026amp;(((type *)0)-\u0026gt;member))) ((type *)0表示将地址0解释为type类型,然后取出member,这自然的其内存地址就是相较于0的偏移,对其取值后转换成size_t,则就是字节偏移了\n本质上等同于\noffset = (size_t)(\u0026amp;(((type *)123)-\u0026gt;member))-123) void*泛型 \u0026hellip;\n","id":52,"section":"posts","summary":"\u003ch1 id=\"总结一下在c语言中遇到的诸多tricks\"\u003e总结一下在c语言中遇到的诸多Tricks\u003c/h1\u003e\n\u003ch2 id=\"柔性数组\"\u003e柔性数组\u003c/h2\u003e\n\u003cp\u003e一个典型的柔性数组如下所示,数组本身是不占空间的\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-c\"\u003estruct skipnode {\n        int key;\n        int value;\n        struct sk_link link[0];\n};\n\nstruct skipnode *node = malloc(sizeof(*node) + level * sizeof(struct sk_link));\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e关于柔性数组也可以看看redis的sds,也是用这个数组实现的\u003c/p\u003e","tags":["C"],"title":"[c] trick1","uri":"https://wymli.github.io/2021/03/c-trick1/","year":"2021"},{"content":"应用层缓存 通常我们不希望所有数据的请求都去查询数据库,这一方面是慢,另一方面对数据库的压力也大.\n因此,类似硬件层面的缓存,我们在应用层也会使用in-memory cache\n通常,我们使用redis,或mongoDB,memcached等\n缓存虽好,但也面临着一些问题,比如缓存穿透,缓存击穿,缓存雪崩\n缓存穿透 如果某些请求一直查询一些不存在的数据,那么将会大幅提高缓存缺失率,这些请求将会去数据库查询,增加数据库压力,但是由于这些数据是不存在的,所以这是一次无用功,平白无故的增加了数据库压力,我们需要对其优化\n一般的, cpu缓存命中率可达90%以上\n所谓穿透,就是指缓存缺失了,请求穿透了缓存达到数据库\n白名单: 布隆过滤器 布隆过滤器可以用于检索一个元素是否在一个集合中。布隆过滤器存储空间和插入/查询时间都是常数 O(K)\n布隆过滤器是基础结构是一个较大的bitmap\n插入: 对输入,通过K个散列函数,映射到k个bit上,置为1 查询: 对输入,通过k个散列函数,映射到k个bit上,若这k个bit均为1,则判定为存在,否则判定为不存在 它使用了多个hash函数,这是与普通的哈希表的差别,目的是为了降低hash冲突,如果一个hash函数的冲突率是0.5,那k个hash函数的冲突率就是(0.5)^k,很可观\n但显然,这无法保证不发生冲突. 而且,其他键的hash值和自己的的hash值是存在交集的,所以这导致了布隆过滤器的特性: 存在误判率(只会误判为存在)\n一般的缓存就是一个动态hash表\n如果误判,则必定是认为数据存在,然后去查找缓存,查找数据库,这是可以忍受的,因为这种误判不会使得服务提供差错,而只是增加延时\n如果是将存在的误判为不存在,则千万不可使用,否则就相当于拒绝服务了\n我们倾向于有损服务,而不是不服务\n黑名单: 缓存空结果 除了在缓存前,再前置一个过滤器,还可以当在数据库中查询到空结果时,重新设置缓存(read allocate).\n但是一般的,这个缓存的过期时间要比较短,毕竟你无法知道这个数据是否真的马上被创建了\n但显然,这种方法有着很大的缺陷,它相当于每查询一次设置一个黑名单,我们无法阻止恶意的用户持续的进行查询不存在数据的攻击(这也算一种dos攻击),\n缓存击穿 某个热点数据在某个时间点过期,但这时有大量的请求打过来,由于缓存缺失,全部穿透到数据库\n为什么会过期? 这里先假设过期时间是不实时更新的,过期时间仅在第一次读时设置\nSETNX SET if Not eXists\n这就是类似一个cas(compare and swap)原子指令,我们知道击穿的痛点在于突然大量对同一数据的请求达到数据库,那么我们可以不让这些请求同时达到数据库,由于是对同一数据的请求,我们可以在缓存层面设计,当第一个请求没查到数据时,用SETNX新建一个与key唯一相关的key_mutex键,置1,这样后续的请求如果未读到缓存,再去读这个key_mutex,读到了1,就会自旋或阻塞或睡眠,一般让其睡眠50ms就好,或者将key_mutex的value设成一个semaphore,让线程在这个信号量上阻塞,但很显然,调度的时间应该超过50ms,毕竟有大量的请求,没必要!\n过期时间策略 针对过期时间的一定优化,但无法解决对可写的热点数据的缓存穿透\n一个数据被写后,通常是先写数据库,再delete缓存,这会导致缓存中数据不存在而击穿,用setnx可以很好解决\n更新过期时间1,每次 只要我们每读一次数据,就用原子指令atomic.Add()增加过期时间,那么缓存击穿的概率也大大降低\n更新过期时间2,阈值 我们不再每次都更新缓存的过期时间,而是在value字段内置一个fake过期时间,这个fake过期时间比缓存的过期时间早,当我们每读一次数据,都要检查一下fake过期时间是否过期,如果过期,就更新缓存\n热点不过期 如果给热点数据,设置一个较长的过期时间,就能防止其失效了\n缓存雪崩 多个缓存在同一时间全部失效\n随机过期时间 给不同的资源设置不同的随机的过期时间,防止一起失效\n","id":53,"section":"posts","summary":"\u003ch1 id=\"应用层缓存\"\u003e应用层缓存\u003c/h1\u003e\n\u003cp\u003e通常我们不希望所有数据的请求都去查询数据库,这一方面是慢,另一方面对数据库的压力也大.\u003c/p\u003e\n\u003cp\u003e因此,类似硬件层面的缓存,我们在应用层也会使用in-memory cache\u003c/p\u003e","tags":["Cache"],"title":"[cache] base concepts","uri":"https://wymli.github.io/2021/03/cache-base-concepts/","year":"2021"},{"content":"[Go] 可交互动态终端 \u0026lt;1, 事件注册分发中心\u0026gt; github.com/mum4k/termdash\n如何完成一个好看的terminal呢?在以前我们大都会使用简单的printf来打印数据到终端,进阶一点,可能会加上颜色,再后来可能又做个贪吃蛇游戏,了解了如何高效刷新terminal\u0026hellip;\u0026hellip;\n我们先来看看该库的Feature List\nFull support for terminal window resizing throughout the infrastructure. Customizable layout, widget placement, borders, margins, padding, colors, etc. Dynamic layout changes at runtime. Binary tree and Grid forms of setting up the layout. Focusable containers and widgets. Processing of keyboard and mouse events. Periodic and event driven screen redraw. A library of widgets, see below. UTF-8 for all text elements. Drawing primitives (Go functions) for widget development with character and sub-character resolution. 这些Feature,就是要学习的地方\n计划阅读学习的部分:\n事件注册分发系统 终端事件轮询器 基于cell的终端结构体 容器二叉树 容器focusTracker 布局 鼠标事件之有限状态机 segmentDisplay 类似于七段数码管的display模式 1. 事件注册分发系统eventDistributionSystem(eds) 依赖于事件监听第三方库: tcell \u0026ldquo;github.com/gdamore/tcell/v2\u0026rdquo;\n针对每个订阅,都启动一个go程轮询自己,看自己的事件队列是否为空,不为空则消费\n用更go的style,这里应该使用channel,而不是用 链表+sync.cond+sync.Mutex\n可以认为订阅没有发起者,只是一个个平行同一的item,当事件触发后,调用订阅的回调函数,该函数一般是闭包函数,由此改变逻辑上的订阅发起者\nupdate2021/3/14 今天在看消息队列的时候,了解到,原来这个事件分发中心的设计模式是观察者模式\n消息队列的特性: 异步解耦削峰\n下一章 就像netpoller网络事件轮询器一样,要实现可交互终端,我们需要终端事件轮询器\n","id":54,"section":"posts","summary":"\u003ch1 id=\"go-可交互动态终端-1-事件注册分发中心\"\u003e[Go] 可交互动态终端 \u0026lt;1, 事件注册分发中心\u0026gt;\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/mum4k/termdash\"\u003egithub.com/mum4k/termdash\u003c/a\u003e\u003c/p\u003e\n\u003cimg src=\"https://github.com/mum4k/termdash/raw/master/doc/images/termdashdemo_0_9_0.gif\" alt=\"termdashdemo\" style=\"zoom: 25%;\" /\u003e\n\u003cp\u003e如何完成一个好看的terminal呢?在以前我们大都会使用简单的printf来打印数据到终端,进阶一点,可能会加上颜色,再后来可能又做个贪吃蛇游戏,了解了如何高效刷新terminal\u0026hellip;\u0026hellip;\u003c/p\u003e","tags":["cli"],"title":"[cli] 事件分发系统","uri":"https://wymli.github.io/2021/03/1.-eventdistributionsystem/","year":"2021"},{"content":"可交互动态终端 \u0026lt;2, 刷新屏幕\u0026gt; ref: github.com/gdamore/tcell/v2\n我们知道,对于终端的刷新来说,如果我们直接刷新整个屏幕,将会有明显的帧刷新感,由此,我们需要只对更新的数据刷新,而跳过不变的数据.\n这依赖于 0. 找到dirty数据 1. 设置输出光标的位置 2. printf (syscall.WriteConsole)\n创建screen 这里有两种类型的screen,\n功能是为了: NewScreen returns a default Screen suitable for the user\u0026rsquo;s terminal environment.\nwin下默认使用NewConsoleScreen\nTerminfo is a library and database that enables programs to use display terminals in a device-independent manner.\n简单来说就是一个第三方库,类似于pcap这种,用于提供posix终端控制\n查看本地是否支持terminfo: echo $TERM\nNewConsoleScreen() NewTerminfoScreen() 我们这里介绍windows下的NewConsoleScreen()\n这些函数都是返回我们自己的定义的一个逻辑上的终端结构体.\n打开输入输出 对于windows下:\nin, e := syscall.Open(\u0026quot;CONIN$\u0026quot;, syscall.O_RDWR, 0) out, e := syscall.Open(\u0026quot;CONOUT$\u0026quot;, syscall.O_RDWR, 0) 这里CONIN$,CONOUT$,指console in/out,简单来看就是stdin/stdout,但是有时候你可能对stdin/stdout重定向到了文件,所以为了直接获取对终端的控制,用这个.\nTrue color 所谓的true color,是指支持RGB颜色的color,即3*8=24-bit的颜色设置\n但是历史原因,较古老的终端就不支持,比如cmd\n加载kernel32.dll 在windows中,我们需要先加载dll,以获取某些系统调用\nGo语言的built-in syscall并未包含一些不常用的系统调用\nvar ( k32 = syscall.NewLazyDLL(\u0026quot;kernel32.dll\u0026quot;) u32 = syscall.NewLazyDLL(\u0026quot;user32.dll\u0026quot;) ) 注意这里NewProc指的是New Procedure\nvar ( procReadConsoleInput = k32.NewProc(\u0026quot;ReadConsoleInputW\u0026quot;) procWaitForMultipleObjects = k32.NewProc(\u0026quot;WaitForMultipleObjects\u0026quot;) procCreateEvent = k32.NewProc(\u0026quot;CreateEventW\u0026quot;) procSetEvent = k32.NewProc(\u0026quot;SetEvent\u0026quot;) procGetConsoleCursorInfo = k32.NewProc(\u0026quot;GetConsoleCursorInfo\u0026quot;) procSetConsoleCursorInfo = k32.NewProc(\u0026quot;SetConsoleCursorInfo\u0026quot;) procSetConsoleCursorPosition = k32.NewProc(\u0026quot;SetConsoleCursorPosition\u0026quot;) procSetConsoleMode = k32.NewProc(\u0026quot;SetConsoleMode\u0026quot;) procGetConsoleMode = k32.NewProc(\u0026quot;GetConsoleMode\u0026quot;) procGetConsoleScreenBufferInfo = k32.NewProc(\u0026quot;GetConsoleScreenBufferInfo\u0026quot;) procFillConsoleOutputAttribute = k32.NewProc(\u0026quot;FillConsoleOutputAttribute\u0026quot;) procFillConsoleOutputCharacter = k32.NewProc(\u0026quot;FillConsoleOutputCharacterW\u0026quot;) procSetConsoleWindowInfo = k32.NewProc(\u0026quot;SetConsoleWindowInfo\u0026quot;) procSetConsoleScreenBufferSize = k32.NewProc(\u0026quot;SetConsoleScreenBufferSize\u0026quot;) procSetConsoleTextAttribute = k32.NewProc(\u0026quot;SetConsoleTextAttribute\u0026quot;) procMessageBeep = u32.NewProc(\u0026quot;MessageBeep\u0026quot;) ) 设置光标位置,注意\nfunc (p *LazyProc) Call(a ...uintptr) (r1, r2 uintptr, lastErr error)\n的签名,参数都要转换成uintptr\ntype coord struct { x int16 y int16 } func (c coord) uintptr() uintptr { // little endian, put x first return uintptr(c.x) | (uintptr(c.y) \u0026lt;\u0026lt; 16) } // s.out 是 screen // out, e := syscall.Open(\u0026quot;CONOUT$\u0026quot;, syscall.O_RDWR, 0) procSetConsoleCursorPosition.Call(uintptr(s.out),coord{int16(x), int16(y)}.uintptr()) 将以ch[0]为首地址的一段buffer输出到屏幕s.out\nsyscall.WriteConsole(s.out, \u0026amp;ch[0], uint32(len(ch)), nil, nil) VT转义字符序列 对于更高级的终端,可以支持VT100/XTerm 转义字符\nVT100/XTerm 转义字符,使用这些转义字符,那么就不用调用syscall了,只要把这些字符print出去,就能达到一些系统调用的效果,比如设置颜色,设置光标位置\nconst ( // VT100/XTerm escapes understood by the console vtShowCursor = \u0026quot;\\x1b[?25h\u0026quot; vtHideCursor = \u0026quot;\\x1b[?25l\u0026quot; vtCursorPos = \u0026quot;\\x1b[%d;%dH\u0026quot; // Note that it is Y then X vtSgr0 = \u0026quot;\\x1b[0m\u0026quot; vtBold = \u0026quot;\\x1b[1m\u0026quot; vtUnderline = \u0026quot;\\x1b[4m\u0026quot; vtBlink = \u0026quot;\\x1b[5m\u0026quot; // Not sure this is processed vtReverse = \u0026quot;\\x1b[7m\u0026quot; vtSetFg = \u0026quot;\\x1b[38;5;%dm\u0026quot; vtSetBg = \u0026quot;\\x1b[48;5;%dm\u0026quot; vtSetFgRGB = \u0026quot;\\x1b[38;2;%d;%d;%dm\u0026quot; // RGB vtSetBgRGB = \u0026quot;\\x1b[48;2;%d;%d;%dm\u0026quot; // RGB ) 如果是自己测试,可以使用诸如echo -e \u0026quot;\\x1b[?25l\u0026quot;\n可以通过GetConsoleMode系统调用来查看终端是否支持ENABLE_VIRTUAL_TERMINAL_PROCESSING\n基于cell的终端屏幕模拟 屏幕是二维的,我们用一个二维逻辑buffer(实际上用一维buffer实现)来模拟屏幕,众所周知,屏幕本质就是由像素点组成的二维阵列,在模拟中,我们__将cell作为最小单元__,它的宽度占比就是一个普通的ascii字符打印出来的宽度\ncell cell结构体存储3+3+1个字段,分别为current(3),last(3),width(1),current/last中包含main,comb,style,分别指主字,加字,风格\n在大多数语言中,比如英文/中文,都不存在加字comb,只包含主字main\n之所以要设置last,是为了判断这个cell是否被更新,如果更新,则要输出到屏幕覆盖旧值,如果未更新,则跳过\n对于width,大多数东亚字符的width都是2,这意味着,下一个cell将不能存储东西,要跳过下一个cell\n// main: primary rune // comb: any combining character runes (which will usually be nil) combining:一般是音调,或者藏语里面的上加字下加字或元音,这些字符是依附在前一个字符身上的,即自己不占空间,在存储到cell时,通常的做法是设置main为' '(空格),将其本身放在comb里面,详见本文后面的示例 // style: the style, and the display width in cells // width: The width can be either 1, normally, or 2 for East Asian full-width characters. type cell struct { currMain rune currComb []rune currStyle Style lastMain rune lastStyle Style lastComb []rune width int }\t// CellBuffer represents a two dimensional array of character cells. // This is primarily intended for use by Screen implementors; it // contains much of the common code they need. To create one, just // declare a variable of its type; no explicit initialization is necessary. // CellBuffer is not thread safe. type CellBuffer struct { w int h int cells []cell } 坐标 屏幕是二维的\u0026lt;width , height\u0026gt;,但存储时,设计成一维的,对于位于(x,y)的点,通过cb.cells[(y*cb.w)+x]取出,这里cb代表cellbuffer\n(设计成一维的,可能是为了得到一个连续的空间buffer,来模拟二维的屏幕)\n对于计算机屏幕的坐标系不用多说,左上角为原点(0,0),向右是x轴正方向,向下是y轴正方向\n如果想hideCursor() , 通常的做法是setCursor(-1,-1)\n扫描buffer,刷新屏幕 这里只考虑ascii字符,对于utf-8字符完整的处理,可看源码\n每检测到脏数据,就添加进一个buffer,直到遇到第一个不需要更新的数据,然后将buffer写到屏幕,不断重复.\nbuf := make([]uint16, 0, s.w) wcs := buf[:] lx, ly := -1, -1 for y := 0; y \u0026lt; s.h; y++ { for x := 0; x \u0026lt; s.w; x++ { mainc := s.cells.GetContent(x, y) // 注意,原本是返回mainc, combc, style, width,这里略去 // cells.Dirty()判断x,y位置的cell是否是脏数据,这意味着要刷新到屏幕覆盖旧数据 dirty := s.cells.Dirty(x, y) if !dirty { // write out any data queued thus far // because we are going to skip over some // cells s.writeString(lx, ly, wcs) wcs = buf[0:0] continue } if len(wcs) == 0 { lx = x ly = y } wcs = append(wcs, utf16.Encode([]rune{mainc})...) } s.writeString(lx, ly , wcs) wcs = buf[0:0] } func (s *cScreen) writeString(x, y int, style Style, ch []uint16) { s.setCursorPos(x, y, s.vten) syscall.WriteConsole(s.out, \u0026amp;ch[0], uint32(len(ch)), nil, nil) } 问题: 为什么syscall.WriteConsole(s.out, \u0026amp;ch[0], uint32(len(ch)), nil, nil)这里,ch必须是[]uint16,len必须是uint32?\n我们来看看微软官方的开发文档给的函数签名:\n// Writes a character string to a console screen buffer beginning at the current cursor location. BOOL WINAPI WriteConsole( _In_ HANDLE hConsoleOutput, _In_ const VOID *lpBuffer, _In_ DWORD nNumberOfCharsToWrite, _Out_opt_ LPDWORD lpNumberOfCharsWritten, _Reserved_ LPVOID lpReserved ); lpBuffer [in] A pointer to a buffer that contains characters to be written to the console screen buffer. This is expected to be an array of either char for WriteConsoleA or wchar_t for WriteConsoleW.\n这里,wchar_t就是16位的类型(windows platform),但是注意,wchar_t,在其他平台可能是32位的,不过由于我们使用的是windows的系统调用,所以直接用就将buffer设置成[]uint16{}就行\nThe wchar_t type is an implementation-defined wide character type. In the Microsoft compiler, it represents a 16-bit wide character used to store Unicode encoded as UTF-16LE, the native character type on Windows operating systems.\n这里UTF-16LE,LE指little endian\nDWORD: double word,双字,一个字是2字节\nUTF16编码 因为windows默认是UTF-16LE编码,我们需要对[]rune编码为utf16,这里rune是int32,也就直接是unicode码点\nfunc (s *cScreen) emitVtString(vs string) { esc := utf16.Encode([]rune(vs)) syscall.WriteConsole(s.out, \u0026amp;esc[0], uint32(len(esc)), nil, nil) } UTF-8/UTF-16 我们知道除了ascii字符(1 byte)之外,我们还需要打印诸如中文这样的宽字符,不同的字符需要用不同的码点(数字编码)来表示,这个编码集就是Unicode\nUnicode 是容纳世界所有文字符号的国际标准编码，使用四个字节为每个字符编码\n但是Unicode每个字符都是四字节,对于英文来说,一个ascii字符只需要1字节,对于英文国家的人来说,如果使用unicode编码来编码字符串,就会有4倍的开销,因此,产生了UTF(Unicode Transformation Format)的各个版本,这些版本都能表示所有的Unicode字符,但是有不同的优化方式(压缩方式)\nUTF-8: 使用一至四个字节为每个字符编码,其中大部分汉字采用三个字节编码 UTF-16: 使用二或四个字节为每个字符编码,其中大部分汉字采用两个字节编码 UTF-32: 使用四个字节为每个字符编码 除了字符本身的编码外,还存在大端序小端序的前置记号,UTF-16是2字节,UTF-32是4字节,UTF-8没有,这些记号在存储时将放置在文件的首部\n一般的,大多编程语言就原生支持unicode,只需要在前面加上\\u即可, \u0026lsquo;\\u1234\u0026rsquo;\n","id":55,"section":"posts","summary":"\u003ch1 id=\"可交互动态终端-2-刷新屏幕\"\u003e可交互动态终端 \u0026lt;2, 刷新屏幕\u0026gt;\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003eref:  github.com/gdamore/tcell/v2\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e我们知道,对于终端的刷新来说,如果我们直接刷新整个屏幕,将会有明显的帧刷新感,由此,我们需要只对更新的数据刷新,而跳过不变的数据.\u003c/p\u003e","tags":["cli"],"title":"[cli] 刷新屏幕","uri":"https://wymli.github.io/2021/03/2.-createandfreshscreen/","year":"2021"},{"content":"Promise\u0026amp;future 函数式编程是一个新的编程范式,基本上,只要你的编程语言支持函数是一等公民这个说法,那么就至少支持部分的函数式编程\n[TOC]\npromise 所谓的promise,是指对异步函数返回值的一个封装,比如就是对单个int的封装,但是由于是异步的,所以只能注册回调函数来完成当函数结束后对int进行访问\n我们知道对异步函数的一般做法是,创建的同时要传入回调函数,比如:\nfunc createAudioFileAsync(successCallback func(result interface{})interface{}, failureCallback func(err interface{})interface{}) interface{}{ go func(){ // dosomething if ok{ return successCallback(result) }else{ return failureCallback(err) } }() } 这里successCallback func(result interface{}), failureCallback func(err interface{})这些函数可以传入闭包,如果希望同时修改外部变量,这就是某种意义上的观察者模式\ncreateAudioFileAsync(func(resutlt interface{}){ //dosomething },func(err interface{}){ //dosomething }) 但很明显,这陷入了某种意义上的回调地狱(callback hell),比如如果我们想有多步,先执行func1,成功了就执行func2,再成功就执行func3,\u0026hellip;\nfunc func1/2/3 (succCb , failCb){ // dosomthing if ok{ succCb() }else{ failCb() } } func1( func2( func3( func(resutlt interface{}){ //dosomething },func(err interface{}){ //dosomething } ),func(err interface{}){ //dosomething } ),func(err interface{}){ } ) //如果写的清晰一点,就是: func1( func2( func3( func(resutlt interface{}){ // dosomething },failureCallback ),failureCallback ),failureCallback ) 于是,Promise引入了,我们不再直接在异步函数参数中传递callback,而是让异步函数返回一个promise,这个promise结构体支持注册回调,哪怕异步函数已经完成了,也会触发一次回调;\n这样,原本嵌套的回调函数,变成了级联的调用链\nfunc func1()promise{ // dosomthing return promise } promise := func1() promise.then(func(resutlt interface{}){ // dosomething },failureCallback) 级联调用时(successCb()要返回promise):\nfunc1().then(func(){return func2()},failureCallback).then(func(){return func3()},failureCallback) 为了更好的减少代码,我们将failureCallback抽离,形成一个统一的错误处理\nfunc1().then(func(){return func2()}).then(func(){return func3()}).catch(failureCallback) 一般的,每个successCb都应该以一个result为参数,在go里面,可以用interface{}替代,假装自己是动态类型\nawait async/await 是promise的语法糖,可以不必再刻意的写出.then()调用链\n比如如下代码,只要有一个await失败,就直接跳转到catch\nasync function foo() { try { const result = await doSomething(); const newResult = await doSomethingElse(result); const finalResult = await doThirdThing(newResult); console.log(`Got the final result: ${finalResult}`); } catch(error) { failureCallback(error); } } async函数,代表这是一个可能的异步函数(如果async内部不包含await,那么就失去async语义,转为同步函数)\nasync函数可能包含0个或者多个await表达式。await表达式会暂停整个async函数的执行进程并出让其控制权，只有当其等待的基于promise的异步操作被兑现或被拒绝之后才会恢复进程。promise的解决值会被当作该await表达式的返回值。使用async / await关键字就可以在异步代码中使用普通的try / catch代码块。\nC++中的future/promise std::promise\u0026lt;int\u0026gt; p; std::future\u0026lt;int\u0026gt; f3 = p.get_future(); std::thread( [\u0026amp;p]{ p.set_value_at_thread_exit(9); }).detach(); f3.wait(); 这里detach,是指分离这个thread,让他独立执行,而不再需要主线程join()来回收资源,可以回顾进程中的僵尸进程,就是子进程执行完了,但是父进程没有join它(wait/waitpid),导致资源未回收\n可以看出,这里future,就是异步值的承载,是只读的,promise则用来设置值,是只写的\n如果以go语言为例,promise就是管道的左端,chan \u0026lt;- ,future就是管道的右端\u0026lt;- chan\n注意,使用promise/future时,就不再只限定于返回值了,可以异步执行的过程中,由promise.setValue,和go的channel很像\n当然,也可以直接将返回值作为future\nstd::future\u0026lt;int\u0026gt; f2 = std::async(std::launch::async, [](){ return 8; }); f2.wait() f2.get() Go中的future/promise 如上所述\nasyncTask := func(){ ch := make(chan int,1) go func(){ //dosomething ch\u0026lt;-1 // work as a kind of promise }() return ch } future := asyncTask() \u0026lt;- future // this will be blocked 当然,对future的读会导致阻塞,我们可以再包装一下\nasyncTask := func(){ promise := \u0026amp;promise_st{} go func(){ //dosomething promise.SetVal(1) }() return promise.getFuture() } future := asyncTask() future.Wait() val := future.get() 设计上也不难,本质是个单生产者,单消费者的问题\ntype promise_st struct{ val interface{} ok bool ch chan interface{} } func (p *promise_st) SetVal(a interface{}){ ch \u0026lt;- a } func (p *promise_st) Wait(){ p.val = \u0026lt;- ch //atomic.CAS(\u0026amp;p.ok , false , true) p.ok = true } func (p *promise_st) Get()interface{}{ if p.ok{ return p.val } return nil } 由于go的channel已经足够强大,所以到没必要去使用future/promise,await/async\n但是知道这些东西还是很有必要的\n","id":56,"section":"posts","summary":"\u003ch1 id=\"promisefuture\"\u003ePromise\u0026amp;future\u003c/h1\u003e\n\u003cp\u003e函数式编程是一个新的编程范式,基本上,只要你的编程语言支持\u003ccode\u003e函数是一等公民\u003c/code\u003e这个说法,那么就至少支持部分的函数式编程\u003c/p\u003e\n\u003cp\u003e[TOC]\u003c/p\u003e\n\u003ch2 id=\"promise\"\u003epromise\u003c/h2\u003e\n\u003cp\u003e所谓的promise,是指对异步函数返回值的一个封装,比如就是对单个int的封装,但是由于是异步的,所以只能注册回调函数来完成当函数结束后对int进行访问\u003c/p\u003e","tags":["concurrency"],"title":"[concurrency] promise\u0026future","uri":"https://wymli.github.io/2021/03/concurrency-promisefuture/","year":"2021"},{"content":"skipList 跳表具有平均的O(logn)的时间复杂度,但最坏情况仍是O(n)\n跳表是二叉搜索树,AVL,RBTree的替代品\n这里我们不介绍如何从头开始编写skipList,但仍然介绍其中可能存在的一些关键点\n数据结构 C 如果是用c语言,我们可以这样实现一个skipList的底层数据结构\n摘自: begeekmyfriend/skiplist\n其中用到了1.柔性数组 2.从成员还原出结构体首地址 等一些trick\n用1.柔性数组,是为了保证link与skipnode是内存连续性,以便于使用2来还原出首地址,这样,st_link就不必去记录*node了,少了一个开销\n柔性数组也是动态分配的,用多少分配多少,避免多余浪费\nstruct sk_link { struct sk_link *prev, *next; }; struct skiplist { int level; int count; struct sk_link head[MAX_LEVEL]; }; struct skipnode { int key; int value; struct sk_link link[0]; }; 在st_link中,我们记录了prev,这是为了方便插入.否则如果只记录next,那么在插入前的search时,就要记录一张表,便于插入时的指针赋值\nGo 在go中,一般实现成:\n摘自: https://github.com/sean-public/fast-skiplist\ntype elementNode struct { next []*Element } type Element struct { elementNode key float64 value interface{} } 这里,len(next)就表示这个node的高度,next[i]就是第i层指向的下一个节点,不同层可能会指向到相同的节点,所以有可能next[0] == next[1]\n思考 为什么不适用上层节点也是node结构呢? 我在youtube的某些视频上看到上层节点也是node,从代码上看,很优美对称,但是会有数据的冗余.\n而且当使用额外的link结构后(c的写法),也完美的继承了这种对称,即逐层的遍历节点\nstruct skipnode { int key; void* value; struct skipnode *right; struct skipnode *down; }; 插入 在学习时,你可能学的是一层一层构建skiplist,先遍历第一层,每个node抛硬币,看自己是否能构建上层\n但在实践中,这没有必要,我们直接用一个random函数决定一个节点有几层即可\n注意,不是简单的抛到几就是几,仍然是逐层增长的,因为概率是乘法,详见后文的概率表\nstatic struct skipnode * skiplist_insert(struct skiplist *list, int key, int value) { int level = random_level(); if (level \u0026gt; list-\u0026gt;level) { list-\u0026gt;level = level; } struct skipnode *node = skipnode_new(level, key, value); // do search and insert } 搜索并插入 首先搜索\n从最高层开始逐步顺着指针遍历,找到end.key\u0026gt;newNode.key,prev.key\u0026lt;newNode.key\n然后插入,将newNode插入到prev和node之间\n__list_add(a,b,c) 函数将a插入在b,c之间,注意a,b,c只是单个st_link\n并向下一层移动(即pos\u0026ndash;,end\u0026ndash;),此时for循环由于条件直接满足而被跳过,直接执行插入\nint i = list-\u0026gt;level - 1; for (; i \u0026gt;= 0; i--) { pos = pos-\u0026gt;next; for (; pos != end; pos = pos-\u0026gt;next) { struct skipnode *nd = list_entry(pos, struct skipnode, link[i]); if (nd-\u0026gt;key \u0026gt;= key) { end = \u0026amp;nd-\u0026gt;link[i]; break; } } pos = end-\u0026gt;prev; if (i \u0026lt; level) { __list_add(\u0026amp;node-\u0026gt;link[i], pos, end); } pos--; end--; } static inline void __list_add(struct sk_link *link, struct sk_link *prev, struct sk_link *next) { link-\u0026gt;next = next; link-\u0026gt;prev = prev; next-\u0026gt;prev = link; prev-\u0026gt;next = link; } Go中的插入 为什么要单独谈论c和go的实现呢? 因为c的语言特性决定了它可以写的很炫,但是go就只能很plain的实现\n首先创建新节点\nelement = \u0026amp;Element{ elementNode: elementNode{ next: make([]*Element, list.randLevel()), }, key: key, value: value, } 然后找到key该插入的位置在各层的前一个node(注意,这个\nprevs的各个元素可能属于不同的node),因为每个node的高都不同\nprevs := list.getPrevElementNodes(key) 执行插入,遍历当前element/node的高度,替换指针\nfor i := range element.next { element.next[i] = prevs[i].next[i] prevs[i].next[i] = element } 搜索 还记得我在前面说的插入前的搜索要维护一张表吗,就是这里的list.prevNodesCache\nfunc (list *SkipList) getPrevElementNodes(key float64) []*elementNode { var prev *elementNode = \u0026amp;list.elementNode var next *Element prevs := list.prevNodesCache for i := list.maxLevel - 1; i \u0026gt;= 0; i-- { next = prev.next[i] for next != nil \u0026amp;\u0026amp; key \u0026gt; next.key { prev = \u0026amp;next.elementNode next = next.next[i] } prevs[i] = prev // 这里prevs[i]存了整个prev,其实只需要存prev[i]即可,不过反之都是指针,开销到是一样的. 是这样吗?详见后面描述的caching and search fingers } return prevs } 关于重复键值 这其实取决于你的上层数据结构的逻辑,如果你是要实现一个set,那显然不能有重复键值,遇到重复的,就直接覆盖\n超参数 根据这个repo,指出了合适的超参数选择\n抛硬币为正面的概率P为1/e,即向上增长的概率为1/e(典型的p的取值为0.25-\u0026gt;0.5) The default P values for skip lists in the wild range from 0.25 to 0.5. In this implementation, the default is 1/e, which is optimal for a general-purpose skip list. To find the derivation of this number, see Analysis of an optimized search algorithm for skip lists Kirschenhofer et al (1995).\n随机数生成器PRNG 我们不能使用全局的随机数生成器,因为这样的化,多个跳表之间就会造成冲突,有锁的竞争\n因此,每个跳表一个rand.Source\nrandSource: rand.New(rand.NewSource(time.Now().UnixNano())), 概率表 一个典型的层数将如下计算\nstatic int random_level(void) { int level = 1; const double p = 0.25; while ((random() \u0026amp; 0xffff) \u0026lt; 0xffff * p) { level++; } return level \u0026gt; MAX_LEVEL ? MAX_LEVEL : level; 很明显,我们可以预先记录好一个概率表,然后只计算一次rand,这意味着,我们将这一次rand视为多次rand的乘积,而概率表也是概率的乘积,因此直接比较\nfunc probabilityTable(probability float64, MaxLevel int) (table []float64) { for i := 1; i \u0026lt;= MaxLevel; i++ { prob := math.Pow(probability, float64(i-1)) table = append(table, prob) } return table } func (list *SkipList) randLevel() (level int) { // Our random number source only has Int63(), so we have to produce a float64 from it // Reference: https://golang.org/src/math/rand/rand.go#L150 r := float64(list.randSource.Int63()) / (1 \u0026lt;\u0026lt; 63) level = 1 for level \u0026lt; list.maxLevel \u0026amp;\u0026amp; r \u0026lt; list.probTable[level] { level++ } return } 缓存,caching and search fingers 当我们把整个节点缓存下来,有利于后面的搜索,而不仅仅是缓存那一层,见https://github.com/sean-public/fast-skiplist#caching-and-search-fingers\nConclusion 个人认为go中的实现可能更好,因为它避免了去逐层的访问,而是统一的去访问一个node,再去访问他的next数组,找到对应层的下一个node\n","id":57,"section":"posts","summary":"\u003ch1 id=\"skiplist\"\u003eskipList\u003c/h1\u003e\n\u003cp\u003e跳表具有平均的O(logn)的时间复杂度,但最坏情况仍是O(n)\u003c/p\u003e\n\u003cp\u003e跳表是二叉搜索树,AVL,RBTree的替代品\u003c/p\u003e\n\u003cp\u003e这里我们不介绍如何从头开始编写skipList,但仍然介绍其中可能存在的一些关键点\u003c/p\u003e","tags":["dataStructure"],"title":"[dataStructure] skip-list","uri":"https://wymli.github.io/2021/03/data-structure-skip-list/","year":"2021"},{"content":"索引中的平衡树:b-tree,b-plus-tree 主要介绍数据库的索引,及其实现,平衡多叉树\n什么是索引 想象一下,假设db没有任何数据结构驻留在内存,其一切存储都放在disk,那么想找到一张表的一个行,就必须把表的所有页取到memory,逐个比较各行. 因此我们必须放置一些特定的数据结构在内存中,方便快速查找(但不是缓存)(也不总是在内存中)\n对于一张表结构,它自身就记录自己在磁盘上的位置和大小,我们可以快速找到它,但是它包含很多页,我们无法确定某一行在哪一页,只能扫描全表.\n索引完成了这样一个功能, 快速找到某一列的值所在的行的在磁盘上的页(os虚拟页,实际在磁盘); 注意,无法找到在那一页的哪一个位置,最终读到内存页后还是扫描整个页,因此文档也指出了,对于小表,加不加索引意义不大,对于要查出绝大部分数据的大表,也不要用索引,不如直接全表扫描\nmysql 官方文档: mysql-indexes ,innodb-index-types\n所谓索引(index),就是给定一个键,快速返回其在磁盘上的存储页(索引本身是一个键值存储数据结构),然后再根据这个位置磁盘的磁头快速旋转到对应扇区(一个扇区512B,但InnoDB的页16KB),读取一整块数据,通过DMA方式从磁盘缓冲区copy到内核缓冲区,然后中断,对应db进程被唤醒,read到用户缓冲区,遍历整页的数据,找到record(实际上页16KB,一条record如果1KB,就有16行,最差比较16次,其实是不慢的),通过tcp本机通信发送给client.\n你可以将其理解为一个map,其键是某一列的取值,其值是对应页所在磁盘的位置.(索引树本身是要持久化在磁盘的,一个结点一页)\n其实这更像是搜索引擎领域中的倒排索引(反向索引),给定关键词,返回其所在页;正向索引则是像普通目录一样,给定页,返回其关键词.\n事实上,数据库的索引常见的实现算法就是hash和b/b+树,其本身就是一个存储型数据结构,可作为in-memory cache/db,当设置特殊的kv时,便可视作索引\nhash分为静态hash和动态hash(依据其是否在runtime时会有分裂桶(增加桶数)的操作),redis作为一个in-memory cache/db,其dict结构就是用的动态哈希算法中的可拓展哈希\nhash和b/b+树的各自特点:\nhash表是无序的,在使用==时很快,对于不等号,有点无能为力\nb/b+树是有序数据结构,在不等号时很快,但本质还是搜索树,判断相等要多分遍历,但也不慢\n实际上索引的树的结点都需要持久化放在磁盘,并且一般来说每个结点一个页\n高度为 3 的 B+ 树就能够存储千万级别的数据: 比如高度为2的树,满载时根节点有16KB/14B =1170个指针,这里14是指主键8B,指针6B,由于一条记录1KB,则一页只能存放16条记录,则总共:1170*16 = 18720 条记录; 高度为3时:1170*1170*16*21902400 条记录\n使用 ALTER TABLE students ADD INDEX idx_name_score (name,score); 这一段sql就为表students,添加了名为idx_name_score的索引,它是针对列name和score的索引.\n我们常称为: 对列name,score创建索引\n显然,它将列的值作为key,行的磁盘地址作为value,当key越不同时,冲突越少,效率越高. db会默认为主键创建索引.\n对表的增删查改,显然也要及时更新索引,因此这是一个缺点,对于hash表和b/b+树,都可能触发整个数据结构的整形(hash是桶的分裂,b/b+树是平衡化),会拖慢速度,但没办法,没有银弹.\n在InnoDB中,默认采用B+树作索引,对于主键的索引,以\u0026lt;primary_id,page\u0026gt;的方式,辅助索引以\u0026lt;col,primary_id\u0026gt;的方式,辅助索引(secondary index)指出了聚簇索引(clustered index)(一般的,主键索引)以外的所有索引\n平衡树 由于大多数db engine会采用b/b+树,比如innodb使用b+树作为索引,我们这里就不探讨动态哈希了,哈希由于对区间查找支持太差,更适合作为键值缓存数据库,比如redis\n平衡二叉搜索树 二叉搜索树(二叉排序树,查找树),相比都知道,其在结构上是类似一个二叉堆,但是满足左子节点\u0026lt;父节点\u0026lt;右子节点,相比之下,用来实现优先队列(大/小顶堆)的二叉堆结构,只需要满足左子节点\u0026lt;父节点,右子节点\u0026lt;父子节点\n平衡化: 这意味着插入/删除元素的时候,不能直接简单的插入删除,需要对局部结构进行reshape(旋转),以满足插入/删除后仍然是平衡树\n平衡树: 如果一棵树,其子节点都是平衡树,并且深度相差不超过1,则称为平衡树\n平衡化的旋转操作比较复杂,如果不是专门去实现一个平衡树,我个人认为了解它需要平衡化就行了\n有序性: 当对平衡二叉搜索树进行中序遍历时,将得到一个递增序列\nB树 B树是平衡二叉搜索树的进阶版,可以认为,B树是平衡多叉搜索树,在这里,平衡是严格平衡,不再是相差为1,而是都一样的高度\n这是google/btree的go语言实现版\n// degree指度数,一个node的最小item数是degree-1,最大是degree*2-1 // order指阶数,一个node的最大子树个数是order,最大item数是order-1,最小item数是order/2 // 所以: order-1 等于 degree*2-1 , 一个2度树是一个4阶数 type BTree struct { degree int length int root *node cow *copyOnWriteContext } // node指tree中的一个节点 type node struct { items items children children cow *copyOnWriteContext } type items []Item type children []Item // 显然items代表父节点自己存储的值数组,而children代表指向子节点的指针数组 // Item represents a single object in the tree. type Item interface { // Less tests whether the current item is less than the given argument. Less(than Item) bool } 对于m阶的b树,每个子节点不能有超过m-1个关键字,非根结点至少有Math.ceil(m/2)-1个关键字\n插入节点时,首先寻路到了叶子节点(注意一定是叶子节点,否则是replace而不是insert),正常按顺序找到位置,插入,对于go实现,可以通过*items = copy((*items)[i:] , (*items)[i+1:]) 如果叶子节点关键字数超过了m-1,则将整个items二分,将中间的关键字append到父节点\n当一层满了之后,才会插入到下一层!\nB+树 B+树显然是B树的升级版\nB+树的特点是,非叶子节点不保存(key-value),而只是保存key用于比较,所有的数据item都在叶子节点\n叶子节点的最右指针将会指向临近的叶子节点\nB+数相对B数的优点 快速性: B+树的层级比B树小,查的更快(基本上看其他资料,都有提到这个,但我实在不懂为什么会更矮:2021/03/16更新:因为B+树的非叶子节点没有数据,而一个数据要1kb,至少相当于100个指针了,所以B+树每个节点能容纳的叉数更多(建立在一个节点存一个页的情况))\n稳定性: B+树由于非叶子节点不存储值,所以每次查询必须一直查到叶子节点,对于不同的键查询时间差距不大(这个是建立在其本身和B树的查询速度差距不大的前提下)\n有序性: 虽然B树作为搜索树也可以通过中序遍历获取有序列,但是B+树更加便捷,因为叶子节点之间是直接通过指针相连的(所以在查区间数据时很有优势)\n有些地方说,B+树有利于全表扫描,但根据文档的建议,对于要查出大部分record的查询来说,不要用索引,直接全表扫描\n2020/03/16更新,今天面试问了为什么稳定性是一个好的特性呢,可惜我不知道! 面试官说是和硬盘的特性有关,我搜索了一下,B+树比B树更满足硬盘的特性,因为硬盘读取慢,我们希望降低io次数,对于3层B+树,就可索引2kw个数据,这意味着4次io就可索引到2kw个数据,很恐怖! 反之对B树,由于数据要放在非叶子节点,所以一页最多16个指针,16^3远小于2kw\n但是对于内存中的存储,多用B树,因为不再需要io\n使用注意: 使用B/B+树时,不建议使用自增主键,因为自增主键由于主键的严格有序性,导致每插入一个元素(最终都会在最后一个叶子节点插入),就会触发一次分裂\n2021/03/16更新,这句话就是在放屁,自己可以压测一下,无论是avl树还是rb树还是b树,在插入递增key时,绝对是比随机key性能好的\n更何况b+树呢\ngif来源博客\n为什么InnoDB使用B+树 等价问题是,为什么InnoDB为什么采用B+树,而不是B树和动态哈希?\n显然,对于OLTP来说,所有提到的优点在前文已经说明了.\n","id":58,"section":"posts","summary":"\u003ch1 id=\"索引中的平衡树b-treeb-plus-tree\"\u003e索引中的平衡树:b-tree,b-plus-tree\u003c/h1\u003e\n\u003cp\u003e主要介绍数据库的索引,及其实现,平衡多叉树\u003c/p\u003e\n\u003ch2 id=\"什么是索引\"\u003e什么是索引\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e想象一下,假设db没有任何数据结构驻留在内存,其一切存储都放在disk,那么想找到一张表的一个行,就必须把表的所有页取到memory,逐个比较各行. 因此我们必须放置一些特定的数据结构在内存中,方便快速查找(但不是缓存)(也不总是在内存中)\u003c/p\u003e","tags":["Database"],"title":"[DB] b-tree","uri":"https://wymli.github.io/2021/03/db-b-tree/","year":"2021"},{"content":"数据库设计范式 所谓设计范式,可理解为设计一张表的各个列的规则\n定义 键和函数依赖\n键 所有的键(key) 都是 a set of one or more attributes\n主属性(prime attribute) 至少出现在一个候选键中的属性\n超键(super key) 一个超键能唯一标识一个元组,其属性集闭包是所有属性的集合\n候选键(candidate key) 最小的超键,即任何一个子集都不能是超键; 超键就是候选键加上其他属性\n主键 存在多个候选键组,选一组成为主键\n函数依赖 α-\u0026gt;β表示α能决定β, β函数依赖于α\n对键的部分函数依赖: (a,b)-\u0026gt;(c,d,e) 且 a-\u0026gt;c , 则c部分函数依赖于候选键(a,b)\n传递依赖: a-\u0026gt;b, b-\u0026gt;c, 则称c传递依赖于a;\n所有的部分函数依赖都是传递依赖: (a,b)-\u0026gt;(c,d,e) 且 a-\u0026gt;c , 则c传递依赖于候选键(a,b)\n四范式 1NF\n给定行与列, 能得到唯一的值 每一列都不可分割成多个子属性 2NF\nIt is of historical significance only and is not used in practice.\n非主属性不会部分函数依赖于候选键,即不存在某个主属性能决定非主属性,除非这个主属性是候选键\n简单来看: 非主属性不能函数依赖于主属性\n否则两个属性应该独立成表 3NF\n学术角度: 对于一个非平凡函数依赖α-\u0026gt;β,要么α是超键,要么β-α的元素在某个候选键中(可以是不同的元素在不同的候选键中)\n简单来讲: 非主属性不能函数依赖非主属性,即禁止传递依赖 (候选键-\u0026gt;非主属性-\u0026gt;非主属性)\n否则两个非主属性应该独立成表 BCNF:\n非平凡函数依赖的左端必是超键(而不能是一个候选键的某个属性) 主属性不能函数依赖于主属性 在表述中,一会是超键,一会是候选键,这其实是自然的,候选键本身就会依赖于超键\n消去非主属性对键的部分函数依赖\n指非主属性不依赖主属性(这个主属性不是键) 消去非主属性对键的传递函数依赖\n指非主属性不依赖非主属性 消去主属性对键的传递函数依赖\n指主属性不依赖主属性(一般指有多个候选键组,一个候选键组里的主属性依赖另一个候选键组的主属性) ","id":59,"section":"posts","summary":"\u003ch1 id=\"数据库设计范式\"\u003e数据库设计范式\u003c/h1\u003e\n\u003cp\u003e所谓设计范式,可理解为设计一张表的各个列的规则\u003c/p\u003e\n\u003ch2 id=\"定义\"\u003e定义\u003c/h2\u003e\n\u003cp\u003e键和函数依赖\u003c/p\u003e\n\u003ch3 id=\"键\"\u003e键\u003c/h3\u003e\n\u003cp\u003e所有的键(key) 都是 a set of one or more attributes\u003c/p\u003e\n\u003cp\u003e主属性(prime attribute) 至少出现在一个候选键中的属性\u003c/p\u003e","tags":["Database"],"title":"[DB] rule","uri":"https://wymli.github.io/2021/03/db-rule/","year":"2021"},{"content":"About sql statement\u0026amp;index spec 参考但不限于Java开发手册（嵩山版）\n关于索引 与索引有关的注意事项,基本都集中在一个sql语句它到底是否正确使用了索引,这可以通过explain后的extra列来识别语句执行速度,但是在理论上,我们知道索引是一颗B+树,所以只要了解了B+树的构造,那么自然可以从理论上去识别一个条件查询是否能使用索引\n联合索引 单键索引没什么好讲的,重点是多键索引\n其非叶子节点的搜索键是多个值,比如__(a,b,c) = (4,7,5)__\n那么(a\u0026lt;4,*,*)会排序到这个索引的左边,如果a == 4,那么再比较b\u0026hellip;\n所以最终,这个索引的左边会是\n(a\u0026lt;4,*,*) , (a=4,b\u0026lt;7,*),(a=4,b=7,c\u0026lt;5)\n右边会是\n(a\u0026gt;4,*,*) , (a=4,b\u0026gt;7,*) , (a=4,b=7,c\u0026gt;=5)\n使用场景 指定联合索引(a,b,c)\n范围查询 如果sql是(语法为EBNF)\nwhere (a \u0026lt; * | a \u0026gt; *) where a = * [and (b \u0026gt; * | b \u0026lt; *)] where a = * and b = * [and (c \u0026gt; * | c \u0026lt; *)] where a = * order by b 那么显然可以使用b+树的联合索引\n这就是最左前缀匹配原则\n并且指定了a后,b,c是天然排序的; 指定a,b同理\n失败案例 以下无法使用索引\nwhere b = * where b = * and c = * where a \u0026gt; * and b \u0026gt; * where a \u0026gt; * order by b 原则 建立联合索引时,区分度最高的在左边(所谓区分度,是指唯一性) 除非,常用查询是where b = * \u0026amp; a \u0026gt; *,即使a区分度更高,也应该设置索引index_b_a 这是因为,where b = *后,对a是天然排序的,若以a为第一个索引,那么查b=*,就需要对b进行filesort 覆盖索引 所谓覆盖索引,就是说对于辅助索引,可以直接查出想要的数据,而不再需要回表查询\n其他 禁止对索引列进行计算\n使用\nselect * from users where adddate\u0026lt;'2007-01-01'\n而不是\nselect * from users where YEAR(adddate)\u0026lt;2007\nLimit 前置条件: k 是辅助索引\nselect * from table_name where k = 1 limit 3 offset 100000\n一方面是将会查找出100003条记录,再丢弃掉前100000条记录,这会导致极高的延时\n再其次就是会有100003次回表查询(即没找到一个辅助索引对应的pk,就回聚簇索引查找record)\n因此,需要使用子查询,防止超多次回表:\nselect * from table_name as t1 inner join (select pk from table_name where k =1 limit 3 offset 100000) as t2 on t1.pk = t2.pk 这其实利用了索引覆盖的特点,由于我们在子查询中是查pk,不需要回表,所以直接放回了100003条pk,然后再统一回表查一次\nType 要精确存储某个类型时,使用decimal(定点数),而不是浮点数\n","id":60,"section":"posts","summary":"\u003ch1 id=\"about-sql-statementindex-spec\"\u003eAbout sql statement\u0026amp;index spec\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e参考但不限于\u003ccode\u003eJava开发手册（嵩山版）\u003c/code\u003e\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch2 id=\"关于索引\"\u003e关于索引\u003c/h2\u003e\n\u003cp\u003e与索引有关的注意事项,基本都集中在一个sql语句它到底是否正确使用了索引,这可以通过explain后的extra列来识别语句执行速度,但是在理论上,我们知道索引是一颗B+树,所以只要了解了B+树的构造,那么自然可以从理论上去识别一个条件查询是否能使用索引\u003c/p\u003e","tags":["Database"],"title":"[DB] sql spec","uri":"https://wymli.github.io/2021/03/db-sql-spec/","year":"2021"},{"content":"记一次云端部署web服务器 本来以为和在自己电脑上本地部署一样,没想到还是遇到很多自己不熟悉的地方,云端服务器会涉及到更多linux相关的知识.\n首先是云服务器的环境配置 典型的,我们是通过ssh上服务器(22端口),如果是windows,则是远程桌面的3389端口,这两个端口连同80和443端口都是默认开放的. 如果想使用其他端口必须在防火墙中设置入站白名单\nssh配置 ​\tssh客户端登陆时,需要配置ssh密钥,将私钥文件的路径放置在ssh的config文件的对应字段就行\n​\t对于你要登陆的用户,一定要在/home/$user/.ssh下有一个authorized_keys目录记录公钥. 本来如果是自己生成密钥的话,直接放在那就好了,但是如果是腾讯云,通过可视化界面帮助你生成密钥,在密钥与实例绑定时,会默认放在root目录下,即你只能登陆root用户. 解决方法也很简单,复制一份到/home/$user/.ssh/就行了\n文件夹权限 我的程序调用了err := os.MkdirAll(folderPath, 0777) 他会递归的创建文件夹/文件,本来以为这是一个正常运行的代码,结果却出乎意料,无论我怎么设置文件权限perm,都无法如愿,最终的文件夹权限都是0774\n后来才知道,还要减去默认的umask才是最终的文件权限,而普通用户的umask是others的w\n对于文件夹的权限,r: 可以list文件夹, w:可以对文件夹内的文件增删查改, x:可以cd进文件夹\noldMask := syscall.Umask(0) defer syscall.Umask(oldMask) // 或者手动修改 os.Chmod(...,0744) web服务器必须以root模式启动 如果你想监听80端口,那么必须以root启动,则是linux的规则,\u0026lt;1024的保留端口只对root开放\n后台运行服务器 一般的,我们会用\u0026amp;来后台启动服务器,比如: sudo ./app \u0026amp; ,\n对于后台启动,当然也可以守护模式: 你的web后端程序代码可以dup文件描述符,fork两次,setsid然后进入守护模式\n虽然这是服务器是成功在后台启动了,但是其还是和当前的shell绑定的,所以程序的输出还是会输出到该终端上,我们还需要重定向输出\nsudo ./app \u0026gt; ./log 2\u0026gt;\u0026amp;1 \u0026amp;\n这里, \u0026gt; ./log 代表标准输入重定向到./log , 2\u0026gt;\u0026amp;1代表标准错误重定向到标准输出,之所以是用\u0026amp;1,是为了和普通文件区分,不然我难道不可以输出到名为1的文件吗?\nsudo运行导致的两个进程 运行sudo ./app,使用ps -aux将会发现两个进程 ./app 和 sudo ./app\n当使用sudo ./app执行代码时，会首先启动一个root用户的shell，但是这个shell的名字就叫做\u0026quot;sudo ./app\u0026quot;，直接引起歧义。\nnohup 忽略sighup信号,该信号在session shell关闭后发出给属于这个shell的所有进程\n注意,如果以sudo启动应用,那么正如前文所说,开启了一个sudo ./app的shell,所以你关闭你的用户shell是不影响程序的,即使不用nohup\n但实际上,只是用\u0026amp;就足够了,即使关闭了终端,也可以继续运行\nlsof -i:80 list open fd 打印出打开的文件描述符,我们知道unix一切皆文件; -i:80 80端口\n要想看到root占用的端口,加sudo\nnetstat -ntlp 查看所有的tcp端口占用情况\np: 显示program名,即对应的程序名; t: tcp; l: 只显示listen端口; n:不显示别名\n要想看到root占用的端口,加sudo\njobs jobs 指令可以方便的看到本用户在本shell启动的后台程序\n但如果换一个bash,就不行了\n","id":61,"section":"posts","summary":"\u003ch1 id=\"记一次云端部署web服务器\"\u003e记一次云端部署web服务器\u003c/h1\u003e\n\u003cp\u003e本来以为和在自己电脑上本地部署一样,没想到还是遇到很多自己不熟悉的地方,云端服务器会涉及到更多linux相关的知识.\u003c/p\u003e\n\u003ch2 id=\"首先是云服务器的环境配置\"\u003e首先是云服务器的环境配置\u003c/h2\u003e\n\u003cp\u003e典型的,我们是通过ssh上服务器(22端口),如果是windows,则是远程桌面的3389端口,这两个端口连同80和443端口都是默认开放的. 如果想使用其他端口必须在防火墙中设置入站白名单\u003c/p\u003e","tags":["deploy"],"title":"[deploy] server deploy","uri":"https://wymli.github.io/2021/03/deploy-server-deploy/","year":"2021"},{"content":"Built-in map\u0026amp; sync.Map \u0026amp; ConcurrentMap 并发map,是指多线程安全的map数据结构, 我们知道go语言原生的map是不支持并发的, 要想获得一个并发map,\n我们有如下的几种方案:\nmap with mutex sync.Map 读写map分级 orcaman/concurrent-map 分片 Map built-in map本质是动态哈希算法实现,在运行过程中桶会分裂,导致元素的迁移.\n这也是经典的遍历无序,取出的value不可取地址的原因,以及衍生的value作为结构体时其字段无法赋值的原因 如何处理并发也是一个比较难的问题了,我当时学数据库实现线性哈希的时候也思考了很久这个问题.\n但是基于当时的我的知识的思考,其实无异于在想如何开汽车登上月球,没有一定知识积累的思考,真就只是想想而已!\n最后,我果断的加上了读写锁 :)\n这里收录一点关于built-in map的一些冷知识\n声明和初始化:\n空map: 声明+初始化 make(map[int]int) map[int]int{} nil map: 声明 var a map[int]int 和slice不一样,空map和nil map有着一定的差距 相同: 空map和nil map的读,都会返回default_value,false 不同: nil map的写触发panic,而空map的写正常; nil map可与nil比较为true 相比之下,slice的append操作对于空切片和nil切片都是一致的,除了与nil比较之外 任何类型都可以作为key吗?\n错,必须是可比较类型; 其中 Slice，Map，Function 是三个内置的唯一的不可比较类型 结构体可比较吗? 同一结构体定义的不同实例: 只要其字段不包含不可比较类型,就可以比较 ref 不同结构体定义的不同实例: 显然不行,因为go是强类型语言! 如果它们定义相同,可以尝试先cast 再加上一嘴: 深度比较: reflect.DeepEqual() ,除了判断值,还会判断底层指针指向的值是否相等! 删除\ndelete (map_,key_) , 只会将其删除位置1,而不会释放空间 map是一种只增不减的数据结构! 对map的clear,直接创建一个新的map覆盖,原map将会被gc 如何有序遍历map\ntype orderedMap (type T1,t2) struct{ _map map[T1]T2 _slice []T1 } // 假装泛型,这泛型用()小括号是真的让人无语! func (m *orderedMap(T1,T2))Add(k T1,v T2){ m._map[k] = v m._slice = append(m._slice , v) sort.Sort(m) } func (m *orderedMap(T1,T2))Iter() func()(T1,T2){ m = snapshot(m) i := -1 return func(){ i++ return m._map[m._slice[i]] } } 键的优化: 据说, golang为 uint32、uint64、string 作为key时提供了fast access,可以在runtime/map_fast32,\u0026hellip; runtime/map_faststr,找到\n不过我看了半天代码,发现自己看不懂 Map with mutex 很显然,性能将不再是一个需要多么谈及的话题.mutex将会导致go程阻塞而被调度出运行队列\ntype concurrentMap(type T1,T2) struct{ _map map[T1]T2 rwMutx sync.RWMutex } sync.Map Go1.9 推出了sync.Map\n以下场景适合sync.Map: (1) when the entry for a given key is only ever written once but read many times, as in caches that only grow - 这也是concurrent-map的文档里说的,sync.Map只适合append-only的场景(only grow) (2) when multiple goroutines read, write, and overwrite entries for disjoint sets of keys. 根据这个issue: https://github.com/golang/go/issues/21035 sync: reduce contention between Map operations with new-but-disjoint keys 我想 (2) 应该不再是一个适用场景 其内部实现是用两个built-in map 加 single-mutex 实现\n实现:\ntype Map struct { mu Mutex // read contains the portion of the map's contents that are safe for // concurrent access (with or without mu held). // // The read field itself is always safe to load, but must only be stored with // mu held. // // Entries stored in read may be updated concurrently without mu, but updating // a previously-expunged entry requires that the entry be copied to the dirty // map and unexpunged with mu held. read atomic.Value // readOnly // dirty contains the portion of the map's contents that require mu to be // held. To ensure that the dirty map can be promoted to the read map quickly, // it also includes all of the non-expunged entries in the read map. // 这里说dirty map can be promoted to the read map,个人感觉会误解为是dirty被promote到了read // 实际上也没错,但更准确的是覆盖了,后续的第一次写将会导致遍历read写回dirty.这个遍历更像是promote? // // Expunged entries are not stored in the dirty map. An expunged entry in the // clean map must be unexpunged and added to the dirty map before a new value // can be stored to it. // // If the dirty map is nil, the next write to the map will initialize it by // making a shallow copy of the clean map, omitting stale entries. dirty map[interface{}]*entry // misses counts the number of loads since the read map was last updated that // needed to lock mu to determine whether the key was present. // // Once enough misses have occurred to cover the cost of copying the dirty // map, the dirty map will be promoted to the read map (in the unamended // state) and the next store to the map will make a new dirty copy. misses int } type readOnly struct { m map[interface{}]*entry amended bool // true if the dirty map contains some key not in m. } type entry struct { p unsafe.Pointer // *interface{} // 用指针,是为了方便的 atomic.CompareAndSwapPointer,可以直接修改read.m中本来应该只读的数据 } // 这里的interface{}, 就是键值对的值,LoadOrStore(k ,v interface{}) 中的v // 删除: p将指向 unsafe.Pointer(new(interface{})) func newEntry(i interface{}) *entry { return \u0026amp;entry{p: unsafe.Pointer(\u0026amp;i)} } 相信这个图加上上面的注释已经解释的差不多了 ref\nsync的结构为: type sync.Map{ mutex read{m map[interface{}]*entry , amended } atomic.Value dirty map[interface{}]*entry misses } 一文以蔽之 ​\t在大多数时刻,dirty都是read.m的超集,除了dirty刚覆盖read.m后,dirty被置为nil,read.amend置为false,表示read.m即为全部的数据, 在下一次写到来后,将会遍历read.m,将kv存进dirty,并将read.amend置为true,表示dirty是read.m的数据的超集!\n​\t什么时候触发dirty对read.m的覆盖? 当 m.misses \u0026gt;= len(m.dirty)时\n注意,无效的读Load也会导致miss次数增加!\n总结一下sync.map的关键 对于本来的map[interface{}] interface{} ,用unsafe.Pointer存储\u0026amp;value, 即unsafe.Pointer是*interface{};\n导致可以利用atomic.CompareAndSwapPointer,直接操作readonly map,而无需加锁即可并发 dirty map大多数时候都是readonly map的超集!除了短暂的dirty覆盖read.m后的nil\n覆盖后的第一次写dirty,会导致for range read.m, copy键值到dirty\n适用于读多写少\nConcurrentMap 通过对内部map进行分片，降低锁粒度，从而达到最少的锁等待时间(锁冲突)\n所谓分片,是指原先的map是一个大map,所有的key计算完的hash都是一个冲突域\n但是我现在不再是一个大map,而不是分成多个小map,我先计算key的一个hash,将其映射到小map上,然后对小map操作.\n这其实依赖于短时间内多个连续到来的key的hash值不同,那么它们就可以并行,否则就等待锁.\n在此种情况下,hash函数的选择也至关重要,对于短时间内无序到来的key序列,如何尽可能的计算出短时间内不同的hash值 // A \u0026quot;thread\u0026quot; safe map of type string:Anything. // To avoid lock bottlenecks this map is dived to several (SHARD_COUNT) map shards. // shard: 碎片 var SHARD_COUNT = 32 type ConcurrentMap []*ConcurrentMapShared // A \u0026quot;thread\u0026quot; safe string to anything map. type ConcurrentMapShared struct { items map[string]interface{} sync.RWMutex // Read Write mutex, guards access to internal map. } 写 Store: 很简单,通过 shard := m.GetShard(key) 获得该key对应所在的ConcurrentMapShared,然后加锁,操作,释放锁;\n只要短时间内到来的key计算的hash值不同,那么就不会有锁竞争\n// Sets the given value under the specified key. func (m ConcurrentMap) Set(key string, value interface{}) { // Get map shard. shard := m.GetShard(key) shard.Lock() shard.items[key] = value shard.Unlock() } hash函数(Fowler–Noll–Vo hash function) ref\nfunc (m ConcurrentMap) GetShard(key string) *ConcurrentMapShared { return m[uint(fnv32(key))%uint(SHARD_COUNT)] } // Fowler–Noll–Vo hash function: func fnv32(key string) uint32 { hash := uint32(2166136261) const prime32 = uint32(16777619) for i := 0; i \u0026lt; len(key); i++ { hash *= prime32 hash ^= uint32(key[i]) } return hash } 这个并发map最核心的思想已经讲完了,简单,却实用! 单个map也许做不了并发,但两个map(一读一写,写是读超集)搭配一个锁就可以做还行的并发,多个平行的map加 map级别的锁就能做很不错的并发\n除了并发的核心,这个库的其他代码其实也值得学习!\n比如并发中的扇入模式 利用chan,每个shard开启一个go程,并发返回所有的Key: 如果是同步的算法,那么时间复杂度是O(n^2),遍历了两次. 但使用了go程进行并发加速\n第一次计算有多少个key,即count,是有必要的,正是这个数值的确定,导致我们可以安心的创建count个缓冲的chan,并关闭通道\n对于无缓冲通道,适合只有一个go程生成数据,常见于lazy evaluate\n// Keys returns all keys as []string func (m ConcurrentMap) Keys() []string { count := m.Count() ch := make(chan string, count) go func() { wg := sync.WaitGroup{} wg.Add(SHARD_COUNT) for _, shard := range m { go func(shard *ConcurrentMapShared) { shard.RLock() for key := range shard.items { ch \u0026lt;- key } shard.RUnlock() wg.Done() }(shard) } wg.Wait() close(ch) }() keys := make([]string, 0, count) for k := range ch { keys = append(keys, k) } return keys } 有缓冲优于无缓冲 // Iter returns an iterator which could be used in a for range loop. // // Deprecated: using IterBuffered() will get a better performence func (m ConcurrentMap) Iter() \u0026lt;-chan Tuple { chans := snapshot(m) ch := make(chan Tuple) go fanIn(chans, ch) return ch } // IterBuffered returns a buffered iterator which could be used in a for range loop. func (m ConcurrentMap) IterBuffered() \u0026lt;-chan Tuple { chans := snapshot(m) total := 0 for _, c := range chans { total += cap(c) } ch := make(chan Tuple, total) go fanIn(chans, ch) return ch } 个人认为,对于有缓冲的通道,有一个特别大的优点就是,发送完数据就可以直接关闭了;\n而如果无缓冲,就会一直阻塞,依赖于读的速度\nshard.RLock() chans[index] = make(chan Tuple, len(shard.items)) wg.Done() for key, val := range shard.items { chans[index] \u0026lt;- Tuple{key, val} } shard.RUnlock() close(chans[index]) 用一个简单的map分片解决了并发问题,而且肉眼可以看出性能不会太差,虽然占空间, 但仍然可以称之为优雅!\n","id":62,"section":"posts","summary":"\u003ch1 id=\"built-in-map-syncmap--concurrentmap\"\u003eBuilt-in map\u0026amp; sync.Map \u0026amp; ConcurrentMap\u003c/h1\u003e\n\u003cp\u003e并发map,是指多线程安全的map数据结构, 我们知道go语言原生的map是不支持并发的, 要想获得一个并发map,\u003c/p\u003e\n\u003cp\u003e我们有如下的几种方案:\u003c/p\u003e","tags":["Golang"],"title":"[Go] concurrentMap","uri":"https://wymli.github.io/2021/03/go-concurrentmap/","year":"2021"},{"content":"Error go的error一直是被人诟病的,对于菜鸡来说无非是每调用一个函数就要判断一下if err!=nil{return err}\n而对于进阶一点的程序员,则会诟病它的error接口设计的太烂,只要实现了Error(),就是一个error,这导致难以比较\n直接返回error是一种错误的做法,因为当error被打印出来的时候,你无法知道这个error产生的调用过程,而只会得到一个干巴巴的最终原因\n因此,为了方便,我们要实现自己的error系统\nErrorx 这里以errorx这个包为例\nFeature 首先看看它的feature\nNo extra care should be required for an error to have all the necessary debug information; it is the opposite that may constitute a special case There must be a way to distinguish one kind of error from another, as they may imply or require a different handling in user code Errors must be composable, and patterns like if err == io.EOF defeat that purpose, so they should be avoided // 这里是因为error的判断完全归结为接口类型的判断,这取决于类型和值,即使是对于一样的字符串,也有着不一样的地址,导致不等 Some context information may be added to the error along the way, and there must be a way to do so without altering the semantics of the error It must be easy to create an error, add some context to it, check for it A kind of error that requires a special treatment by the caller is a part of a public API; an excessive amount of such kinds is a code smell 看完之后,我们就大概知道std error的局限在哪里了\n在我们自定义的error系统中,我们至少要解决\nerror应该是可比较的,这种可比较不应该和它Error()后的label有关(有点kind和type的感觉) error既要有可变的类型type,也要有不变的特性trait error应该可以较方便的追加上下文 error处理应该较快 Example var user_namespace_1 = errorx.NewNamespace(\u0026quot;user_namespace_1\u0026quot;) var user_trait_1 = errorx.RegisterTrait(\u0026quot;user_trait_1\u0026quot;) var user_property_1 = errorx.RegisterProperty(\u0026quot;user_property_1\u0026quot;) var user_property_1_p = errorx.RegisterPrintableProperty(\u0026quot;user_property_1_p\u0026quot;) func main() { err := errorx.AssertionFailed.New(\u0026quot;1\u0026quot;).WithProperty(user_property_1, \u0026quot;test1\u0026quot;).WithProperty(user_property_1_p, \u0026quot;test1_p\u0026quot;) fmt.Printf(\u0026quot;%v\\n\u0026quot;, err) fmt.Printf(\u0026quot;typecheck: %t\\n\u0026quot;, err.IsOfType(errorx.AssertionFailed)) fmt.Printf(\u0026quot;traitcheck: %t\\n\u0026quot;, err.HasTrait(errorx.Timeout())) err = errorx.Decorate(err, \u0026quot;2\u0026quot;).WithProperty(user_property_1, \u0026quot;test2\u0026quot;).WithProperty(user_property_1_p, \u0026quot;test2_p\u0026quot;) fmt.Printf(\u0026quot;%v\\n\u0026quot;, err) err = errorx.IllegalArgument.Wrap(err, \u0026quot;3\u0026quot;) fmt.Printf(\u0026quot;%v\\n\u0026quot;, err) err = errorx.NewType(user_namespace_1, \u0026quot;userErrorType\u0026quot;, user_trait_1).Wrap(err, \u0026quot;4\u0026quot;) fmt.Printf(\u0026quot;%v\\n\u0026quot;, err) fmt.Printf(\u0026quot;traitcheck: %t\\n\u0026quot;, err.HasTrait(user_trait_1)) } PS C:\\Users\\salvare000\\Desktop\\benchmark\\errorx\u0026gt; go run . common.assertion_failed: 1 {user_property_1_p: test1_p} typecheck: true traitcheck: false 2 {user_property_1_p: test2_p}, cause: common.assertion_failed: 1 {user_property_1_p: test1_p} common.illegal_argument: 3, cause: 2 {user_property_1_p: test2_p}, cause: common.assertion_failed: 1 {user_property_1_p: test1_p} user_namespace_1.userErrorType: 4, cause: common.illegal_argument: 3, cause: 2 {user_property_1_p: test2_p}, cause: common.assertion_failed: 1 {user_property_1_p: test1_p} traitcheck: true 类型系统 Error Namespace Type Trait Property 依赖关系 graph LR A[Error] --\u0026gt;B(Type) A[Error] --\u0026gt;C(Property) B[Type] --\u0026gt;D(Namespace) B[Type] --\u0026gt;E(Trait) D[Namespace] --\u0026gt;E(Trait) 类型组织Wrap graph LR A[Error1] --\u0026gt;B(Type1) A[Error1] --\u0026gt;a(Property) A[Error1] --\u0026gt;C[Error2] C[Error2] --\u0026gt;D(Type2) C[Error2] --\u0026gt;b(Property) F[Error3] --\u0026gt;E(Type3) F[Error3] --\u0026gt;e(Property) C[Error2] --\u0026gt;F[Error3] 类型组织Decorate 本质是设置Error的isTraparent = True\ngraph LR A[Error1] --\u0026gt;a(Property) A[Error1] --\u0026gt;C[Error2] C[Error2] --\u0026gt;b(Property) F[Error3] --\u0026gt;E(Type3) F[Error3] --\u0026gt;e(Property) C[Error2] --\u0026gt;F[Error3] Trait 定义trait,所有的error类型应该都包含一个或多个trait\n// Trait is a static characteristic of an error type. // All errors of a specific type possess exactly the same traits. // Traits are both defined along with an error and inherited from a supertype and a namespace. type Trait struct { id uint64 label string } 内置trait\nvar ( traitTemporary = RegisterTrait(\u0026quot;temporary\u0026quot;) traitTimeout = RegisterTrait(\u0026quot;timeout\u0026quot;) traitNotFound = RegisterTrait(\u0026quot;not_found\u0026quot;) traitDuplicate = RegisterTrait(\u0026quot;duplicate\u0026quot;) ) func newTrait(label string) Trait { return Trait{ id: nextInternalID(), label: label, } } Type 每个error type都要依托于一个namespace,即error的类型是与领域有关的,我觉得这个设计挺好\n使用一个map来表示一个type是否有一个trait(优化也很简单,用一个uint64,但是只支持最多64个traits,但大多数时候够用)\ntype Type struct { namespace Namespace parent *Type id uint64 fullName string traits map[Trait]bool modifiers modifiers } 常见内置错误类型,注册在\u0026quot;common\u0026quot; namespace下\n这些type都没有traits\nvar ( // CommonErrors is a namespace for general purpose errors designed for universal use. // These errors should typically be used in opaque manner, implying no handing in user code. // When handling is required, it is best to use custom error types with both standard and custom traits. CommonErrors = NewNamespace(\u0026quot;common\u0026quot;) // IllegalArgument is a type for invalid argument error IllegalArgument = CommonErrors.NewType(\u0026quot;illegal_argument\u0026quot;) // IllegalState is a type for invalid state error IllegalState = CommonErrors.NewType(\u0026quot;illegal_state\u0026quot;) // IllegalFormat is a type for invalid format error IllegalFormat = CommonErrors.NewType(\u0026quot;illegal_format\u0026quot;) // InitializationFailed is a type for initialization error InitializationFailed = CommonErrors.NewType(\u0026quot;initialization_failed\u0026quot;) // DataUnavailable is a type for unavailable data error DataUnavailable = CommonErrors.NewType(\u0026quot;data_unavailable\u0026quot;) // UnsupportedOperation is a type for unsupported operation error UnsupportedOperation = CommonErrors.NewType(\u0026quot;unsupported_operation\u0026quot;) // RejectedOperation is a type for rejected operation error RejectedOperation = CommonErrors.NewType(\u0026quot;rejected_operation\u0026quot;) // Interrupted is a type for interruption error Interrupted = CommonErrors.NewType(\u0026quot;interrupted\u0026quot;) // AssertionFailed is a type for assertion error AssertionFailed = CommonErrors.NewType(\u0026quot;assertion_failed\u0026quot;) // InternalError is a type for internal error InternalError = CommonErrors.NewType(\u0026quot;internal_error\u0026quot;) // ExternalError is a type for external error ExternalError = CommonErrors.NewType(\u0026quot;external_error\u0026quot;) // ConcurrentUpdate is a type for concurrent update error ConcurrentUpdate = CommonErrors.NewType(\u0026quot;concurrent_update\u0026quot;) // TimeoutElapsed is a type for timeout error TimeoutElapsed = CommonErrors.NewType(\u0026quot;timeout\u0026quot;, Timeout()) // NotImplemented is an error type for lacking implementation NotImplemented = UnsupportedOperation.NewSubtype(\u0026quot;not_implemented\u0026quot;) // UnsupportedVersion is a type for unsupported version error UnsupportedVersion = UnsupportedOperation.NewSubtype(\u0026quot;version\u0026quot;) ) Namespace // Namespace is a way go group a number of error types together, and each error type belongs to exactly one namespace. // Namespaces may form hierarchy, with child namespaces inheriting the traits and modifiers of a parent. // Those modifiers and traits are then passed upon all error types in the namespace. // In formatting, a dot notation is used, for example: // // namespace.sub_namespace.type.subtype // type Namespace struct { parent *Namespace id uint64 name string traits []Trait modifiers modifiers } Error Error类似一个链表,每改动一下,都不是在原Error上改动,而是生成一个新的Error,并将原Error作为新Error的cause字段(详见后续的Decorate)\n每个Error不仅有自己的Error Type,还有properties,这些properties都说动态的,指的的一些调用者希望传入的键值信息,因为单独的error可能只是表示某种错误,如果想知道现场的值的什么,用这个动态properties(怎么感觉和log很重叠)\ntype Error struct { message string errorType *Type cause error stackTrace *stackTrace // properties are used both for public properties inherited through \u0026quot;transparent\u0026quot; wrapping // and for some optional per-instance information like \u0026quot;underlying errors\u0026quot; properties *propertyMap transparent bool hasUnderlying bool printablePropertyCount uint8 } 行为 Decorate decorate只是用于添加一些上下文信息,不会更改Error的类型,更不会改变Error的traits和properties\n从下面的代码可以看出,即使是Decorate,也是新建了一个Error结构体,并将原err作为自己的cause字段,为了表示自己不是一个真正的Error类型,标识自己是transparentWrapper\n// 装饰不会改变error的type,traits,properties func Decorate(err error, message string, args ...interface{}) *Error { return NewErrorBuilder(transparentWrapper). WithConditionallyFormattedMessage(message, args...). WithCause(err). Create() } func NewErrorBuilder(t *Type) ErrorBuilder Wrap 如果你想改变Error的type(这导致在与原Error进行type check时失败,有时这的确是我们想要的)\nfunc (t *Type) Wrap(err error, message string, args ...interface{}) *Error { return NewErrorBuilder(t). WithConditionallyFormattedMessage(message, args...). WithCause(err). Create() } Type Check 判断两个Error是否是同一个类型,或对方是否是自己类型的祖先\n// IsOfType is a type check for errors. // Returns true either if both are of exactly the same type, or if the same is true for one of current type's ancestors. // For an error that does not have an errorx type, returns false. func IsOfType(err error, t *Type) bool { e := Cast(err)\treturn e != nil \u0026amp;\u0026amp; e.IsOfType(t) } func Cast(err error) *Error // Cast函数将标准库error接口断言成errorx.Error 这个函数单纯的使用for loop跳过透明Error层,即Decorate:\nfunc (e *Error) IsOfType(t *Type) bool { cause := e for cause != nil { if !cause.transparent { return cause.errorType.IsOfType(t) } cause = Cast(cause.Cause()) } return false } 判断自己是否是对方的类型的继承者(必须在一个namespace内),或自己是否就是对方类型\n// Returns true either if both are of exactly the same type, or if the same is true for one of current type's ancestors. func (t *Type) IsOfType(other *Type) bool { current := t for current != nil { if current.id == other.id { return true } current = current.parent } return false } Trait Check 无他,就是单纯检查type的trait,type祖先的trait,namespace的trait,namespace祖先的trait\n编码技巧 builder模式创建error 由于error的参数较多,选择建造者模式来构造error\n建造者模式的好处是,我们是对option结构体不断修改,最终build出一个完整的error,这样,只要error出现,就是完好的,而不是一步一步的去设置error的字段\ntype ErrorBuilder struct { message string errorType *Type cause error mode callStackBuildMode isTransparent bool } 使用链式调用来set字段 func (eb ErrorBuilder) WithCause(err error) ErrorBuilder func (eb ErrorBuilder) Transparent() ErrorBuilder func (eb ErrorBuilder) EnhanceStackTrace() ErrorBuilder func (eb ErrorBuilder) WithConditionallyFormattedMessage(fmt string, args ...interface{}) ErrorBuilder 打印特性 实现fmt.Printf()接口 func (e *Error) Format(s fmt.State, verb rune) { message := e.fullMessage() switch verb { case 'v': io.WriteString(s, message) if s.Flag('+') { e.stackTrace.Format(s, verb) } case 's': io.WriteString(s, message) } } 运行时静态断言 以这样的方式明确指出,\n*Error类型满足fmt.Formatter接口\u0026hellip;\nvar _ fmt.Formatter = (*Error)(nil) var _ encoding.TextMarshaler = (*Type)(nil) 设计缺陷与思考 Namespace与Type 个人感觉,完全没必要设置这个Namespace作为一个单独的结构体,但是Namespace作为逻辑上的一个域,是有必要的,但实现时,完全可以就直接只使用Type,因为目前来看,它的结构体字段上,二者是相似的,几乎无差.\n从逻辑的角度看,type不断继承,需要一个baseType,和type在一个namespace下,都说说的通的,所以,baseType和namespace,几乎是可以不加区分的\n再不济\ntype Namespace Type ","id":63,"section":"posts","summary":"\u003ch1 id=\"error\"\u003eError\u003c/h1\u003e\n\u003cp\u003ego的error一直是被人诟病的,对于菜鸡来说无非是每调用一个函数就要判断一下\u003ccode\u003eif err!=nil{return err}\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e而对于进阶一点的程序员,则会诟病它的error接口设计的太烂,只要实现了\u003ccode\u003eError()\u003c/code\u003e,就是一个error,这导致难以比较\u003c/p\u003e","tags":["Golang"],"title":"[Go] errorx","uri":"https://wymli.github.io/2021/03/go-errorx/","year":"2021"},{"content":"逃逸分析 首先,逃逸分析发生在编译时,由分析结果决定运行时对象应该在堆还是栈上分配\n注意: 这个编译时分析似乎是以函数为单位的静态分析,因此才有当函数参数是interface{}时,不知其具体类型\n规则 堆对象不能指向栈对象,否则栈对象被分配在堆上 其他\u0026hellip;. 典型场景 1.函数返回指向栈内对象的指针 func NewA()*a{ return \u0026amp;a{123} } 2.调用反射(interface{}动态类型) 在反射的实现中,比如 reflect.ValueOf :\nfunc ValueOf(i interface{}) Value { if i == nil { return Value{} } // TODO: Maybe allow contents of a Value to live on the stack. // For now we make the contents always escape to the heap. It // makes life easier in a few places (see chanrecv/mapassign // comment below). escapes(i) return unpackEface(i) } 直接对i逃逸了,那么i指向的内存必然也逃逸,所以传进去的值便逃逸了\n因此,不是说往func(interface{})传值,或者往func(*struct)传指针就会导致逃逸分析.\n只是大多数场景下,其内部都会用到反射,导致逃逸(switch type不会导致逃逸)\n拼接字符串 比如:\nvar strt = \u0026quot;asdf\u0026quot; //go:noinline func t(i *int) string{ *i += 1 return \u0026quot;asdf\u0026quot;+strt } .\\a.go:15:15: \u0026quot;asdf\u0026quot; + strt escapes to heap 很奇怪,直接return string(\u0026ldquo;asdf\u0026rdquo;)却不会导致逃逸,按道理string{ptr,len}的结构,这个ptr应该会逃逸才对\n-gcflags \u0026ldquo;-m -l\u0026rdquo; -m 设置打印信息 -l禁止内联, 也可用//go:noinline 三个典型输出的意义: (https://groups.google.com/g/golang-dev/c/Cf4tpaWP6rc)\n\u0026ldquo;moved to heap\u0026rdquo; means that a local variable was allocated on the heap\nrather than the stack.\n\u0026ldquo;leaking param\u0026rdquo; means that the memory associated with some parameter\n(e.g., if the parameter is a pointer, the memory to which it points)\nwill escape. This typically means that the caller must allocate that\nmemory on the heap.\n\u0026ldquo;escapes to heap\u0026rdquo; means that some value was copied into the heap.\nThis differs from \u0026ldquo;moved to heap\u0026rdquo; in that with \u0026ldquo;moved to heap\u0026rdquo; the\nvariable was allocated in the heap. With \u0026ldquo;escapes to heap\u0026rdquo; the value\nof some variable was copied, for example when assigning to a variable\nof interface type, and that copy forced the value to be copied into a\nnewly allocated heap slot.\n\u0026ldquo;moved to heap\u0026rdquo; and \u0026ldquo;escapes to heap\u0026rdquo; both always mean a heap allocation occurs. The difference is \u0026ldquo;moved to heap\u0026rdquo; is used for named variables, and \u0026ldquo;escapes to heap\u0026rdquo; is used for anonymous variables (e.g., as allocated by \u0026ldquo;new\u0026rdquo; or \u0026ldquo;make\u0026rdquo;; taking the address of a composite literal).\n个人理解:\nmove常用于普通变量的,由于生命周期的原因导致的需要分配在堆上\nescape常用于匿名变量,比如st.a = new(int),或者传入interface{}\n编译指令 运行时判断一个对象在不在堆上\n一般的,如果//后没有空格,那么就是编译指令,常见的还有generate\nhttps://www.yuque.com/flipped-aurora/gqbcfk/io1db4\n//go:linkname inheap runtime.inheap func inheap(b uintptr) bool // example println(inheap(uintptr(unsafe.Pointer(\u0026amp;m)))) println(inheap(uintptr(unsafe.Pointer(m.b)))) 其他 个人感觉,不必深究,知道基础的就好\n声明:看看就好,不一定对\n","id":64,"section":"posts","summary":"\u003ch1 id=\"逃逸分析\"\u003e逃逸分析\u003c/h1\u003e\n\u003cp\u003e首先,逃逸分析发生在编译时,由分析结果决定运行时对象应该在堆还是栈上分配\u003c/p\u003e\n\u003cp\u003e注意: 这个编译时分析似乎是以函数为单位的静态分析,因此才有当函数参数是interface{}时,不知其具体类型\u003c/p\u003e","tags":["Golang"],"title":"[Go] escape analysis","uri":"https://wymli.github.io/2021/03/go-escape-analysis/","year":"2021"},{"content":"垃圾回收算法 https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-garbage-collector/\n有两种常见的自动管理堆内存的方法:\n引用计数/智能指针 追踪式垃圾回收(对堆内存的对象关系图进行可达性分析) 术语 根对象: 包括所有栈上对象,全局变量 标记-清扫法(mark-sweep) 典型的STW(stop the world)算法,当进行垃圾回收时,先暂停用户程序,然后从根对象出发对堆对象进行可达性标记(比如bfs/dfs),标记完后遍历所有的堆对象,回收掉不可达对象\n三色标记法 这是一种并发算法,不需要或只需要短暂的暂停用户程序\n定义三色: 黑白灰\n灰色: 可达对象 黑色: 由灰色衍生出来的可达对象 白色: 不可达对象 算法流程:\n首先所有根对象置为灰色\n从灰色对象中选择一个,置为黑色对象 将黑色对象指向的所有对象置为灰色 重复1,2,直到不存在灰色对象 回收剩余的白色对象 由于在标记过程中,对象图可能改变,所以需要作如下操作:\n修改指针之前,必须先对被指向的对象标记为灰色,由于现代cpu的乱序执行和多发射,这需要我们用写内存屏障来实现 屏障 插入写屏障\nwritePointer(slot, ptr): shade(ptr) //染灰 *slot = ptr 删除写屏障\nwritePointer(slot, ptr) shade(*slot) //染灰 *slot = ptr 混合写屏障(v1.8引入)\nwritePointer(slot, ptr): shade(*slot) if current stack is grey: shade(ptr) *slot = ptr 注意: 不会在所有的根对象上开启写屏障,因为一个程序可能由成百上千个goroutine,如果在所有的goroutine的栈上开启写屏障,压力太大\n看了了b站刘丹冰的视频后,有了更深的理解\ngo的gc算法:\nv1.3 StopTheWorld 标记清扫法 stw-\u0026gt;mark-\u0026gt;sweep-\u0026gt;stw\n优化: stw-\u0026gt;mark-\u0026gt;stw-\u0026gt;sweep(串行标记,并发清扫)\nv1.5 三色标记法 这里的mark是分层的bfs.\n这个方法可以解决并发吗?\n对于新创建的对象:\n对于已有对象的并发标记问题:\n如果一个白色对象原来被正常引用(或是作为白色新创建节点,被黑色对象引用), 在mark过程中变为仅被黑色对象引用,显然就会最终仍是白色,被丢失,这是因为三色标记法是基于灰色对象标记下一个灰色对象的,不会对黑色对象所引用的对象标记\n解决方法:\n强三色不变性: 禁止mark过程中的黑色对象指向白色对象\n弱三色不变性: 一个白色对象的上游链路必须存在灰色对象,此时其可被黑色对象引用(只要上游灰色存在,最终一定会标记到自己)\n如何实现:\n屏障技术(实际上,就是在变更引用关系的时候触发回调函数)\n初始时 A.field1 = B\n变更: A.field1 = C\n则: B触发删除写屏障,C触发插入写屏障(要么开启删除写屏障,要么开启插入写屏障)\n最后v1.8 优化为混合写屏障\n插入写屏障:\n​\t被黑色节点引用的对象置灰色\n​\t1. 堆空间作为根节点时,白色对象若被黑色对象引用,触发回调,自己置为灰色\n​\t2. 栈空间不触发插入屏障,这是为了保证速度. 所以为了保证新节点不丢失,要最后stw扫描栈,重新扫描mark一次\n因此:\n插入写屏障的不足: 结束时stw扫描栈,10-100ms\n删除写屏障:\n​\t被删除的对象直接置为灰色\n​\t显然,如果这个对象确实是不再被引用,而不是变更为被黑色对象引用,那么这个对象就会在本轮不被删除,但是无论如何,下轮gc仍然删除.所以缺点就是有可能造成延迟删除.但是这不可避免,因为你无法判断他是变更引用关系到黑色对象上,还是真的删了,只能先妥协一轮.\nv1.8混合写屏障:\n栈上对象(根节点为栈)全部置为黑色,后续被栈引用的新对象均置为黑色(防止重复stw扫描栈) 栈不开启写屏障 堆上被删除的对象置为灰色 堆上被插入的对象置为灰色 满足弱三色不变性\n注意这里,栈对象也是分配在堆上的,因为go程是用户态的,详见GMP\n","id":65,"section":"posts","summary":"\u003ch1 id=\"垃圾回收算法\"\u003e垃圾回收算法\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-garbage-collector/\"\u003ehttps://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-garbage-collector/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e有两种常见的自动管理堆内存的方法:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e引用计数/智能指针\u003c/li\u003e\n\u003cli\u003e追踪式垃圾回收(对堆内存的对象关系图进行可达性分析)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"术语\"\u003e术语\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e根对象: 包括所有栈上对象,全局变量\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"标记-清扫法mark-sweep\"\u003e标记-清扫法(mark-sweep)\u003c/h2\u003e\n\u003cp\u003e典型的STW(stop the world)算法,当进行垃圾回收时,先暂停用户程序,然后从根对象出发对堆对象进行可达性标记(比如bfs/dfs),标记完后遍历所有的堆对象,回收掉不可达对象\u003c/p\u003e","tags":["Golang"],"title":"[Go] GC","uri":"https://wymli.github.io/2021/03/go-gc/","year":"2021"},{"content":"Goroutine Pool 代码来自:gobwas/ws-example\n在go中,由于goroutine是完全的用户态线程,所以创建新线程的开销很小,在这种情况下,复用goroutine形成goroutine池的优化效果很有限\n但是,池不仅减少了创建开销,还能有效的限制对象个数\n因此,假如我们的服务期望有最大的goroutine个数限制,将需要使用goroutine pool\n设计 一个goroutine pool需要什么呢?\n需要: 当前运行的gorotine数,最大goroutine数,任务队列,条件变量/信号量(用于线程阻塞等待任务)\n但是在go中,chan是天然的一个阻塞队列,任务队列本身就完成了阻塞唤醒的功能\n对于curr_n_thread和max_n_thread,本来应该用两个int去存,但是在go中,也可以用chan struct{},因为有缓冲的通道天然有上限,并且增加减少都是并发安全的\n虽然用sem chan struct{}表示goroutine数目的限制很炫,但是确实不如int去存有用,毕竟int能反映当前运行的goroutine数目,而sem chan struct{}只能限制最大数\ntype Pool struct { sem chan struct{} work chan func() } NewPool 创建一个pool\nsize: max_n_thread\nqueue: 等待队列上限(最大等待任务数)\nspawn: 立即运行多少工作线程\nfunc NewPool(size, queue, spawn int) *Pool { if spawn \u0026lt;= 0 \u0026amp;\u0026amp; queue \u0026gt; 0 { panic(\u0026quot;dead queue configuration detected\u0026quot;) } if spawn \u0026gt; size { panic(\u0026quot;spawn \u0026gt; workers\u0026quot;) } p := \u0026amp;Pool{ sem: make(chan struct{}, size), work: make(chan func(), queue), } for i := 0; i \u0026lt; spawn; i++ { p.sem \u0026lt;- struct{}{} go p.worker(func() {}) } return p } 分配任务 只需要简单的往通道里丢任务就可以了\n注意,这里的实现是有问题的,原作者可能是想实现:优先想p.work发送任务,如何P.work满了还没有被消费,就新开一个工作线程\n但是go的select是没有顺序的,所以我们必须拆分一下\nfunc (p *Pool) Schedule(task func()) { p.schedule(task, nil) } func (p *Pool) schedule(task func(), timeout \u0026lt;-chan time.Time) error { select { case \u0026lt;-timeout: return ErrScheduleTimeout case p.work \u0026lt;- task: return nil case p.sem \u0026lt;- struct{}{}: go p.worker(task) return nil } } =\u0026gt;\nfunc (p *Pool) schedule(task func(), timeout \u0026lt;-chan time.Time) error { select{ case p.work \u0026lt;- task: return nil default: } select { case \u0026lt;-timeout: return ErrScheduleTimeout case p.work \u0026lt;- task: return nil case p.sem \u0026lt;- struct{}{}: go p.worker(task) return nil } } 或:\nselect { case \u0026lt;-timeout: return ErrScheduleTimeout case p.work \u0026lt;- task: return nil case p.sem \u0026lt;- struct{}{}: select{ case p.work \u0026lt;- task: \u0026lt;- p.sem return nil default: } go p.worker(task) return nil } 工作线程等待分发任务 由于chan的自阻塞性,极易实现,当然这个没有实现线程的退出,如果想实现,可以使用一个退出chan,然后每个线程去竞争done,就像竞争任务一样\nfunc (p *Pool) worker(task func()) { defer func() { \u0026lt;-p.sem }() task() for task := range p.work { task() } } 加了退出通道的工作线程\nfunc (p *Pool) worker(task func()) { defer func() { \u0026lt;-p.sem }() task() for task := range p.work { task() select{ case \u0026lt;- p.done: return default: } } } func (p *Pool) ReduceOne(){ p.done \u0026lt;- struct{}{} p.work \u0026lt;- func(){} // 发送一个空任务,防止工作线程阻塞在p.work而接收不到p.done } 当然,更好的写法是直接同等地位的判断p.work和p.done:\nfunc (p *Pool) worker(task func()) { defer func() { \u0026lt;-p.sem }() task() for { select{ case task := \u0026lt;- p.work: task() case \u0026lt;- p.done return } } } Ants库 github上看到了一个5.2k star的协程库,首先不管技术架构和代码风格,看到readme的几张大图,就感动的哭了,这就是所谓的一分钟上手!\n1h后,我只想说挺捞的.\nreadme有很多错误或不足:\n作者似乎区分不清throughput和one-way latency; 配图也比较老旧了,和代码对不上; go test , 某些协程发生了panic 性能测试是基于工作是sleep的,这相当于又将开销放到了go自己的阻塞调度上 我自己基于如下的工作函数重新测了下:\nfunc demoFunc() { begin := time.Now() i := 0 for { i++ end := time.Now() if end.UnixNano()-begin.UnixNano() \u0026gt; int64(time.Millisecond)*10 { return } } } goos: windows goarch: amd64 pkg: a/ants cpu: Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz BenchmarkPlainPool BenchmarkPlainPool-8 1 13103489000 ns/op 6123848 B/op 54292 allocs/op BenchmarkGoroutines BenchmarkGoroutines-8 1 13296742800 ns/op 4290672 B/op 10006 allocs/op BenchmarkAntsPool BenchmarkAntsPool-8 1 13276752000 ns/op 2631920 B/op 41997 allocs/op PASS ok a/ants 39.795s 这里的plainPool指的就是我们上面自己实现的pool\n可以看到,整个的吞吐率是差不多的,测试完成时间都是13s(所以加起来是39s),但是ants确实降低了1倍的内存消耗\n至于单向提交延迟,我个人感觉意义不太大.协程池的主要优点应该在内存上,避免了无节制的新建内存.\n但是话又说回来,如果只是避免内存,那只需要加个计数器来限制就好了\n于是给ants提了个issue: https://github.com/panjf2000/ants/issues/144\nConclusion 协程池是有必要的,它所保证的__内存消耗与协程调度的上限__,增强了服务器对DOS攻击的耐受性.\n除此之外,在go中的优势似乎没有太多,不过,即使只有一点,也够了.\n","id":66,"section":"posts","summary":"\u003ch1 id=\"goroutine-pool\"\u003eGoroutine Pool\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e代码来自:gobwas/ws-example\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e在go中,由于goroutine是完全的用户态线程,所以创建新线程的开销很小,在这种情况下,复用goroutine形成goroutine池的优化效果很有限\u003c/p\u003e","tags":["Golang"],"title":"[Go] goroutine pool","uri":"https://wymli.github.io/2021/03/go-goroutine-pool/","year":"2021"},{"content":"Monkey patch 猴子补丁 ref: https://bou.ke/blog/monkey-patching-in-go/\nIntro: 什么是monkey patch? package main func a() int { return 1 } func b() int { return 2 } func main() { replace(a, b) print(a()) // 2 } monkey patch将做到如上的效果,当你调用a函数时,实际却调用了b函数,看起来有点神奇!\n这实际上是运行时改变了函数的行为\n实现原理 We need to modify function a to jump to b’s code instead of executing its own body\nfunc replace(orig, replacement func() int) { bytes := assembleJump(replacement) functionLocation := **(**uintptr)(unsafe.Pointer(\u0026amp;orig)) window := rawMemoryAccess(functionLocation) copy(window, bytes) } bytes := assembleJump(replacement) 生成跳转replacement的机器码,将用它来替换跳转orig的机器码\nfunc assembleJump(f func() int) []byte { funcVal := *(*uintptr)(unsafe.Pointer(\u0026amp;f)) return []byte{ 0x48, 0xC7, 0xC2, byte(funcVal \u0026gt;\u0026gt; 0), byte(funcVal \u0026gt;\u0026gt; 8), byte(funcVal \u0026gt;\u0026gt; 16), byte(funcVal \u0026gt;\u0026gt; 24), // MOV rdx, funcVal 0xFF, 0x22, // JMP [rdx] } } functionLocation := **(**uintptr)(unsafe.Pointer(\u0026amp;orig))\n获取orig的函数位置\n注意,这里涉及函数赋值,原函数赋值给了orig,这也是原文为什么先分析func a(){} ; f := a的原因\n函数变量的内部结构(注意区分函数变量和函数):\ntype funcval struct { fn uintptr // variable-size, fn-specific data here (典型的,闭包的实现需要引用外部变量,放在这) } 因此,functionLocation 将等于fn\nwindow := rawMemoryAccess(functionLocation)\n获取由functionLocation开始的0xFF大小的内存空间\nfunc rawMemoryAccess(b uintptr) []byte { return (*(*[0xFF]byte)(unsafe.Pointer(b)))[:] } copy(window, bytes)\n注意不是全部覆盖0xFF那么大,因为bytes没有那么大 ","id":67,"section":"posts","summary":"\u003ch1 id=\"monkey-patch-猴子补丁\"\u003eMonkey patch 猴子补丁\u003c/h1\u003e\n\u003cp\u003eref: \u003ca href=\"https://bou.ke/blog/monkey-patching-in-go/\"\u003ehttps://bou.ke/blog/monkey-patching-in-go/\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"intro-什么是monkey-patch\"\u003eIntro: 什么是monkey patch?\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003epackage main\n\nfunc a() int { return 1 }\nfunc b() int { return 2 }\n\nfunc main() {\n\treplace(a, b)\n\tprint(a())  // 2\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003emonkey patch将做到如上的效果,当你调用a函数时,实际却调用了b函数,看起来有点神奇!\u003c/p\u003e","tags":["Golang"],"title":"[Go] monkey patch","uri":"https://wymli.github.io/2021/03/go-monkey-patch/","year":"2021"},{"content":"mutex 结构 type Mutex struct { state int32 sema uint32 } 自旋\nfor{ cas(m.state) } 阻塞\nwait(m.sema) 状态 普通模式 就是正常的模式,线程相互竞争获得锁 饥饿模式 由于线程竞争失败会阻塞,而这些被唤醒的线程会和其他第一次来申请锁的线程一起竞争,显然,不可能竞争过,因为新的线程是占据着cpu的 这会导致阻塞线程的饥饿,因此,mutex加入了饥饿模式,当进入饥饿模式后,锁直接赋予阻塞队列的第一个线程,新线程自动加入阻塞队列 注意,对锁的竞争,有两大来源,一是新线程,二是被阻塞线程(由于锁的释放而被唤醒),新线程如果自旋一段时间后未获得锁,便进入阻塞态,加入该锁的等待队列\n加锁 Lock 对申请锁的情况分为三种：\n无冲突，通过 CAS 操作把当前状态设置为加锁状态 有冲突，开始自旋轮询，并等待锁释放，如果其他 goroutine 在这段时间内释放该锁，直接获得该锁；如果没有释放则为下一种情况 有冲突，且已经过了自旋阶段，通过调用 semrelease 让 goroutine 进入等待状态 摘自 https://golang.design/under-the-hood/zh-cn/part4lib/ch15sync/mutex/\ngoroutine会自旋轮询四次,如果失败,就在信号量上阻塞睡眠\nFSM 进入饥饿模式 如果一个 goroutine 等待 mutex 释放的时间超过 1ms，它就会将 mutex 切换到饥饿模式 退出饥饿模式 它是等待队列中的最后一个 它等待的时间少于 1ms ","id":68,"section":"posts","summary":"\u003ch1 id=\"mutex\"\u003emutex\u003c/h1\u003e\n\u003ch2 id=\"结构\"\u003e结构\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003etype Mutex struct {\n    state int32\n    sema  uint32\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e自旋\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003efor{\n  cas(m.state)\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e阻塞\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003ewait(m.sema)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"状态\"\u003e状态\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e普通模式\n\u003cul\u003e\n\u003cli\u003e就是正常的模式,线程相互竞争获得锁\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e饥饿模式\n\u003cul\u003e\n\u003cli\u003e由于线程竞争失败会阻塞,而这些被唤醒的线程会和其他第一次来申请锁的线程一起竞争,显然,不可能竞争过,因为新的线程是占据着cpu的\u003c/li\u003e\n\u003cli\u003e这会导致阻塞线程的饥饿,因此,mutex加入了饥饿模式,当进入饥饿模式后,锁直接赋予阻塞队列的第一个线程,新线程自动加入阻塞队列\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003e注意,对锁的竞争,有两大来源,一是新线程,二是被阻塞线程(由于锁的释放而被唤醒),新线程如果自旋一段时间后未获得锁,便进入阻塞态,加入该锁的等待队列\u003c/p\u003e","tags":["Golang"],"title":"[Go] mutex","uri":"https://wymli.github.io/2021/03/go-mutex/","year":"2021"},{"content":"","id":69,"section":"posts","summary":"","tags":["Golang"],"title":"[Go] netaddr","uri":"https://wymli.github.io/2021/03/go-netaddr/","year":"2021"},{"content":"Radix树 又叫压缩前缀树,基数树,常用于路由匹配上,会将路由组织成一颗radix树\n","id":70,"section":"posts","summary":"\u003ch1 id=\"radix树\"\u003eRadix树\u003c/h1\u003e\n\u003cp\u003e又叫压缩前缀树,基数树,常用于路由匹配上,会将路由组织成一颗radix树\u003c/p\u003e","tags":["Golang"],"title":"[Go] radix-tree","uri":"https://wymli.github.io/2021/03/go-radix-tree/","year":"2021"},{"content":"什么是反射? 反射提供了一种运行时能对对象增删查改的方法.\n换句话说,当函数参数的interface{}时,提供了一种访问原来的类型和值的方法. 这与switch type类似,但是switch只能对type进行判断,而你根本不知道会传进来何种自定义的结构体,这就是需要判断reflect.kind了\n(Value) Elem() Value Elem returns the value that the interface v contains or that the pointer v points to. It panics if v\u0026rsquo;s Kind is not Interface or Ptr. It returns the zero Value if v is nil.\nreflect.Value.Elem(),必须接收Interface或Ptr类型的Kind,它将会返回其指向或包含的类型.\n这很好理解,如果reflect.Value{\u0026amp;a},那么Elem()后,就会返回reflect.Value{a}.\n但是,什么时候reflect.Value会是一个Interface呢?\nValueOf(i interface{}) Value ValueOf returns a new Value initialized to the concrete value stored in the interface i. ValueOf(nil) returns the zero Value.\n当我们执行如下代码时:\nvar i interface{} = 1 x := reflect.ValueOf(i).Kind() fmt.Println(x) // int 为什么呢?\n明明传入的是一个interface{}类型的 i 再看文档,它明确的说明了 initialized to the concrete value stored in the interface,因此,具体值将会被取出,那么既然都会被取出,难道还存在interface包一个interface吗? 即取出来后还是一个interface?\n答案是不可能的,https://blog.golang.org/laws-of-reflection 说明了 An interface variable can store any concrete (non-interface) value 再看另一个问题,为什么reflect.ValueOf一定要把interface里面的具体值取出来呢,留在那里,我们自己调用Elem取出来不行吗?\n我们要注意,reflect.ValueOf(i interface{})的函数签名,我们知道对于空接口,其内部和reflect.Value是类似的结构,都是(type,dataPtr)\n如果传入的是a (int, \u0026amp;1),那么首先发生简单的浅复制: i = a =\u0026gt; i(int,\u0026amp;1). 然后返回reflect.Value{i.type,i.dataPtr,\u0026hellip;},可以看出,所谓的取出,本质是interface{}的type,dataPtr被复制转移到了reflect.Value\n如果传入的是\u0026amp;a, 那么经过浅复制,i将会是 (interface , \u0026amp;a). 这是自然的,对x T取地址\u0026amp;x将产生*T指向x,所以\u0026amp;a将产生*interface{}指向a\nfunc test(i interface{}) { switch i.(type) { case *int: fmt.Println(\u0026quot;*int\u0026quot;) case int: fmt.Println(\u0026quot;int\u0026quot;) case *interface{}: fmt.Println(\u0026quot;*interface\u0026quot;) default: fmt.Println(\u0026quot;not this\u0026quot;) } } func main(){ var i interface{} = 1 test(i) // int test(\u0026amp;i) // *interface } Value.Kind() == Interface 执行如下代码:\nvar i interface{} = 1 x := reflect.ValueOf(i).Kind() fmt.Println(x) // int fmt.Println(reflect.ValueOf(\u0026amp;i).Elem().Kind()) // interface v := reflect.ValueOf(struct{ a interface{} }{1}) fmt.Println(v.Field(0).Kind()) // interface 当我们传递\u0026amp;i给ValueOf的时候,就会返回一个Ptr,然后我们调用Elem(),便得到了interface\n或者访问结构体的字段,也可以得到interface.\nType.Kind() == Interface 前面介绍了Value.Kind(),与之类似的,还有Type.Kind()\nreflect.TypeOf([]interface{}{1, 2}).Elem().Kind() == reflect.Interface // true\n(Type)Elem() : Elem returns a type\u0026rsquo;s element type. It panics if the type\u0026rsquo;s Kind is not Array, Chan, Map, Ptr, or Slice.\n","id":71,"section":"posts","summary":"\u003ch2 id=\"什么是反射\"\u003e什么是反射?\u003c/h2\u003e\n\u003cp\u003e反射提供了一种运行时能对对象增删查改的方法.\u003c/p\u003e\n\u003cp\u003e换句话说,当函数参数的interface{}时,提供了一种访问原来的类型和值的方法. 这与switch type类似,但是switch只能对type进行判断,而你根本不知道会传进来何种自定义的结构体,这就是需要判断reflect.kind了\u003c/p\u003e","tags":["Golang"],"title":"[Go] reflect","uri":"https://wymli.github.io/2021/03/go-reflect/","year":"2021"},{"content":"Runtime Struct: 运行时结构体构造方法 参考:\nhttps://github.com/itsubaki/gostruct\nhttps://pkg.go.dev/reflect#example-StructOf\nreflect.New(typ reflect.Type) reflect.Value New returns a Value representing a pointer to a new zero value for the specified type. That is, the returned Value\u0026rsquo;s Type is PtrTo(typ).\n因此,给定一个结构体类型的type,我们就可以构造出value\nreflect.StructOf(fields []reflect.StructField) reflect.Type StructOf returns the struct type containing fields. The Offset and Index fields are ignored and computed as they would be by the compiler.\nStructOf currently does not generate wrapper methods for embedded fields and panics if passed unexported StructFields. These limitations may be lifted in a future version.\n因此,给定[]reflect.StructField,就可以构造出type\n注: 其他类型同理,比如reflect.ChanOf,reflect.ArrayOf,reflect.SliceOf\nreflect.StructField // A StructField describes a single field in a struct. type StructField struct { // Name is the field name. Name string // PkgPath is the package path that qualifies a lower case (unexported) // field name. It is empty for upper case (exported) field names. // See https://golang.org/ref/spec#Uniqueness_of_identifiers PkgPath string Type Type // field type Tag StructTag // field tag string Offset uintptr // offset within struct, in bytes Index []int // index sequence for Type.FieldByIndex Anonymous bool // is an embedded field } 根据reflect.StructOf的文档和自身的注释(见上文),Offset,Index都不需要指定,Anonymous也不支持(go1.13),name必须capital,PkgPath也为空\n总结来说,我们需要指定:\niField := reflect.StructField{ Name: \u0026quot;Id\u0026quot;, Type: reflect.TypeOf(uint64(0)), Tag: `json:\u0026quot;id\u0026quot;`, // optional } Build typ := reflect.StructOf([]reflect.StructField{ { Name: \u0026quot;Height\u0026quot;, Type: reflect.TypeOf(float64(0)), Tag: `json:\u0026quot;height\u0026quot;`, }, { Name: \u0026quot;Age\u0026quot;, Type: reflect.TypeOf(int(0)), Tag: `json:\u0026quot;age\u0026quot;`, }, }) v := reflect.New(typ).Elem() v.Field(0).SetFloat(0.4) v.Field(1).SetInt(2) s := v.Addr().Interface() 一般来说,使用时,比如将其返回,要转换成Interface{}\n为了方便的用string访问字段,而不是index,我们可以自己包装一层,然后加上Interface(),Addr()两个方法\ntype myStruct struct { internal reflect.Value index map[string]int } func (i *myStruct) Field(name string) reflect.Value { return i.internal.Field(i.index[name]) } func (i *myStruct) Interface() interface{} { return i.internal.Interface() } func (i *myStruct) Addr() interface{} { return i.internal.Addr().Interface() } 调用Addr()方法,可用于取地址,常用于调用指针接收者的方法\nAddr is typically used to obtain a pointer to a struct field or slice element in order to call a method that requires a pointer receiver.\n用处 母鸡,暂时不太知道运行时构建结构体的用处\n我唯一用到反射的地方,就只有解析结构体字段了,比如把struct转成map这种\n但是以此来作为熟悉refelct包,还是不错的\n","id":72,"section":"posts","summary":"\u003ch1 id=\"runtime-struct-运行时结构体构造方法\"\u003eRuntime Struct: 运行时结构体构造方法\u003c/h1\u003e\n\u003cp\u003e参考:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/itsubaki/gostruct\"\u003ehttps://github.com/itsubaki/gostruct\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://pkg.go.dev/reflect#example-StructOf\"\u003ehttps://pkg.go.dev/reflect#example-StructOf\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"reflectnewtyp-reflecttype-reflectvalue\"\u003ereflect.New(typ reflect.Type) reflect.Value\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003eNew returns a Value representing a pointer to a new zero value for the specified type. That is, the returned Value\u0026rsquo;s Type is PtrTo(typ).\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e因此,给定一个结构体类型的type,我们就可以构造出value\u003c/p\u003e","tags":["Golang"],"title":"[Go] runtime struct builder","uri":"https://wymli.github.io/2021/03/go-runtime-struct-builder/","year":"2021"},{"content":"[Go] 短变量声明 := 在Go中,提供了动态语言常用的一种直接声明并赋值的语法糖,即 := 短变量声明\n:= 这个符号,可能是借鉴了Pascal\n短变量声明有一定的要注意的地方,它与先声明后赋值有着一定的区别:\n1 短变量声明无法用于全局变量的创建\n2 短变量定义函数时无法使用递归\na := func(){ a() // undeclared name: a } var a func() a = func(){ a() // ok! } 3 多变量赋值,左端必须有一项是新定义的变量\n若在同一作用域, 已存在的变量将被覆盖. 否则,是定义新的局部变量 a,_ := f() if a,err := f();!err{ a++ } fmt.Println(a) // 这个a还是原来的a,因为if{}是个局部作用域 ","id":73,"section":"posts","summary":"\u003ch1 id=\"go-短变量声明-\"\u003e[Go] 短变量声明 :=\u003c/h1\u003e\n\u003cp\u003e在Go中,提供了动态语言常用的一种直接声明并赋值的语法糖,即 := 短变量声明\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e:= 这个符号,可能是借鉴了Pascal\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e短变量声明有一定的要注意的地方,它与先声明后赋值有着一定的区别:\u003c/p\u003e","tags":["Golang"],"title":"[Go] short var declare","uri":"https://wymli.github.io/2021/03/go-short-var-declare/","year":"2021"},{"content":"[Go] Slice的下标索引细节 在刷oj的时候,经常遇到要对一个数组取一部分的场景,用来递归分治\n常见的比如快排,恢复二叉树等\n在c/c++中,我会使用func(int* array , int lo , int hi)来标识数组的范围,但是在python这种动态语言中,可以直接使用数组的切片,很方便的传入递归函数 func (slice[lo:hi])\n在go中,也有切片,也可以达到类似的效果,但是会存在一些你平时没有注意到的地方\n1. a[len(a):] 对于边界情况,要注意:\na := []int{1,2,3} len(a[:0]) == 0 // true len(a[len(a):]) == 0 // true len(a[cap(a):]) == 0 // true 对于Line#3/4,一定要注意,不会越界!\na[2:] // same as a[2 : len(a)] a[:3] // same as a[0 : 3] a[:] // same as a[0 : len(a)] 只要按如上的规则还原low和high后,若满足 rule 就不会越界\n但是如果cap=4,a[5:],就越界了\n2. cap 一定要注意\nhigh是否越界取决于cap low是否越界取决于len 当我们往递归函数不断传入切片后,因为都在引用同一个底层内存,所以其实存在某些时候看似越界,实则是因为cap比len大的原因\n如果想严格限制切片cap,那么在切片的时候,可以设置max参数:\nb := a[low : high : max] rule 这是spec上的切片下标的规则:\n0 \u0026lt;= low \u0026lt;= high \u0026lt;= max \u0026lt;= cap(a) 但我想补充一下:\nlow和high都可以 \u0026gt;=len(a),只要小于cap(a),都是合法的 新切片:\ncap(b) = max - low , len(b) = high - low\nref https://golang.org/ref/spec#Slice_expressions\n","id":74,"section":"posts","summary":"\u003ch1 id=\"go-slice的下标索引细节\"\u003e[Go] Slice的下标索引细节\u003c/h1\u003e\n\u003cp\u003e在刷oj的时候,经常遇到要对一个数组取一部分的场景,用来递归分治\u003c/p\u003e\n\u003cp\u003e常见的比如快排,恢复二叉树等\u003c/p\u003e\n\u003cp\u003e在c/c++中,我会使用func(int* array , int lo , int hi)来标识数组的范围,但是在python这种动态语言中,可以直接使用数组的切片,很方便的传入递归函数 func (slice[lo:hi])\u003c/p\u003e","tags":["Golang"],"title":"[Go] slice index detail","uri":"https://wymli.github.io/2021/03/go-slice-index-detail/","year":"2021"},{"content":"Standard Package Layout 标准包布局 -Ben Johnson https://www.gobeyond.dev/standard-package-layout/\nVendoring和Generics,它们在go社区似乎都是big issue,但还有一个很少提及的issue,就是应用的包布局(application package layout)\n每个我所参与的go应用都似乎对一个问题有不同的答案,我应该如何组织我的代码?有些应用将所有东西堆到一个包里面,但是还有一些应用会选择按type或module来分组. 如果没有一个好的策略能在整个团队中贯彻使用,你会发现代码会分散在应用的各个包中(译者注:即强耦合).我们需要一个更好的go应用设计的标准\n我建议这样的一个更好的方法. 通过遵循一些简单的规则我们可以解耦我们的代码,使得它更加容易测试,并且为我们的项目带来一致性的结构.在我们深入探讨之前,先看看现在最常见的一些人们组织包的方法\n有缺陷的方法 似乎存在一些常用的方法来组织go包,但它们都有这自己各自的缺陷\n方法#1: 单包(译者注:类比单内核/宏内核) 将你的代码扔在一个包里确实对于一些小应用来说可以运行的很好.它避免了循环依赖的可能,因为在你的应用里面,没有任何依赖(译者注:即引用别的包)\n我曾看见过这样的方式能对至多10k行源码的应用起效.但超过这个大小后,就会使浏览代码和隔离代码变得非常困难\n方法#2: Rails风格布局 另一种方法是按功能类型来对代码分包.比如,你所有的handlers放在一个package,所有的controllers放在一个package,所有的models放在一个package.我在过去的Rails开发者中经常看见这种布局\n但是这个方法仍然存在两个问题.首先,你的命名是atrocious的.你最终得到类似controller.UserController这样的类型名称,这意味着你在类型名中重复了包名.我倾向于对命名有一定的质量要求(stickler).当你陷入杂草般的代码中时,我相信名字是最好的文档.名字也被用作是对代码质量的代理(译者注:即命名是代码质量的外显/一部分)(a proxy for quality)-因为它是某个人阅读代码时最先注意到的东西.\n但是,最大的问题是环形依赖. 不同的功能类型也许需要互相引用彼此. 这样的按功能类型分包的布局只会在你的依赖都是单向时才有效,但是大部分情况你的应用都不会那么简单.\n方法#3: 按模块分包 译者注: 类似于按照类来分包?\n这个方法与Rails风格布局相似,但此时我们按模块进行分包来组织我们的代码,而不是功能.比如,你有一个users包和一个accounts包.\n在这个方法中,我们将会发现和Rails风格中同样的问题.再一次,我们最终得到了类似users.User这样糟糕的命名.我们也同样面临环形依赖的问题,如果accounts.Controller需要和users.Controller进行交互,反之亦然.\n一个更好的方法 我使用的应用在我们项目中的分包策略包括四个简单的宗旨:\n根包用于领域类型(译者注:根包即net/http中的net,其含有与http子包并列的代码文件) 按依赖对子包分组 使用共享的mock子包(mock模拟,译者注:用于测试) Main包将捆绑所有依赖(译者注:Main包是可执行包,将会引用所有需要的依赖,此外的子包不可以平行引用子包) 这些规则帮助隔离我们的包和在整个应用中定义一个清晰的领域语言.让我们看看每一个规则是如何在实践中生效的\n1.根包用于领域类型 你的应用有一个逻辑的,高层次的语言来描述数据和进程的交互. 这就是你的领域(domain).如果你有一个电商应用,你的领域将包含诸如顾客,账户,对信用卡收费,处理库存等.如果你是Facebook,那么你的领域将是用户,爱好,关系网等. 领域所包含的东西就是一些不依赖于你底层技术的东西\n我将我们的领域类型放在根包中.这个包只包含简单的数据类型比如User结构体,用于持有用户数据或UserService接口用于存取用户数据\n代码可能长这样:\npackage myapp type User struct { ID int Name string Address Address } type UserService interface { User(id int) (*User, error) Users() ([]*User, error) CreateUser(u *User) error DeleteUser(id int) error } 这会使得你的根包非常小. 你也可以包含执行操作的类型,但前提是它们仅依赖于其他领域类型.比如,你可以有一个用于周期性轮询UserService的类型.但是它不可以访问外部的服务(service)或保存数据到数据库.这是一个实现细节.(译者注:即不能引入更多的包(外部包/子包),只能用现有的类型)\n根包不应该依赖其他任何在你应用中的包(译者注:不应该依赖子包)\n2.按依赖来分包 (译者注:比如http依赖在一个包,数据库依赖在一个包)\n如果你的根包不允许有外部的依赖,那么我们必须将这些依赖放置在子包中(译者注:根包不应该有任何import).在这个关于包布局的方法中,子包作为一个你的领域和你的实现之间的适配器存在(译者注:核心观点,子包作为领域与实现的适配器,而实现将使用外部依赖,这中间通过接口适配,便于mock)\n比如,你的UserService也许由Postgresql支持.你可以在你的应用中引入一个名为postgres的子包用于提供postgres.UserService实现(译者注:app.postgres.UserService结构体实现app.UserService接口)\npackage postgres import ( \u0026quot;database/sql\u0026quot; \u0026quot;github.com/benbjohnson/myapp\u0026quot; _ \u0026quot;github.com/lib/pq\u0026quot; ) // UserService represents a PostgreSQL implementation of myapp.UserService. type UserService struct { DB *sql.DB } // User returns a user for a given id. func (s *UserService) User(id int) (*myapp.User, error) { var u myapp.User row := db.QueryRow(`SELECT id, name FROM users WHERE id = $1`, id) if row.Scan(\u0026amp;u.ID, \u0026amp;u.Name); err != nil { return nil, err } return \u0026amp;u, nil } // implement remaining myapp.UserService interface... 这段代码隔离了我们的Posgresql依赖,简化了测试(译者注:这称为依赖注入)和提供了简单的方法用于未来可能的迁移数据库.它可以被用作一种可插拔架构(pluggable architecture),如果你决定支持其他的数据库实现比如BoltDB.\n它也给了你一种对实现分层的方法.也许你想要持有一个在内存中的,LRU算法的cache在PostgreSQL之前.那么你只需要添加一个实现了UserService的UserCache,它可以包装(wrap)你的PostgreSQL实现(译者注:装饰模式)\npackage myapp // UserCache wraps a UserService to provide an in-memory cache. type UserCache struct { cache map[int]*User service UserService } // NewUserCache returns a new read-through cache for service. func NewUserCache(service UserService) *UserCache { return \u0026amp;UserCache{ cache: make(map[int]*User), service: service, } } // User returns a user for a given id. // Returns the cached instance if available. func (c *UserCache) User(id int) (*User, error) { // Check the local cache first. if u := c.cache[id]]; u != nil { return u, nil } // Otherwise fetch from the underlying service. u, err := c.service.User(id) if err != nil { return nil, err } else if u != nil { c.cache[id] = u } return u, err } 我们在标准库中也看到了这种方法.io.Reader是一个领域类型,用于读字节,它的实现按依赖进行分组(分包)\u0026mdash;-tar.Reader,gzip.Reader,multipart.Reader. 它们也可以被分层叠起来,我们经常可以看到os.File被bufio.Reader包装,再被gzip.Reader包装,再被tar.Reader包装.\n依赖之间的依赖 你的依赖们并没有隔离.你也许会存储User数据到PostgreSQL中,但你的金融交易数据存放在第三方服务中,比如Strip. 在这个例子中我们使用一个逻辑领域类型来包装Strip依赖\u0026mdash;让我们叫他TrasactionService.\n通过添加TransactionService到UserService,我们解耦了这两个依赖:(译者注:这里是myapp.posgres.UserService,而不是myapp.UserService, myapp.posgres.UserService实现了myapp.UserService)\ntype UserService struct { DB *sql.DB TransactionService myapp.TransactionService } 现在这些依赖仅通过公共领域语言来进行通信. 这意味这我们可以将PosgreSQL切换成MySql,或者切换Strip为另一个支付处理器,而不影响其他依赖.\n不要局限于第三方依赖 (译者注:对于标准库也要隔离)\n这听起来可能很奇怪，但是我也使用这种相同的方法来隔离我的标准库依赖. 例如,net/http包只是另一个依赖. 我们也可以通过在应用程序中包含http子包来隔离它.(译者注:所谓隔离一个包,是指只在特定的包引入一个包,而不是在应用中到处引用)\n具有与其包装的依赖相同名称的包似乎很奇怪,但是,我是故意的. 除非您允许在应用程序的其他部分中使用net/http，否则您的应用程序中没有程序包名称冲突. 复制名称的好处是它要求你将所有HTTP代码(译者注:与http通信相关的代码)隔离到http包中.\npackage http import ( \u0026quot;net/http\u0026quot; \u0026quot;github.com/benbjohnson/myapp\u0026quot; ) type Handler struct { UserService myapp.UserService } func (h *Handler) ServeHTTP(w http.ResponseWriter, r *http.Request) { // handle request } 现在，http.Handler充当您的域和HTTP协议之间的适配器\n3. 使用共享的mock子包 因为我们的依赖通过领域接口与其他依赖隔离，所以我们可以使用这些连接点来注入模拟实现.(译者注:依赖注入)\n有许多模拟库（例如GoMock）可以为你生成模拟，但我个人更喜欢自己编写mock. 因为我发现许多模拟工具过于复杂.\n我使用的模拟非常简单. 例如, UserService的模拟如下所示:\npackage mock import \u0026quot;github.com/benbjohnson/myapp\u0026quot; // UserService represents a mock implementation of myapp.UserService. type UserService struct { UserFn func(id int) (*myapp.User, error) UserInvoked bool UsersFn func() ([]*myapp.User, error) UsersInvoked bool // additional function implementations... } // User invokes the mock implementation and marks the function as invoked. func (s *UserService) User(id int) (*myapp.User, error) { s.UserInvoked = true return s.UserFn(id) } // additional functions: Users(), CreateUser(), DeleteUser() 译者注:此处的mock只涉及了是否调用,对于更verbose的mock,还可能涉及调用顺序等\n这个mock让我们可以注入函数到任何使用myapp.UserService接口的地方,我们可以借此来验证参数,返回期望数据,或者注入失败\n比如我们想测试我们之前定义的http.Handler:\npackage http_test import ( \u0026quot;testing\u0026quot; \u0026quot;net/http\u0026quot; \u0026quot;net/http/httptest\u0026quot; \u0026quot;github.com/benbjohnson/myapp/mock\u0026quot; ) func TestHandler(t *testing.T) { // Inject our mock into our handler. var us mock.UserService var h Handler h.UserService = \u0026amp;us // Mock our User() call. us.UserFn = func(id int) (*myapp.User, error) { if id != 100 { t.Fatalf(\u0026quot;unexpected id: %d\u0026quot;, id) } return \u0026amp;myapp.User{ID: 100, Name: \u0026quot;susy\u0026quot;}, nil } // Invoke the handler. w := httptest.NewRecorder() r, _ := http.NewRequest(\u0026quot;GET\u0026quot;, \u0026quot;/users/100\u0026quot;, nil) h.ServeHTTP(w, r) // Validate mock. if !us.UserInvoked { t.Fatal(\u0026quot;expected User() to be invoked\u0026quot;) } } mock让我们完全隔离单元测试到仅仅的http协议的处理上(译者注:如果没有mock,则单元测试将包含UserService的创建和http协议的处理,UserService的创建可能依赖很多东西)\n4.Main包将捆绑所有依赖 现在所有这些依赖都被隔离地漂浮在那里了, 您可能想知道它们是如何组合在一起的. 这就是main包的工作.\nMain包的布局 一个应用也许会产生出很多二进制文件,所以我们将使用Go的传统,将main包作为cmd包的一个子目录.比如,我们的项目也许有一个myapp的服务器二进制文件,但也有一个myappctl的客户端二进制文件用于通过终端管理服务器.我们列出这个main包的布局:\nmyapp/ cmd/ myapp/ main.go myappctl/ main.go 译者注: 一定要在app/cmd下再创建一个子目录,否则go build/go install出来默认是目录名,即cmd,且go install没办法rename\n编译时注入依赖 术语\u0026quot;依赖注入\u0026quot;从字面上描述的并不好.它使人想到了冗长的Spring XML文件. 但是,这个术语真正表示的是我们将要向对象传递依赖(译者注:作为NewXXX函数的参数传入),而不是要求这个对象自己建立或找到依赖.\nmain包就是我们选择哪个依赖被注入哪个对象的地方. 因为main包简单地将一小块一小块的依赖连接在一起(译者注:原文:wires up the pieces, 可见google/wire命名由来),它往往是比较小且琐碎的代码:\npackage main import ( \u0026quot;log\u0026quot; \u0026quot;os\u0026quot; \u0026quot;github.com/benbjohnson/myapp\u0026quot; \u0026quot;github.com/benbjohnson/myapp/postgres\u0026quot; \u0026quot;github.com/benbjohnson/myapp/http\u0026quot; ) func main() { // Connect to database. db, err := postgres.Open(os.Getenv(\u0026quot;DB\u0026quot;)) if err != nil { log.Fatal(err) } defer db.Close() // Create services. us := \u0026amp;postgres.UserService{DB: db} // Attach to HTTP handler. var h http.Handler h.UserService = us // start http server... } 同样重要的是要注意到,你的main包也是一个适配器(adapter). 它连接终端到你的领域.\n结论 应用设计是一个很难的问题. 存在太多需要做出的设计决策,并且如果没有一系列可靠的原则去指引你,问题将会被弄得更糟. 我们研究了当前Go应用程序设计的几种方法,并且发现了它们的许多缺陷.\n我相信从依赖关系的桀骜都着手进行设计将会使得代码组织的更简单,也更容易究因. 首先我们设计领域语言.然后我们隔离依赖.再接着我们引入mock来隔离测试. 最后,我们将所有内容捆绑在一起放在main包\n在下一个你设计的应用程序中考虑这些原则. 如果你有任何问题或想要讨论设计, contact me at @benbjohnson on Twitter or find me as benbjohnson on the Gopher slack.\n译者: @https://github.com/liwm29\n概括: 按依赖分包,各子包将实现根包定义的interface,且它们之间不可以互相import. 根包定义领域类型,如果依赖外部服务,则定义interface.最终在cmd/app/main.go中完成依赖注入\n","id":75,"section":"posts","summary":"\u003ch1 id=\"standard-package-layout\"\u003eStandard Package Layout\u003c/h1\u003e\n\u003cp\u003e标准包布局   -Ben Johnson \u003ca href=\"https://www.gobeyond.dev/standard-package-layout/\"\u003ehttps://www.gobeyond.dev/standard-package-layout/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eVendoring和Generics,它们在go社区似乎都是big issue,但还有一个很少提及的issue,就是应用的包布局(application package layout)\u003c/p\u003e","tags":["Golang"],"title":"[Go] standard package layout","uri":"https://wymli.github.io/2021/03/go-standard-package-layout/","year":"2021"},{"content":"用户线程与核心线程 ref: Scheduler Activations: Effective Kernel Support for the User-Level Management of Parallelism\n论文观点:\nWe argue that the performance of user-levelthreads is inherently better than that of kernel threads, rather than thisbeing an artifact of existing implementations. kernel threads are the wrong abstraction on which to support user-level management of parallelism. 1.用户线程的优势 The cost of accessing thread management operations. ","id":76,"section":"posts","summary":"\u003ch1 id=\"用户线程与核心线程\"\u003e用户线程与核心线程\u003c/h1\u003e\n\u003cp\u003eref: \u003ca href=\"https://flint.cs.yale.edu/cs422/doc/sched-act.pdf\"\u003eScheduler Activations: Effective Kernel Support for the  User-Level Management of Parallelism\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e论文观点:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eWe  argue  that  the  performance  of  user-levelthreads  is  inherently  better  than  that  of  kernel  threads,  rather  than  thisbeing  an  artifact  of  existing  implementations.\u003c/li\u003e\n\u003cli\u003ekernel   threads   are   the wrong   abstraction   on   which   to   support   user-level management   of   parallelism.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"1用户线程的优势\"\u003e1.用户线程的优势\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eThe  cost  of  accessing  thread  management  operations.\u003c/li\u003e\n\u003c/ol\u003e","tags":["Golang"],"title":"[Go] user thread","uri":"https://wymli.github.io/2021/03/go-user-thread/","year":"2021"},{"content":"About Content-Type Content-Type 用来指定在POST请求中body的数据类型(或格式),是一个非常重要的Header字段\n三种Content-Type application/x-www-form-urlencoded 默认类型,当form不指定enctype时使用此content-type 看名字就知道,urlencoded,当自己构造时,要对参数进行url转义 示例: a=123\u0026amp;b=123 go语言中,可以直接传string/[]byte给body,也可以是map[string]string,也可以是url.Values(typedef map[string][]string) 虽然这些都可以,但推荐url.Values,可以直接调用.encode(),自己构造的是没有encode的,但一般来说都没有问题,因为只有特殊字符需要encode! go server 解析: multipart/form-data(mime) 用于上传文件 html form 构造: form.enctype=\u0026quot;multipart/form-data\u0026quot; i.put:type=\u0026quot;file\u0026quot; go client 构造: import \u0026quot;mime/multipart\u0026quot; go server 解析: 首先解析: r.ParseMultipartForm(1024 * 1024) 取出来:image := r.MultipartForm.Value[\u0026quot;image\u0026quot;] 也可以看看gin的api,更方便 application/json json.marshall之后传进body即可 gin解析: id := c.Query(\u0026quot;id\u0026quot;) c.PostForm(\u0026quot;name\u0026quot;) // 也可以bind进一个结构体 // 推荐使用bind,可以很方便的进行表单验证 // get:BindQuery , post:bindjson/bindxml/... c.ShouldBind(\u0026amp;person) // 单文件 router.MaxMultipartMemory = 8 \u0026lt;\u0026lt; 20 file, _ := c.FormFile(\u0026quot;file\u0026quot;) c.SaveUploadedFile(file, dst) // 多文件 form, _ := c.MultipartForm() files := form.File[\u0026quot;upload[]\u0026quot;] ","id":77,"section":"posts","summary":"\u003ch1 id=\"about-content-type\"\u003eAbout Content-Type\u003c/h1\u003e\n\u003cp\u003eContent-Type 用来指定在POST请求中body的数据类型(或格式),是一个非常重要的Header字段\u003c/p\u003e\n\u003ch2 id=\"三种content-type\"\u003e三种Content-Type\u003c/h2\u003e\n\u003ch3 id=\"applicationx-www-form-urlencoded\"\u003eapplication/x-www-form-urlencoded\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e默认类型,当form不指定enctype时使用此content-type\u003c/li\u003e\n\u003cli\u003e看名字就知道,urlencoded,当自己构造时,要对参数进行url转义\u003c/li\u003e\n\u003cli\u003e示例: \u003ccode\u003ea=123\u0026amp;b=123\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003ego语言中,可以直接传string/[]byte给body,也可以是map[string]string,也可以是url.Values(typedef map[string][]string)\n\u003cul\u003e\n\u003cli\u003e虽然这些都可以,但推荐url.Values,可以直接调用.encode(),自己构造的是没有encode的,但一般来说都没有问题,因为只有特殊字符需要encode!\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ch2 id=\"go-server-解析\"\u003ego server 解析:\u003c/h2\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"multipartform-datamime\"\u003emultipart/form-data(mime)\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e用于上传文件\u003c/li\u003e\n\u003cli\u003ehtml form 构造: \u003ccode\u003eform.enctype=\u0026quot;multipart/form-data\u0026quot; i.put:type=\u0026quot;file\u0026quot;\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003ego client 构造: \u003ccode\u003eimport \u0026quot;mime/multipart\u0026quot;\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003ego server 解析:\n\u003cul\u003e\n\u003cli\u003e首先解析: \u003ccode\u003er.ParseMultipartForm(1024 * 1024)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e取出来:\u003ccode\u003eimage := r.MultipartForm.Value[\u0026quot;image\u0026quot;] \u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e也可以看看gin的api,更方便\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"applicationjson\"\u003eapplication/json\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003ejson.marshall之后传进body即可\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"gin解析\"\u003egin解析:\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-go\"\u003eid := c.Query(\u0026quot;id\u0026quot;)\nc.PostForm(\u0026quot;name\u0026quot;)\n// 也可以bind进一个结构体\n// 推荐使用bind,可以很方便的进行表单验证\n// get:BindQuery , post:bindjson/bindxml/...\nc.ShouldBind(\u0026amp;person)\n\n\n// 单文件\nrouter.MaxMultipartMemory = 8 \u0026lt;\u0026lt; 20 \nfile, _ := c.FormFile(\u0026quot;file\u0026quot;)\nc.SaveUploadedFile(file, dst)\n\n// 多文件\nform, _ := c.MultipartForm()\nfiles := form.File[\u0026quot;upload[]\u0026quot;]\n\n\u003c/code\u003e\u003c/pre\u003e","tags":["HTTP"],"title":"[HTTP] Content-Type","uri":"https://wymli.github.io/2021/03/http-content-type/","year":"2021"},{"content":"ByteDance\u0026amp;Tencent 2021/3 暑期实习\n腾讯一面 上来抛了道js,问我输出 const a = ( i : 0, toString(){ return i++ } ) print(a == 0 \u0026amp;\u0026amp; a==1 \u0026amp;\u0026amp; a==2) 答案是false,没答出来,我当时主要纠结于为什么会调用toString呢 问了下闭包,以及和方法引用对象变量的区别 union结构体,柔性数组 讲讲TCP三次握手,序数是从0开始吗 不是 讲讲数据包从本机到公网的历程 讲了arp,交换机,路由器这些 讲讲物理层的冲突 载波侦听多路访问 交换机和路由器的区别 交换机的端口分向内向外吗 不分,一个广播域,一个子网 了解tcmalloc吗 不懂,查了下,是thread cache malloc,一种内存管理中的内存分配方法 介绍自己的项目,聊到多态哈希,问我的并发控制是怎么做的 读写锁,map分片 哈希怎么做的内存管理 用bitmap,不是像slab用链表 等等,多数忘了 二面 今天早上过了tx的二面,感觉面的很简单\n讨论项目 问我了不了解第三方登陆接口 不了解,查了下,和OAuth有关 做题 用三种方法,计算一个数字转化为二进制后有多少个1 for{b = a\u0026amp;1,a = a\u0026raquo;1,\u0026hellip;..} 经典leetcode,找到数组第k大数 快排/优先队列 问了下算法复杂度 12个鸡蛋,一个天平,怎样快速识别出来唯一的坏鸡蛋 忘了 字节 接雨水,本菜鸡没写出来 TCP三次握手,四次挥手 额外讲了个两个positive socket之间的主动连接 四次挥手可以是3次吗 回答可以,关闭连接的本质在于自己不再写socket,所以只要收到对方的fin,并且自己不再需要写,便可以返回fin+ack,没必要分开发 SYN半连接攻击 导致SYN队列满 额外讲了个TCP cookie,用来解决SYN队列满的问题 go GC 标记清扫法,三色标记法,混合写屏障 数据库事务的特性 ACID 原子性:要么发生要么不发生 一致性:相容性,互相不矛盾 隔离性:四个隔离级别 持久性: 刷回硬盘,分数据和日志 讲讲隔离性中的幻读 即读出了其他事务插入的行,本质是只锁了行,可以通过gap锁来锁区间 innoDB的索引 B+树 B+树的特点 叶子节点存数据,且链起来,方便顺序遍历 B+树的优点 有序性:区间查找快,相较于B树的中序遍历,和hash的无序性 快速性: B+树更矮胖,查找的层级会更少,3层B+树可以容纳2kw个数据 稳定性: 因为数据都在叶子节点,所以搜索数据都必须搜到最底层 稳定性的好处,其实在于其非叶子节点容纳了更多的指向下一层的指针,这导致io次数急剧下降,所以应该说,不是稳定性的好处,而是B+树非叶子节点不存数据的好处(这导致了稳定性),想象一下.任意2kw数据,都可以只通过3次io就查出来,快到极致,反观B树,一层最多16个指针,16^6=1.6kw 可惜,当时我不会 结束 可以看出字节会偏向八股文一点,但是我个人觉得这是有必要的,因为虽然都是些基础概念,但每个人都会有自己的理解,而且都是比较简单的吧,如果不会,一是基础问题,二是态度问题.\n并且字节问了我go的GC,这是我比较感动的,毕竟我简历上写着目标岗位是go后端开发:)\n","id":78,"section":"posts","summary":"\u003ch1 id=\"bytedancetencent\"\u003eByteDance\u0026amp;Tencent\u003c/h1\u003e\n\u003cp\u003e2021/3 暑期实习\u003c/p\u003e\n\u003ch3 id=\"腾讯一面\"\u003e腾讯一面\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e上来抛了道js,问我输出\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class=\"language-js\"\u003econst a = (\n   i : 0,\n   toString(){\n      return i++\n   }\n)\nprint(a == 0 \u0026amp;\u0026amp; a==1 \u0026amp;\u0026amp; a==2)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003e答案是false,没答出来,我当时主要纠结于为什么会调用toString呢\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e问了下闭包,以及和方法引用对象变量的区别\u003c/li\u003e\n\u003cli\u003eunion结构体,柔性数组\u003c/li\u003e\n\u003cli\u003e讲讲TCP三次握手,序数是从0开始吗\n\u003col\u003e\n\u003cli\u003e不是\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e讲讲数据包从本机到公网的历程\n\u003col\u003e\n\u003cli\u003e讲了arp,交换机,路由器这些\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e讲讲物理层的冲突\n\u003col\u003e\n\u003cli\u003e载波侦听多路访问\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e交换机和路由器的区别\u003c/li\u003e\n\u003cli\u003e交换机的端口分向内向外吗\n\u003col\u003e\n\u003cli\u003e不分,一个广播域,一个子网\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e了解tcmalloc吗\n\u003col\u003e\n\u003cli\u003e不懂,查了下,是thread cache malloc,一种内存管理中的内存分配方法\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e介绍自己的项目,聊到多态哈希,问我的并发控制是怎么做的\n\u003col\u003e\n\u003cli\u003e读写锁,map分片\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e哈希怎么做的内存管理\n\u003col\u003e\n\u003cli\u003e用bitmap,不是像slab用链表\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e等等,多数忘了\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"二面\"\u003e二面\u003c/h3\u003e\n\u003cp\u003e今天早上过了tx的二面,感觉面的很简单\u003c/p\u003e","tags":["Interview"],"title":"[Interview] ByteDance\u0026Tencent","uri":"https://wymli.github.io/2021/03/interview-bytedancetencent/","year":"2021"},{"content":"记录一下为面试做的准备 声明: 以下知识点可能不完全正确,但也不会错的太离谱\n记录一些知识点\n数据库事务的四个特性: ACID 原子性,一致性,隔离性,持久性 事务的隔离级别: 读未提交 : 即脏读 读提交: 解决脏读,可以读到其他事务提交了的行 读重复: 可以重复读数据,但是存在幻读(即对方插入了新的数据行,你是可以重复读出来行数不一样的)(要解决这个问题要锁全表) 读串化: 加表级锁 InnoDB的索引: B+树,有利于范围选择(对比hash和b树),B+树的数据指针节点都在叶子节点 3层的B+树可以支持2kw数据索引(基于一页放一个结点,一页16KB,一行数据1KB) 四,七层负载均衡: 四层:传输层,根据(ip:port)来映射到不同的app server,其工作本质类似于一个NAT,它不查看包的内容 七层:应用层,以http为例,它可能会解析出http request line/header,根据url来映射到不同的app server 不管是哪种方式,连接都是client和proxy建立,proxy再与app server建立 中断的分类: 外部中断: 外部io设备中断 内部中断 受迫中断: 除零等 自主中断: 系统调用 os是中断驱动的软件(指令序列) 内核态与用户态切换的开销(系统调用的开销): 几百ns左右 特权模式的切换本身应该没有多耗时,主要是这个系统调用本身底层可能要执行数百条指令 对于getpid这样的系统调用,其实也是很快的,个位数ns左右 需要切换堆栈指针寄存器等 进程上下文切换的开销(deprecated: see 16 instead) 进入内核态 切换页表寄存器指针 切换硬件寄存器上下文 执行调度代码(比如PCB进入运行队列) 冷启动造成的频繁缺页 硬件线程上下文切换的开销 切换硬件寄存器上下文 内核态进行 用户线程(协程)上下文切换的开销 用户态进行,超轻量 线程比进程轻量的原因: 页表缓存 协程比线程轻量的原因: 不用进入内核态 https: 7次握手(tcp3+tls4) io复用: select和poll类似,需要自己去遍历整个event数组寻找哪些可读可写; epoll返回激活fd的数目fds,访问event数组的前fds个event即可 进程切换的开销: ref 直接开销: pcb的各字段的load\u0026amp;store(页表指针,界限指针等)(从内存到寄存器) 间接开销: cold cache 内核线程切换的开销: 直接开销: pcb的各字段的load\u0026amp;store(页表指针,界限指针等)(从内存到寄存器) 线程和进程都是task_struct 用户态线程的开销: 不需要进入内核态(进入内核态涉及中断) 指令级并行: ILP 多发射,超标量(动态多发射) 多个取值译码器,多个ALU,单个执行上下文(所以只支持单进程的多发射乱序执行) 线程级并行: 多核程序 单核多线程也可以,比如intel的四核八线程,在指令级并行的基础上增加多个执行上下文 数据级并行: SIMD 单个取值译码器,超多个ALU TLS握手: client hello,client random server hello,server random,server certificate client encode premaster secret using server public key \u0026lt;-\u0026gt;通信双方根据预主密钥和random计算出对称密钥,用于后续通信的加密 server-\u0026gt;client , finished 为什么要random: 避免重放攻击? 个人感觉不是,random就只是单纯的random一下,为了生成一个不易被爆破的密钥吧 为了避免重放,应该为每一个报文加一个序号 为什么要对称密钥加密,而不是直接server公钥: 对称密钥加解密速度快 tcp三次握手,最后一次为什么要握手,没有行不行? 为了防止无意的过期连接的建立 可以类比有意的syn攻击(一种dos攻击) 防御手段? tcp cookie? 数据库并发控制 悲观锁: 一次封锁或两阶段锁 一次封锁: 有效防止死锁,在事务开始时,一次获取所有锁,事务结束后释放所有锁 两阶段锁: 可能死锁, 事务分为growing阶段和shrinking阶段,前一个阶段只能获取锁,后一个阶段只能释放锁 解决死锁: 死锁检测: 维护一个锁等待图,追踪每个事务要获得哪些锁,图中节点是事务,边是等待关系(i-\u0026gt;j, 表示事务i等待事务j释放锁) ,系统周期性检查图中是否有环, 有环则死锁,对其中一个restart或者abort 死锁避免: 当事务i想要获取事务j的某个锁,dbms杀掉i或j来避免死锁 old waits for young(wait-die) 如果请求事务比持有事务启动的早,则请求事务wait; 否则请求事务abort young waits for old(wound-wait) 如果请求事务比持有事务启动的早,则持有事务abort,释放锁; 否则等待 悲观锁的缺点: 大多数db读多于写,减少了潜在的并行性 意向锁: An intention lockallows a higher-level node to be locked in sharedor exclusivemode without having to check all descendent nodes. 如果表有意向读锁,则说明某一行加了读锁 如果表有意向写锁,则说明某一行加了写锁 意向锁与锁有一定的兼容性,本质是为了快速判断某一事物是否能在这个表上完成: 共享意向排他锁SIX: 表示读取整个表,修改部分行(即 S + IX),只有当某个事务是读取某一行时,才让其进入表(与之兼容) 乐观锁: 基于时间戳排序的协议(保证执行效果就像按时间戳串行一样) 不加锁,每个事务启动时获取一个唯一时间戳. 表的每一行都维护读时间戳和写时间戳 行的读写时间戳不能和事务启动时间戳矛盾 另一种方法,不在运行时验证,而是先写到自己的空间,事务提交时统一验证 OCC phases(optimistic concurrency control) 读阶段,The DBMS copies every tuple that the txnaccesses from the shared database to its workspace ensure repeatable reads. 验证阶段: When txnTi invokes COMMIT, the DBMS checks if it conflicts with other txns. 写阶段:The DBMS propagates the changes in the txn’swrite set to the database and makes them visible to other txns 多版本并发控制 对于每一行,维护多个版本,只要一个事务写或修改了一行,就创建一个那一行的新版本(版本基于时间戳) 事务读时,会自己选择去读最新的与事务启动时间戳兼容的版本 日志记录(持久化机制) 高可用: 短暂的系统中断时间,能快速恢复(类比汽车的备胎) 容错: 系统故障,但继续提供服务,因为冗余节点(类比飞机的多个发动机) 灾备(disaster recovery): 系统故障后,如何抢救业务数据,放弃基础设施 外排序: 以归并排序为例,对900MB数据排序,内存100MB 归并排序是divide-and-conquer算法,先分成多块,分别sort,然后对这排好序的多快进行merge 900/100 = 9,所有9路归并 divide-sort阶段: 对这9块数据,每块100MB,依次读入内存,进行内排序sort,写出内存 merge阶段: 内存分为9个input buffer和1个output buffer;每次对每块读入10MB,进行merge,output buffer满后写出内存,input buffer满后,从自己那块再从磁盘取 redis持久化机制: RDB:redis database 将数据快照保存在磁盘上 命令: save(同步save) , bgsave(异步save),自动同步(配置文件) 缺点: 自动同步时间一般设置的较大,比如100s,实时性不够 显然不能频繁写,因为要把内存全部覆盖到磁盘,数据量还是很大的 AOF: append-only-file 存储日志,恢复时redo,可以配置每一条指令,或每秒fsync一次 缺点:aof文件比rdb文件大 优点: append-only,方便磁盘寻址 bgrewriteaof,对aof文件重写(优化),目的是为了减少指令数目,用尽可能少的指令数目完成一样的功能; 有助于数据恢复速度和磁盘空间 WAL: write ahead log 先写日志再写数据 ","id":79,"section":"posts","summary":"\u003ch1 id=\"记录一下为面试做的准备\"\u003e记录一下为面试做的准备\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e声明: 以下知识点可能不完全正确,但也不会错的太离谱\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e记录一些知识点\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e数据库事务的四个特性: ACID 原子性,一致性,隔离性,持久性\u003c/li\u003e\n\u003cli\u003e事务的隔离级别:\n\u003col\u003e\n\u003cli\u003e读未提交 : 即脏读\u003c/li\u003e\n\u003cli\u003e读提交: 解决脏读,可以读到其他事务提交了的行\u003c/li\u003e\n\u003cli\u003e读重复: 可以重复读数据,但是存在幻读(即对方插入了新的数据行,你是可以重复读出来行数不一样的)(要解决这个问题要锁全表)\u003c/li\u003e\n\u003cli\u003e读串化: 加表级锁\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eInnoDB的索引: B+树,有利于范围选择(对比hash和b树),B+树的数据指针节点都在叶子节点\u003c/li\u003e\n\u003cli\u003e3层的B+树可以支持2kw数据索引(基于一页放一个结点,一页16KB,一行数据1KB)\u003c/li\u003e\n\u003cli\u003e四,七层负载均衡:\n\u003col\u003e\n\u003cli\u003e四层:传输层,根据(ip:port)来映射到不同的app server,其工作本质类似于一个NAT,它不查看包的内容\u003c/li\u003e\n\u003cli\u003e七层:应用层,以http为例,它可能会解析出http request line/header,根据url来映射到不同的app server\u003c/li\u003e\n\u003cli\u003e不管是哪种方式,连接都是client和proxy建立,proxy再与app server建立\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e中断的分类:\n\u003col\u003e\n\u003cli\u003e外部中断: 外部io设备中断\u003c/li\u003e\n\u003cli\u003e内部中断\n\u003col\u003e\n\u003cli\u003e受迫中断: 除零等\u003c/li\u003e\n\u003cli\u003e自主中断: 系统调用\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eos是中断驱动的软件(指令序列)\u003c/li\u003e\n\u003cli\u003e内核态与用户态切换的开销(系统调用的开销): 几百ns左右\n\u003col\u003e\n\u003cli\u003e特权模式的切换本身应该没有多耗时,主要是这个系统调用本身底层可能要执行数百条指令\u003c/li\u003e\n\u003cli\u003e对于getpid这样的系统调用,其实也是很快的,个位数ns左右\u003c/li\u003e\n\u003cli\u003e需要切换堆栈指针寄存器等\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e进程上下文切换的开销(deprecated: see 16 instead)\n\u003col\u003e\n\u003cli\u003e进入内核态\u003c/li\u003e\n\u003cli\u003e切换页表寄存器指针\u003c/li\u003e\n\u003cli\u003e切换硬件寄存器上下文\u003c/li\u003e\n\u003cli\u003e执行调度代码(比如PCB进入运行队列)\u003c/li\u003e\n\u003cli\u003e冷启动造成的频繁缺页\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e硬件线程上下文切换的开销\n\u003col\u003e\n\u003cli\u003e切换硬件寄存器上下文\u003c/li\u003e\n\u003cli\u003e内核态进行\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e用户线程(协程)上下文切换的开销\n\u003col\u003e\n\u003cli\u003e用户态进行,超轻量\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e线程比进程轻量的原因: 页表缓存\u003c/li\u003e\n\u003cli\u003e协程比线程轻量的原因: 不用进入内核态\u003c/li\u003e\n\u003cli\u003ehttps: 7次握手(tcp3+tls4)\u003c/li\u003e\n\u003cli\u003eio复用: select和poll类似,需要自己去遍历整个event数组寻找哪些可读可写; epoll返回激活fd的数目fds,访问event数组的前fds个event即可\u003c/li\u003e\n\u003cli\u003e进程切换的开销: \u003ca href=\"https://www.youtube.com/watch?v=lS1GOdXFLJo\"\u003eref\u003c/a\u003e\n\u003col\u003e\n\u003cli\u003e直接开销: pcb的各字段的load\u0026amp;store(页表指针,界限指针等)(从内存到寄存器)\u003c/li\u003e\n\u003cli\u003e间接开销: cold cache\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e内核线程切换的开销:\n\u003col\u003e\n\u003cli\u003e直接开销: pcb的各字段的load\u0026amp;store(页表指针,界限指针等)(从内存到寄存器)\u003c/li\u003e\n\u003cli\u003e线程和进程都是task_struct\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e用户态线程的开销:\n\u003col\u003e\n\u003cli\u003e不需要进入内核态(进入内核态涉及中断)\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e指令级并行: ILP 多发射,超标量(动态多发射)\n\u003col\u003e\n\u003cli\u003e多个取值译码器,多个ALU,单个执行上下文(所以只支持单进程的多发射乱序执行)\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e线程级并行: 多核程序\n\u003col\u003e\n\u003cli\u003e单核多线程也可以,比如intel的四核八线程,在指令级并行的基础上增加多个执行上下文\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e数据级并行: SIMD\n\u003col\u003e\n\u003cli\u003e单个取值译码器,超多个ALU\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eTLS握手:\n\u003col\u003e\n\u003cli\u003eclient hello,client random\u003c/li\u003e\n\u003cli\u003eserver hello,server random,server certificate\u003c/li\u003e\n\u003cli\u003eclient encode premaster secret using server public key\u003c/li\u003e\n\u003cli\u003e\u0026lt;-\u0026gt;通信双方根据预主密钥和random计算出对称密钥,用于后续通信的加密\u003c/li\u003e\n\u003cli\u003eserver-\u0026gt;client ,  finished\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e为什么要random: 避免重放攻击?\n\u003col\u003e\n\u003cli\u003e个人感觉不是,random就只是单纯的random一下,为了生成一个不易被爆破的密钥吧\u003c/li\u003e\n\u003cli\u003e为了避免重放,应该为每一个报文加一个序号\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e为什么要对称密钥加密,而不是直接server公钥: 对称密钥加解密速度快\u003c/li\u003e\n\u003cli\u003etcp三次握手,最后一次为什么要握手,没有行不行?\n\u003col\u003e\n\u003cli\u003e为了防止无意的过期连接的建立\u003c/li\u003e\n\u003cli\u003e可以类比有意的syn攻击(一种dos攻击)\n\u003col\u003e\n\u003cli\u003e防御手段? tcp cookie?\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e数据库并发控制\n\u003col\u003e\n\u003cli\u003e悲观锁: 一次封锁或两阶段锁\n\u003col\u003e\n\u003cli\u003e一次封锁: 有效防止死锁,在事务开始时,一次获取所有锁,事务结束后释放所有锁\u003c/li\u003e\n\u003cli\u003e两阶段锁: 可能死锁, 事务分为growing阶段和shrinking阶段,前一个阶段只能获取锁,后一个阶段只能释放锁\n\u003col\u003e\n\u003cli\u003e解决死锁:\n\u003col\u003e\n\u003cli\u003e死锁检测: 维护一个锁等待图,追踪每个事务要获得哪些锁,图中节点是事务,边是等待关系(i-\u0026gt;j, 表示事务i等待事务j释放锁) ,系统周期性检查图中是否有环, 有环则死锁,对其中一个restart或者abort\u003c/li\u003e\n\u003cli\u003e死锁避免:  当事务i想要获取事务j的某个锁,dbms杀掉i或j来避免死锁\n\u003col\u003e\n\u003cli\u003eold waits for young(wait-die)\n\u003col\u003e\n\u003cli\u003e如果请求事务比持有事务启动的早,则请求事务wait; 否则请求事务abort\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eyoung waits for old(wound-wait)\n\u003col\u003e\n\u003cli\u003e如果请求事务比持有事务启动的早,则持有事务abort,释放锁; 否则等待\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e悲观锁的缺点: 大多数db读多于写,减少了潜在的并行性\u003c/li\u003e\n\u003cli\u003e意向锁: An intention lockallows a higher-level node to be locked in sharedor exclusivemode without having to check all descendent nodes.\n\u003col\u003e\n\u003cli\u003e如果表有意向读锁,则说明某一行加了读锁\u003c/li\u003e\n\u003cli\u003e如果表有意向写锁,则说明某一行加了写锁\u003c/li\u003e\n\u003cli\u003e意向锁与锁有一定的兼容性,本质是为了快速判断某一事物是否能在这个表上完成:\n\u003col\u003e\n\u003cli\u003e\n\u003cimg src=\"C:\\Users\\salvare000\\AppData\\Roaming\\Typora\\typora-user-images\\image-20210309091233223.png\" alt=\"image-20210309091233223\"  /\u003e\n\u003c/li\u003e\n\u003cli\u003e共享意向排他锁SIX: 表示读取整个表,修改部分行(即 S + IX),只有当某个事务是读取某一行时,才让其进入表(与之兼容)\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e乐观锁: 基于时间戳排序的协议(保证执行效果就像按时间戳串行一样)\n\u003col\u003e\n\u003cli\u003e不加锁,每个事务启动时获取一个唯一时间戳. 表的每一行都维护读时间戳和写时间戳\n\u003col\u003e\n\u003cli\u003e行的读写时间戳不能和事务启动时间戳矛盾\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e另一种方法,不在运行时验证,而是先写到自己的空间,事务提交时统一验证\n\u003col\u003e\n\u003cli\u003eOCC phases(optimistic concurrency control)\n\u003col\u003e\n\u003cli\u003e读阶段,The DBMS copies every tuple that the txnaccesses from the shared database to its workspace ensure repeatable reads.\u003c/li\u003e\n\u003cli\u003e验证阶段: When txnTi invokes COMMIT, the DBMS checks if it conflicts with other txns.\u003c/li\u003e\n\u003cli\u003e写阶段:The DBMS propagates the changes in the txn’swrite set to the database and makes them visible to other txns\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e多版本并发控制\n\u003col\u003e\n\u003cli\u003e对于每一行,维护多个版本,只要一个事务写或修改了一行,就创建一个那一行的新版本(版本基于时间戳)\u003c/li\u003e\n\u003cli\u003e事务读时,会自己选择去读最新的与事务启动时间戳兼容的版本\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e日志记录(持久化机制)\u003c/li\u003e\n\u003cli\u003e高可用:  短暂的系统中断时间,能快速恢复(类比汽车的备胎)\u003c/li\u003e\n\u003cli\u003e容错: 系统故障,但继续提供服务,因为冗余节点(类比飞机的多个发动机)\u003c/li\u003e\n\u003cli\u003e灾备(disaster recovery): 系统故障后,如何抢救业务数据,放弃基础设施\u003c/li\u003e\n\u003cli\u003e外排序: 以归并排序为例,对900MB数据排序,内存100MB\n\u003col\u003e\n\u003cli\u003e归并排序是divide-and-conquer算法,先分成多块,分别sort,然后对这排好序的多快进行merge\u003c/li\u003e\n\u003cli\u003e900/100 = 9,所有9路归并\u003c/li\u003e\n\u003cli\u003edivide-sort阶段: 对这9块数据,每块100MB,依次读入内存,进行内排序sort,写出内存\u003c/li\u003e\n\u003cli\u003emerge阶段: 内存分为9个input buffer和1个output buffer;每次对每块读入10MB,进行merge,output buffer满后写出内存,input buffer满后,从自己那块再从磁盘取\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eredis持久化机制:\n\u003col\u003e\n\u003cli\u003eRDB:redis database\u003c/li\u003e\n\u003cli\u003e将数据快照保存在磁盘上\u003c/li\u003e\n\u003cli\u003e命令: save(同步save) , bgsave(异步save),自动同步(配置文件)\u003c/li\u003e\n\u003cli\u003e缺点: 自动同步时间一般设置的较大,比如100s,实时性不够\n\u003col\u003e\n\u003cli\u003e显然不能频繁写,因为要把内存全部覆盖到磁盘,数据量还是很大的\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eAOF: append-only-file\n\u003col\u003e\n\u003cli\u003e存储日志,恢复时redo,可以配置每一条指令,或每秒fsync一次\u003c/li\u003e\n\u003cli\u003e缺点:aof文件比rdb文件大\u003c/li\u003e\n\u003cli\u003e优点: append-only,方便磁盘寻址\u003c/li\u003e\n\u003cli\u003ebgrewriteaof,对aof文件重写(优化),目的是为了减少指令数目,用尽可能少的指令数目完成一样的功能; 有助于数据恢复速度和磁盘空间\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eWAL: write ahead log\n\u003col\u003e\n\u003cli\u003e先写日志再写数据\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e","tags":["Interview"],"title":"[Interview] 杂","uri":"https://wymli.github.io/2021/03/interview-%E6%9D%82/","year":"2021"},{"content":"[linux] 关于后台运行进程的小实验 我们经常有将进程放到后台运行的需求,我们可以通过编程实现守护模式,也可以在shell中启动进程的时候配置\n守护模式 通过编程,可以使得程序进入daemon模式\nfork和setsid\nshell启动命令 \u0026amp; 使用\u0026amp;可以让进程后台运行,但是仍然会输出到终端上\nsetsid ./test.sh \u0026amp; 设置父进程为init进程 ","id":80,"section":"posts","summary":"\u003ch1 id=\"linux-关于后台运行进程的小实验\"\u003e[linux] 关于后台运行进程的小实验\u003c/h1\u003e\n\u003cp\u003e我们经常有将进程放到后台运行的需求,我们可以通过编程实现守护模式,也可以在shell中启动进程的时候配置\u003c/p\u003e\n\u003ch2 id=\"守护模式\"\u003e守护模式\u003c/h2\u003e\n\u003cp\u003e通过编程,可以使得程序进入daemon模式\u003c/p\u003e","tags":["server"],"title":"[linux] daemon","uri":"https://wymli.github.io/2021/03/linux-bg-run-linux/","year":"2021"},{"content":"高性能linux服务器 服务器监听范式 一个传统的单线程服务器\ngraph LR; A[\u0026quot;socket()\u0026quot;]--\u0026gt;B(sockfd); B--\u0026gt;|\u0026quot;setsockopt()\u0026quot;| C[bind] C--\u0026gt;D[listen] D--\u0026gt;E[accept] E--\u0026gt;|connfd|F[\u0026quot;dowork(){read/write connfd}\u0026quot;] F--\u0026gt;|\u0026quot;while (1)\u0026quot;| E 一个传统的多线程服务器, pthread也可以换成fork,多进程\ngraph LR; A[\u0026quot;socket()\u0026quot;]--\u0026gt;B(sockfd); B--\u0026gt;|\u0026quot;setsockopt()\u0026quot;| C[bind] C--\u0026gt;D[listen] D--\u0026gt;E[accept] E--\u0026gt;|connfd|F[pthread_create] F--\u0026gt;|pthread|G[threadRoutine]--\u0026gt;O[\u0026quot;dowork(){read/write connfd}\u0026quot;] F--\u0026gt;|pthread|H[threadRoutine]--\u0026gt;Oo[\u0026quot;dowork(){read/write connfd}\u0026quot;] F--\u0026gt;|pthread|I[threadRoutine]--\u0026gt;Ooo[\u0026quot;dowork(){read/write connfd}\u0026quot;] F--\u0026gt;|\u0026quot;while (1)\u0026quot;| E 一个传统的多线程服务器,多线程同时accpet同一个sockfd\n这种方法应该会触发所谓的__\u0026ldquo;惊群现象\u0026rdquo;__,在linux2.6后,如果是多进程调用sockfd.accept(),则惊群被解决\n如果是使用epoll_wait()监听sockfd,则仍然存在惊群问题,其原因很明显,因为只是在监听文件描述符,内核没权利指定到底哪个线程epoll_wait成功,而accept()解决惊群则是因为将accept设计成了某种意义上的原子指令\n解决方法是对多个线程,任何时刻都只让一个线程去epoll_wait sockfd\ngraph LR; A[\u0026quot;socket()\u0026quot;]--\u0026gt;B(sockfd); B--\u0026gt;|\u0026quot;setsockopt()\u0026quot;| C[bind] C--\u0026gt;D[listen]--\u0026gt;F[pthread_create] F--\u0026gt;|pthread|G[threadRoutine]--\u0026gt;aa[accept]--\u0026gt;|connfd|O[\u0026quot;dowork(){read/write connfd}\u0026quot;]--\u0026gt;|\u0026quot;while (1)\u0026quot;|aa F--\u0026gt;|pthread|H[threadRoutine]--\u0026gt;aaa[accept]--\u0026gt;|connfd|Oo[\u0026quot;dowork(){read/write connfd}\u0026quot;]--\u0026gt;|\u0026quot;while (1)\u0026quot;|aaa F--\u0026gt;|pthread|I[threadRoutine]--\u0026gt;aaaa[accept]--\u0026gt;|connfd|Ooo[\u0026quot;dowork(){read/write connfd}\u0026quot;]--\u0026gt;|\u0026quot;while (1)\u0026quot;|aaaa 一个现代的多线程服务器,使用了SO_REUSEPORT来达到多个普通的sockfd绑定到同一个port,这样的好处是内核帮你实现了负载均衡,由于是不同的sockfd,所以即使使用epoll_wait,也只会有一个sockfd被唤醒\ngraph LR; x[pthread_create]--\u0026gt;A xa[pthread_create]--\u0026gt;Aa xaa[pthread_create]--\u0026gt;Aaa A[\u0026quot;socket()\u0026quot;]--\u0026gt;B(sockfd); Aa[\u0026quot;socket()\u0026quot;]--\u0026gt;Ba(sockfd); Aaa[\u0026quot;socket()\u0026quot;]--\u0026gt;Baa(sockfd); B--\u0026gt;|\u0026quot;setsockopt(so_reuseport)\u0026quot;| C[bind] Ba--\u0026gt;|\u0026quot;setsockopt(so_reuseport)\u0026quot;| Ca[bind] Baa--\u0026gt;|\u0026quot;setsockopt(so_reuseport)\u0026quot;| Caa[bind] C--\u0026gt;D[listen] Ca--\u0026gt;Da[listen] Caa--\u0026gt;Daa[listen] D--\u0026gt;aa[accept]--\u0026gt;|connfd|O[\u0026quot;dowork(){read/write connfd}\u0026quot;]--\u0026gt;|\u0026quot;while (1)\u0026quot;|aa Da--\u0026gt;aaa[accept]--\u0026gt;|connfd|Oo[\u0026quot;dowork(){read/write connfd}\u0026quot;]--\u0026gt;|\u0026quot;while (1)\u0026quot;|aaa Daa--\u0026gt;aaaa[accept]--\u0026gt;|connfd|Ooo[\u0026quot;dowork(){read/write connfd}\u0026quot;]--\u0026gt;|\u0026quot;while (1)\u0026quot;|aaaa SO_REUSEPORT\u0026amp;SO_REUSEADDR SO_REUSEADDR 常见的是用于复用监听TIME_WAIT状态的端口,对于多线程监听同一个端口,也需要使用这个参数\nSO_REUSEPORT\n为了解决上述的常见的多线程处理网络请求的需求,linux推出了一个sockopt参数:\n首先给出官方文档的介绍,很清晰了\nSO_REUSEPORT (since Linux 3.9)\nPermits multiple AF_INET or AF_INET6 sockets to be bound to an identical socket address. This option must be set on each socket (including the first socket) prior to calling bind(2) on the socket. To prevent port hijacking, all of the processes binding to the same address must have the same effective UID. This option can be employed with both TCP and UDP sockets.\nFor TCP sockets, this option allows accept(2) load distribution in a multi-threaded server to be improved by using a distinct listener socket for each thread. This provides improved load distribution as compared to traditional techniques such using a single accept(2)ing thread that distributes connections, or having multiple threads that compete to accept(2) from the same socket.\nFor UDP sockets, the use of this option can provide better distribution of incoming datagrams to multiple processes (or threads) as compared to the traditional technique of having multiple processes compete to receive datagrams on the same socket.\n在go中如何实现呢?我们知道一般提供的都是linux c的api,对于go,当然可以通过syscall,但还是会有些不同\n具体可以看看这个repo: https://github.com/kavu/go_reuseport/blob/47bb7f1bfa3921a92422a1eb4f0941e9caed1103/tcp.go#L96\n如何完成syscall得到的fd与go语言内置的net.Listener之间的转换,可能是一个关键\n在该库中,是这样实现\n由于SO_REUSEPORT在go中尚未提供,所有直接用 var reusePort = 0x0F 代替\ngraph TD; fx[\u0026quot;begin\u0026quot;]--\u0026gt;|\u0026quot;syscall.ForkLock.RLock()\u0026quot;|a a[\u0026quot;syscall.Socket(soType, syscall.SOCK_STREAM, syscall.IPPROTO_TCP)\u0026quot;]--\u0026gt;|\u0026quot;syscall.ForkLock.RUnlock()\u0026quot;|b[fd] b--\u0026gt;c[\u0026quot;syscall.SetsockoptInt(fd, syscall.SOL_SOCKET, syscall.SO_REUSEADDR, 1)\u0026quot;] c--\u0026gt;d[\u0026quot;syscall.SetsockoptInt(fd, syscall.SOL_SOCKET, reusePort, 1)\u0026quot;] d--\u0026gt;f[\u0026quot;syscall.Bind(fd, sockaddr)\u0026quot;] f--\u0026gt;g[\u0026quot;syscall.Listen(fd, listenerBacklogMaxSize)\u0026quot;] g--\u0026gt;s[\u0026quot;file = os.NewFile(uintptr(fd), getSocketFileName(proto, addr))\u0026quot;] s--\u0026gt;ss[\u0026quot;listener, err = net.FileListener(file)\u0026quot;] ss--\u0026gt;sss[\u0026quot;net.Listener\u0026quot;] 这里\ngetSocketFileName()\n只是单纯的返回了fmt.Sprintf(\u0026quot;reuseport.%d.%s.%s\u0026quot;, os.Getpid(), proto, addr) os.NewFile(fd uintptr, name string)*os.File\nreturns a new File with the given file descriptor and name.` net.FileListener(* os.File)\nFileListener returns a copy of the network listener corresponding to the open file f listenerBacklogMaxSize\nfd, err := os.Open(\u0026quot;/proc/sys/net/core/somaxconn\u0026quot;) 默认最大128 非阻塞io 文件描述符应该被设置成非阻塞,如果你通过epoll等进行io复用,可以通过fcntl设置\nfcntl(fd, F_SETFL, O_NONBLOCK);\n高级封装 import \u0026ldquo;golang.org/x/sys/unix\u0026rdquo;\n直接使用syscall可能比较复杂繁琐,golang.org实现了一个类似c语言的封装,api和c语言的接口基本一致\nunix.Socket(domain int, typ int, proto int) unix.SetsockoptInt(fd int, level int, opt int, value int) unix.Bind(fd int, sa unix.Sockaddr) unix.Listen(s int, n int) unix.Accept(fd int) 我们之前说过将fd转换到net.Listener的方法,这里也同样适用\n减少内核态切换拷贝开销 如果是UDP类型通信,每调用一次recvmsg,都会触发内核态缓冲区到用户态缓冲区的数据拷贝,并且只会拷贝一个数据包,为了减少次数,我们期望一次接受多个UDP包,linux提供了recvmmsg,即recv multiple msg, 一次性接受多个包.\ngo中可以自己封装syscall(这里的6,指的是后面的参数个数)\nfunc (rw *ReaderWriter) read() (int, error) { n, _, err := unix.Syscall6(unix.SYS_RECVMMSG, uintptr(rw.fd),uintptr(unsafe.Pointer(\u0026amp;rw.msgs[0])), uintptr(len(rw.msgs)), unix.MSG_WAITFORONE, 0, 0) return int(n),err } ","id":81,"section":"posts","summary":"\u003ch1 id=\"高性能linux服务器\"\u003e高性能linux服务器\u003c/h1\u003e\n\u003ch2 id=\"服务器监听范式\"\u003e服务器监听范式\u003c/h2\u003e\n\u003cp\u003e一个传统的单线程服务器\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-mermaid\"\u003egraph LR;\nA[\u0026quot;socket()\u0026quot;]--\u0026gt;B(sockfd);\nB--\u0026gt;|\u0026quot;setsockopt()\u0026quot;| C[bind]\nC--\u0026gt;D[listen]\nD--\u0026gt;E[accept]\nE--\u0026gt;|connfd|F[\u0026quot;dowork(){read/write connfd}\u0026quot;]\nF--\u0026gt;|\u0026quot;while (1)\u0026quot;| E\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e一个传统的多线程服务器, pthread也可以换成fork,多进程\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-mermaid\"\u003egraph LR;\nA[\u0026quot;socket()\u0026quot;]--\u0026gt;B(sockfd);\nB--\u0026gt;|\u0026quot;setsockopt()\u0026quot;| C[bind]\nC--\u0026gt;D[listen]\nD--\u0026gt;E[accept]\nE--\u0026gt;|connfd|F[pthread_create]\nF--\u0026gt;|pthread|G[threadRoutine]--\u0026gt;O[\u0026quot;dowork(){read/write connfd}\u0026quot;]\nF--\u0026gt;|pthread|H[threadRoutine]--\u0026gt;Oo[\u0026quot;dowork(){read/write connfd}\u0026quot;]\nF--\u0026gt;|pthread|I[threadRoutine]--\u0026gt;Ooo[\u0026quot;dowork(){read/write connfd}\u0026quot;]\nF--\u0026gt;|\u0026quot;while (1)\u0026quot;| E\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e一个传统的多线程服务器,多线程同时accpet同一个sockfd\u003c/p\u003e","tags":["server"],"title":"[linux] high performance server","uri":"https://wymli.github.io/2021/03/linux-high-performance-server/","year":"2021"},{"content":"Introduction to linux server linux 服务器导论\n文件目录相关 假设我们的服务器名为testServerd,这里末尾以d结尾,代表daemon守护模式\n如果是.d结尾,则代表是文件目录\n日志目录 /var/log/testServerd/\n/var目录承载可变的数据文件,即可写,与之对比的是/usr,只可读\nPID记录 进程在创建时应该记录自己的pid,可以放置在\n/var/run/testServerd.pid\n配置文件 程序的配置文件可以放置在\n/etc/testServerd/testServerd.conf\netc是专用于放置配置文件的目录\n用户信息 大部分服务器必须以root的身份启动,但不能以root的身份运行\nUID,EUID,GID,EGID userid , effective userid, groupid,effective groupid\nUID是进程的真实用户id\nEUID是进程的有效用户id,是为了方便资源访问的,它使得运行程序的用户可以拥有该程序的有效用户的权限\n如何设置有效用户? 一个可执行文件有一个set-user-id标志位,这个标志位表示普通用户运行程序时,有效用户就是该程序的所有者,使用chown改变程序所有者\nSwitch User 调用setgid()和setuid()来切换由root身份启动的程序到普通用户身份\n","id":82,"section":"posts","summary":"\u003ch1 id=\"introduction-to-linux-server\"\u003eIntroduction to linux server\u003c/h1\u003e\n\u003cp\u003elinux 服务器导论\u003c/p\u003e\n\u003ch2 id=\"文件目录相关\"\u003e文件目录相关\u003c/h2\u003e\n\u003cp\u003e假设我们的服务器名为testServerd,这里末尾以d结尾,代表daemon守护模式\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e如果是.d结尾,则代表是文件目录\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch3 id=\"日志目录\"\u003e日志目录\u003c/h3\u003e\n\u003cp\u003e/var/log/testServerd/\u003c/p\u003e","tags":["server"],"title":"[linux] server intro","uri":"https://wymli.github.io/2021/03/linux-server-intro/","year":"2021"},{"content":"12.1 重新学习了gin的一部分用法,比如参数获取,文件上传,静态文件目录之类的,我感觉任何东西还是要先学会用,再去看源码学习 看了一篇微服务的概述,看起来微服务的兴起就像操作系统的历史一样,由宏内核到微内核,将函数作为服务提供调用,微服务则是将不同的功能组件独立成独立的网络服务,分布在不同的主机;为了降低延迟,使用rpc而不是http,使用protobuf(?存疑)而不是json/xml,因为解析速度不够;带宽方面,随着计算机性能的提升,一般没问题,记得chenshuo在muduo教程里面测过通过本机tcp端口做ipc,带宽也非常可观.目的还是降低单次调用的延时 看了下go语言的sync.map源码,实现上类似于双缓冲区,涉及到写缓冲区的操作一律加锁,默认一个读一个写,加快速度,读不到了再从写的那个缓冲区读;miss次数一定后,就更新缓冲区(用写缓冲区直接覆盖读缓冲区,写缓冲区置为0,后续第一次写入写缓冲区时,会先将读缓冲区的数据拷贝过来,为什么这样设计,可能只是语言机制语法上的妥协吧); 关于写,如果在读缓冲区读到了(注意读到了还要考虑是不是被删除了),就用cas写(换指针),否则上锁,去写缓冲区; 关于读,读缓冲区没读到,并且两个缓冲区数据不一致(定义两个缓冲区数据一致指的是写缓冲区为0,即刚将写缓冲区覆盖读缓冲区),就上锁,去写缓冲区读; 删除: 将指向value的指针置为nil,但本身还存在map中,延迟删除 还有一个特点是,获取锁后,不要立即访问写缓冲区,而是再访问一次读缓冲区,因为你不知道有没有其他线程触发更新,使得写缓存区清空了 把win10升级到了专业版,可以用remote desktop了 12.2 remote desktop 的延迟还是挺高的,仅仅能用 继续说sync.map,其中还是有很多东西可以说到说到的 乐观锁与悲观锁 数据库中的概念 cas(compare\u0026amp;swap),或者是test\u0026amp;set,这些原子指令认为是无锁的,lock-free 但这并不意味着它们代价低,事实上cas作为一个写指令,一定会在总线上发出BusX(后续会写的读信号)信号,以失效多核cpu的其他核的cache,保证cache一致性,然后才读到数据,compare失败或成功 因此一个典型的优化是read and cas,先读,因为处理器读导致BusRead不会使cache失效,这其实就是要减少cas的强制占用总线,后续也可能会有多个核cas,但没关系,最多是核数而不是线程数 乐观锁,倾向于数据少写 先不加锁访问(读),直到更新的时候再用cas更新,可以通过比较version字段(或要修改的值的最新状态与之前的快照)来比较,然后update 如果是全局的version字段,就不会有ABA问题 如果失败,就回滚,重新search 所以其实乐观锁不算是一种锁 悲观锁,倾向于数据多写 强制加锁,访问 复制的效率 可以看到读缓冲区miss后将要访问写缓冲区时,写缓冲区要先copy读缓冲区,再写新的key\u0026amp;value 这是说明了复制的效率一定高于加锁PV的效率? 12.13 一下子就10天没写了,自己还是太懒了,但是这十天还是接触了很多东西的 authentication and authorization, 认证与鉴权 在go里面,认证可以用jwt,鉴权可以用casbin,一般鉴权是rbac,role-based-access-control,基于角色的访问控制,鉴权就是访问控制 这其实就类似于Kerberos,有认证服务器和票据服务器,二者分开 go语言并发,daisy chain之类的东西,输入channel,开goroutine对数据filter,输出channel reactor,proactor,两种事件处理模式,event-driven reactor是主线程只负责监听事件发生(epoll_wait),然后分发任务给任务线程,读写数据都在工作线程中完成,accept()也在worker中完成 proactor是异步io的,将io操作交给主线程/内核完成,我们知道异步本质就是注册一个回调函数,当io结束后执行回调函数 不够,感觉没太大用,因为目前还接触不到应用的场景 reactiveX,流式处理数据,一种异步io风格 但是和回调又有点不同,它是源源不断接收流式的数据,然后对数据像流水线一样处理. 当然本质也就是注册回调函数,但可以避免过多callback时候的混乱代码,主要是语法上更简介吧 看了beego的session模块的代码,感觉写的确实收益颇多 因为可以有不同的存储场景,所以用interface在中间层抽象,应用层(应用者,user)和底层(提供者,provider)都面向interface编程,底层存储提供者可以是memory,file,redis,db等等,这需要编写对应的驱动(虽然我不知道这叫不叫驱动,但是确实在功能上给我一种驱动的感觉,一般会称之为adapter吧,适配器) 它的并发链表的实现也不错,一方面用链表存储数据,另一方面为了解决链表线性访问慢的问题,用map存储链表的node,快速查找sessionId对应的node 为什么要用container/list呢,而不直接用sync.map存储session,这是因为,我们还要计算其超时时间! 我们不可能遍历所有的node去计算其超时,所以必须要按时间排序 在这里,list就充当了这个角色,新创建的session被放到list的前面,快超时的session自然在最后面,在gc的时候只需要不断测试最后一个node就好了 另外这种定时事件,好像都是用小顶堆做的,这里用链表其实也不错 container/list提供了极其方便的api,比如:PushFront,MoveToFront,Remove 何时GC,处理超时session: 在sessionInit时,就goroutine一个线程定时gc,可以用递归的形式,比较优雅.当然放在一个for{}无穷循环里面也可 func(m *manager)gc(){m.provider.gc(); time.AfterFunc(time.Duration , m.gc)} 在哪里告诉程序,这个provider实现了? 直接在init()中register,维护一个全局的map即可,实现了就在这个文件的init函数中往map里面写就可以了,极其容易拓展,低耦合 注意session只需要管理一个sessionId和对应的value就行了,value可以是任何值的集合,可以设成map[string]interface{},虽然其实go也支持map[interface{}]interface{} session不需要管理对应的url路径什么的,那是cookie的事,我们在response的时候要set-cookie,对应的cookie值在那里设置,value设置成对应的sessionId即可 MVC架构 model-view-controller model就是一个个定义的结构体/类对象,其实主要还是用来访问数据库的,其他的名字:DAO,data-access-object,数据访问对象,也就是orm,object-relation-model view,就是前端视图了,可能是一些模板之类的 controller就是后端处理逻辑,hanler,middlerware,log,session,router之类的 综合看下来,beego不完全是一个web框架,它还集成了client,定时任务task之类的模块,我感觉非常值得学习,而且谢大的书go web编程也是开源的,顶礼膜拜好吧 VUE 在看奇淼在b站录的vue视频,感觉这个人教学方面是很不错的,视频看下来不会让我感觉无聊,讲的也比较有激情,知识点归纳的也不错 在我入门gin的情况下去听了下他的gin入门课,感觉还是很不错的,也有收获 之前接触的那些开源项目的目录结构都很迷,初学者完全看不懂为什么这么摆,他的gin-vue-admin的项目目录结构就比较清爽,一目了然 vue-router 前端页面路由,用来构建单页面应用 表现上就是一个页面内的标签页/导航 典型的,前端路由可以用在登陆界面上,就不用登陆界面单独写一个后端路由/html了 12.14 这一周打算: 学会vue/element ui的布局layout,一个典型的后台管理系统就是单页面的,在固定的框类切换不同的内容,所以建立好总体的布局尤为重要 了解http2,简单看了下,感觉都在说什么连接复用,头部压缩之类的,但是http1.0/1.1不是也已经支持keep-alive了吗?这两个长连接的区别? 了解redis?redis就是一个键值对的数据库,经常用作缓存 看到了vue-element-admin,是个不错的项目,而且有教程,基本和奇淼的gin-vue-admin是一个东西,不过这也是因为后台管理系统确实就是那一套.但是对我来说,依然还是有很多学习的地方的 todo 组件上的v-model 子组件的this.emit(\u0026lsquo;input\u0026rsquo;,) 根组件 就是new Vue() 组件一定要被包含? 直接获取组件对象: 根组件: $root 父组件:$parent 只读 子组件:$children 只读,无序 若想改变子组件的内容,只能直接改变子组件所引用的数组的内容,子组件由v-for生成 插槽 用来指示外部传给组件的innerHTML的显示位置 比如\u0026ldquo;this is innerHTML\u0026rdquo; vue的入口文件: 入口可以是 main.js、index.js、App.vue 或 app.vue 中的一个 哪个定义了new Vue()实例,哪个就是入口 vue实例内置数据/方法,前加$,比如var vm = new Vue({el:\u0026quot;\u0026quot;,data:{}}),vm.$el,vm.$mount() 只有在初始创建时在data字典里面的数据才是响应式的,后面添加的都必须手动触发更新 关于layout 一般来说,后台管理系统是单页面的,简洁好用,没必要设计成跳来跳去的跳转 一般的,用侧边栏来导航,el-main块用来显示内容,如何实现点击不同的按钮,main块切换到不同的页面内容呢? 这个其实element-ui直接实现了,叫标签页 但是如果想更灵活一点,可以自己设计,是通过vue-route实现的 main块放即可 标签页是容易实现的,可以用它来练习组件,设计插槽,父子组件通信这些 本质就是一个tab组件,子组件是tab-pane代表各个标签,tab只是控制tab-pane的显示而已,而显示可以用v-if,很简单 一个标准的vue前端代码结构是: ./component , ./App.vue , ./main.js 在main.js中引入全局组件,App.vue是入口文件 组件通信: 父传子:props down ; 子传父:events up : this.$emit() 关于vue的组件,强推这个课程:https://www.bilibili.com/video/BV1nx411X7oA 12.16 前后端分离,不仅仅是独立开发,也是独立部署,这意味着后端仅仅是提供api的路由!而由前端自己提供页面的路由,这就是意味着前端有自己的路由 12.18 前后端分离,前端一般是单页面的,通过内置前端路由实现多页面,但只有一个vue实例,请求后端api服务器可能需要设置跨域 SPA,单页面应用的路由有两种模式:hash和history,这两种方法都可以改变uri而不触发浏览器的刷新(向服务器请求) 如果是history模式,又没有前后端分开部署(即服务端渲染),指浏览器直接向后端服务器请求html,这时候手动刷新页面就会触发对后端的请求,但因为是前端路由,在后端中不存在,所以需要后端特别配置,后端当收到不存在的路由时,直接返回index.html,index.html将自动根据浏览器栏的path跳转到特定的前端路由,此时要注意设置前端路由的404,用\u0026rsquo;*\u0026lsquo;匹配即可 了解了vue的路由,以及子路由 todo: import , export default,export const这些是什么 未来目标: 重构一下sysu_jwxt_v2,前后端分离,后端仅作为api服务器 ","id":83,"section":"posts","summary":"\u003ch1 id=\"121\"\u003e12.1\u003c/h1\u003e\n\u003col\u003e\n\u003cli\u003e重新学习了gin的一部分用法,比如参数获取,文件上传,静态文件目录之类的,我感觉任何东西还是要先学会用,再去看源码学习\u003c/li\u003e\n\u003cli\u003e看了一篇微服务的概述,看起来微服务的兴起就像操作系统的历史一样,由宏内核到微内核,将函数作为服务提供调用,微服务则是将不同的功能组件独立成独立的网络服务,分布在不同的主机;为了降低延迟,使用rpc而不是http,使用protobuf(?存疑)而不是json/xml,因为解析速度不够;带宽方面,随着计算机性能的提升,一般没问题,记得chenshuo在muduo教程里面测过通过本机tcp端口做ipc,带宽也非常可观.目的还是降低单次调用的延时\u003c/li\u003e\n\u003cli\u003e看了下go语言的sync.map源码,实现上类似于双缓冲区,涉及到写缓冲区的操作一律加锁,默认一个读一个写,加快速度,读不到了再从写的那个缓冲区读;miss次数一定后,就更新缓冲区(用写缓冲区直接覆盖读缓冲区,写缓冲区置为0,后续第一次写入写缓冲区时,会先将读缓冲区的数据拷贝过来,为什么这样设计,可能只是语言机制语法上的妥协吧);\n\u003col\u003e\n\u003cli\u003e关于写,如果在读缓冲区读到了(注意读到了还要考虑是不是被删除了),就用cas写(换指针),否则上锁,去写缓冲区;\u003c/li\u003e\n\u003cli\u003e关于读,读缓冲区没读到,并且两个缓冲区数据不一致(定义两个缓冲区数据一致指的是写缓冲区为0,即刚将写缓冲区覆盖读缓冲区),就上锁,去写缓冲区读;\u003c/li\u003e\n\u003cli\u003e删除: 将指向value的指针置为nil,但本身还存在map中,延迟删除\u003c/li\u003e\n\u003cli\u003e还有一个特点是,获取锁后,不要立即访问写缓冲区,而是再访问一次读缓冲区,因为你不知道有没有其他线程触发更新,使得写缓存区清空了\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e把win10升级到了专业版,可以用remote desktop了\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch1 id=\"122\"\u003e12.2\u003c/h1\u003e\n\u003col\u003e\n\u003cli\u003eremote desktop 的延迟还是挺高的,仅仅能用\u003c/li\u003e\n\u003cli\u003e继续说sync.map,其中还是有很多东西可以说到说到的\n\u003col\u003e\n\u003cli\u003e乐观锁与悲观锁\n\u003col\u003e\n\u003cli\u003e数据库中的概念\u003c/li\u003e\n\u003cli\u003ecas(compare\u0026amp;swap),或者是test\u0026amp;set,这些原子指令认为是无锁的,lock-free\n\u003col\u003e\n\u003cli\u003e但这并不意味着它们代价低,事实上cas作为一个写指令,一定会在总线上发出BusX(后续会写的读信号)信号,以失效多核cpu的其他核的cache,保证cache一致性,然后才读到数据,compare失败或成功\u003c/li\u003e\n\u003cli\u003e因此一个典型的优化是read and cas,先读,因为处理器读导致BusRead不会使cache失效,这其实就是要减少cas的强制占用总线,后续也可能会有多个核cas,但没关系,最多是核数而不是线程数\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e乐观锁,倾向于数据少写\n\u003col\u003e\n\u003cli\u003e先不加锁访问(读),直到更新的时候再用cas更新,可以通过比较version字段(或要修改的值的最新状态与之前的快照)来比较,然后update\n\u003col\u003e\n\u003cli\u003e如果是全局的version字段,就不会有ABA问题\u003c/li\u003e\n\u003cli\u003e如果失败,就回滚,重新search\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e所以其实乐观锁不算是一种锁\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e悲观锁,倾向于数据多写\n\u003col\u003e\n\u003cli\u003e强制加锁,访问\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e复制的效率\n\u003col\u003e\n\u003cli\u003e可以看到读缓冲区miss后将要访问写缓冲区时,写缓冲区要先copy读缓冲区,再写新的key\u0026amp;value\u003c/li\u003e\n\u003cli\u003e这是说明了复制的效率一定高于加锁PV的效率?\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch1 id=\"1213\"\u003e12.13\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e一下子就10天没写了,自己还是太懒了,但是这十天还是接触了很多东西的\u003c/li\u003e\n\u003cli\u003eauthentication and authorization, 认证与鉴权\n\u003cul\u003e\n\u003cli\u003e在go里面,认证可以用jwt,鉴权可以用casbin,一般鉴权是rbac,role-based-access-control,基于角色的访问控制,鉴权就是访问控制\u003c/li\u003e\n\u003cli\u003e这其实就类似于Kerberos,有认证服务器和票据服务器,二者分开\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ego语言并发,daisy chain之类的东西,输入channel,开goroutine对数据filter,输出channel\u003c/li\u003e\n\u003cli\u003ereactor,proactor,两种事件处理模式,event-driven\n\u003cul\u003e\n\u003cli\u003ereactor是主线程只负责监听事件发生(epoll_wait),然后分发任务给任务线程,读写数据都在工作线程中完成,accept()也在worker中完成\u003c/li\u003e\n\u003cli\u003eproactor是异步io的,将io操作交给主线程/内核完成,我们知道异步本质就是注册一个回调函数,当io结束后执行回调函数\u003c/li\u003e\n\u003cli\u003e不够,感觉没太大用,因为目前还接触不到应用的场景\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ereactiveX,流式处理数据,一种异步io风格\n\u003cul\u003e\n\u003cli\u003e但是和回调又有点不同,它是源源不断接收流式的数据,然后对数据像流水线一样处理. 当然本质也就是注册回调函数,但可以避免过多callback时候的混乱代码,主要是语法上更简介吧\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e看了beego的session模块的代码,感觉写的确实收益颇多\n\u003cul\u003e\n\u003cli\u003e因为可以有不同的存储场景,所以用interface在中间层抽象,应用层(应用者,user)和底层(提供者,provider)都面向interface编程,底层存储提供者可以是memory,file,redis,db等等,这需要编写对应的驱动(虽然我不知道这叫不叫驱动,但是确实在功能上给我一种驱动的感觉,一般会称之为adapter吧,适配器)\u003c/li\u003e\n\u003cli\u003e它的并发链表的实现也不错,一方面用链表存储数据,另一方面为了解决链表线性访问慢的问题,用map存储链表的node,快速查找sessionId对应的node\n\u003cul\u003e\n\u003cli\u003e为什么要用container/list呢,而不直接用sync.map存储session,这是因为,我们还要计算其超时时间!\u003c/li\u003e\n\u003cli\u003e我们不可能遍历所有的node去计算其超时,所以必须要按时间排序\u003c/li\u003e\n\u003cli\u003e在这里,list就充当了这个角色,新创建的session被放到list的前面,快超时的session自然在最后面,在gc的时候只需要不断测试最后一个node就好了\n\u003cul\u003e\n\u003cli\u003e另外这种定时事件,好像都是用小顶堆做的,这里用链表其实也不错\u003c/li\u003e\n\u003cli\u003econtainer/list提供了极其方便的api,比如:PushFront,MoveToFront,Remove\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e何时GC,处理超时session:\n\u003cul\u003e\n\u003cli\u003e在sessionInit时,就goroutine一个线程定时gc,可以用递归的形式,比较优雅.当然放在一个for{}无穷循环里面也可\u003c/li\u003e\n\u003cli\u003efunc(m *manager)gc(){m.provider.gc(); time.AfterFunc(time.Duration , m.gc)}\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e在哪里告诉程序,这个provider实现了?\n\u003cul\u003e\n\u003cli\u003e直接在init()中register,维护一个全局的map即可,实现了就在这个文件的init函数中往map里面写就可以了,极其容易拓展,低耦合\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e注意session只需要管理一个sessionId和对应的value就行了,value可以是任何值的集合,可以设成map[string]interface{},虽然其实go也支持map[interface{}]interface{}\n\u003cul\u003e\n\u003cli\u003esession不需要管理对应的url路径什么的,那是cookie的事,我们在response的时候要set-cookie,对应的cookie值在那里设置,value设置成对应的sessionId即可\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eMVC架构\n\u003cul\u003e\n\u003cli\u003emodel-view-controller\n\u003cul\u003e\n\u003cli\u003emodel就是一个个定义的结构体/类对象,其实主要还是用来访问数据库的,其他的名字:DAO,data-access-object,数据访问对象,也就是orm,object-relation-model\u003c/li\u003e\n\u003cli\u003eview,就是前端视图了,可能是一些模板之类的\u003c/li\u003e\n\u003cli\u003econtroller就是后端处理逻辑,hanler,middlerware,log,session,router之类的\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e综合看下来,beego不完全是一个web框架,它还集成了client,定时任务task之类的模块,我感觉非常值得学习,而且谢大的书go web编程也是开源的,顶礼膜拜好吧\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eVUE\n\u003cul\u003e\n\u003cli\u003e在看奇淼在b站录的vue视频,感觉这个人教学方面是很不错的,视频看下来不会让我感觉无聊,讲的也比较有激情,知识点归纳的也不错\u003c/li\u003e\n\u003cli\u003e在我入门gin的情况下去听了下他的gin入门课,感觉还是很不错的,也有收获\u003c/li\u003e\n\u003cli\u003e之前接触的那些开源项目的目录结构都很迷,初学者完全看不懂为什么这么摆,他的gin-vue-admin的项目目录结构就比较清爽,一目了然\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003evue-router\n\u003cul\u003e\n\u003cli\u003e前端页面路由,用来构建单页面应用\u003c/li\u003e\n\u003cli\u003e表现上就是一个页面内的标签页/导航\u003c/li\u003e\n\u003cli\u003e典型的,前端路由可以用在登陆界面上,就不用登陆界面单独写一个后端路由/html了\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"1214\"\u003e12.14\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e这一周打算:\n\u003cul\u003e\n\u003cli\u003e学会vue/element ui的布局layout,一个典型的后台管理系统就是单页面的,在固定的框类切换不同的内容,所以建立好总体的布局尤为重要\u003c/li\u003e\n\u003cli\u003e了解http2,简单看了下,感觉都在说什么连接复用,头部压缩之类的,但是http1.0/1.1不是也已经支持keep-alive了吗?这两个长连接的区别?\u003c/li\u003e\n\u003cli\u003e了解redis?redis就是一个键值对的数据库,经常用作缓存\u003c/li\u003e\n\u003cli\u003e看到了vue-element-admin,是个不错的项目,而且有教程,基本和奇淼的gin-vue-admin是一个东西,不过这也是因为后台管理系统确实就是那一套.但是对我来说,依然还是有很多学习的地方的\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003etodo\n\u003cul\u003e\n\u003cli\u003e组件上的v-model\u003c/li\u003e\n\u003cli\u003e子组件的this.emit(\u0026lsquo;input\u0026rsquo;,)\u003c/li\u003e\n\u003cli\u003e根组件\n\u003cul\u003e\n\u003cli\u003e就是new Vue()\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e组件一定要被\u003ctemplate\u003e包含?\u003c/li\u003e\n\u003cli\u003e直接获取组件对象:\n\u003cul\u003e\n\u003cli\u003e根组件: $root\u003c/li\u003e\n\u003cli\u003e父组件:$parent 只读\u003c/li\u003e\n\u003cli\u003e子组件:$children 只读,无序\n\u003cul\u003e\n\u003cli\u003e若想改变子组件的内容,只能直接改变子组件所引用的数组的内容,子组件由v-for生成\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cslot\u003e插槽\n\u003cul\u003e\n\u003cli\u003e用来指示外部传给组件的innerHTML的显示位置\u003c/li\u003e\n\u003cli\u003e比如\u003cmy-button\u003e\u0026ldquo;this is innerHTML\u0026rdquo;\u003c/my-button\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003evue的入口文件:\n\u003cul\u003e\n\u003cli\u003e入口可以是 main.js、index.js、App.vue 或 app.vue 中的一个\u003c/li\u003e\n\u003cli\u003e哪个定义了new Vue()实例,哪个就是入口\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003evue实例内置数据/方法,前加$,比如var vm = new Vue({el:\u0026quot;\u0026quot;,data:{}}),vm.$el,vm.$mount()\n\u003cul\u003e\n\u003cli\u003e只有在初始创建时在data字典里面的数据才是响应式的,后面添加的都必须手动触发更新\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e关于layout\n\u003cul\u003e\n\u003cli\u003e一般来说,后台管理系统是单页面的,简洁好用,没必要设计成跳来跳去的跳转\u003c/li\u003e\n\u003cli\u003e一般的,用侧边栏来导航,el-main块用来显示内容,如何实现点击不同的按钮,main块切换到不同的页面内容呢?\n\u003cul\u003e\n\u003cli\u003e这个其实element-ui直接实现了,叫标签页\u003c/li\u003e\n\u003cli\u003e但是如果想更灵活一点,可以自己设计,是通过vue-route实现的\u003c/li\u003e\n\u003cli\u003emain块放\u003crouter-view\u003e即可\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e标签页是容易实现的,可以用它来练习组件,设计插槽,父子组件通信这些\n\u003cul\u003e\n\u003cli\u003e本质就是一个tab组件,子组件是tab-pane代表各个标签,tab只是控制tab-pane的显示而已,而显示可以用v-if,很简单\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e一个标准的vue前端代码结构是: ./component , ./App.vue , ./main.js\n\u003cul\u003e\n\u003cli\u003e在main.js中引入全局组件,App.vue是入口文件\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e组件通信: 父传子:props down ; 子传父:events up : this.$emit()\u003c/li\u003e\n\u003cli\u003e关于vue的组件,强推这个课程:https://www.bilibili.com/video/BV1nx411X7oA\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"1216\"\u003e12.16\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e前后端分离,不仅仅是独立开发,也是独立部署,这意味着后端仅仅是提供api的路由!而由前端自己提供页面的路由,这就是意味着前端有自己的路由\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"1218\"\u003e12.18\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e前后端分离,前端一般是单页面的,通过内置前端路由实现多页面,但只有一个vue实例,请求后端api服务器可能需要设置跨域\nSPA,单页面应用的路由有两种模式:hash和history,这两种方法都可以改变uri而不触发浏览器的刷新(向服务器请求)\n\u003cul\u003e\n\u003cli\u003e如果是history模式,又没有前后端分开部署(即服务端渲染),指浏览器直接向后端服务器请求html,这时候手动刷新页面就会触发对后端的请求,但因为是前端路由,在后端中不存在,所以需要后端特别配置,后端当收到不存在的路由时,直接返回index.html,index.html将自动根据浏览器栏的path跳转到特定的前端路由,此时要注意设置前端路由的404,用\u0026rsquo;*\u0026lsquo;匹配即可\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e了解了vue的路由,以及子路由\u003c/li\u003e\n\u003cli\u003etodo:\n\u003cul\u003e\n\u003cli\u003eimport , export default,export const这些是什么\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e未来目标: 重构一下sysu_jwxt_v2,前后端分离,后端仅作为api服务器\u003c/li\u003e\n\u003c/ul\u003e","tags":["Other"],"title":"[other] everyDay","uri":"https://wymli.github.io/2021/03/other-everyday/","year":"2021"},{"content":"What\u0026rsquo;s the diff? x86,x64,386,amd64,i386,intel64 \u0026hellip;. x86,x86-32,386,80386,i386,IA32 都是指的intel的32位cpu架构\nx86-64,x64,amd64,intel64 都是指的intel的64位cpu架构,基于x86\nIA64,一种新的64位架构,不基于x86\nLinux , Ubuntu , CentOS , RedHat \u0026hellip;. linux是内核kernel的名字\nUbuntu,CentOS都是发行版,是操作系统\nRedHat是一家企业,它有旗下的企业版linux发行版:RHEL(Red Hat Enterprise Linux)\nCentOS(Community ENTerprise Operating System)就是RHEL的社区版\nDarwin , Mac OS, macintosh ,BSD \u0026hellip; darwin是内核, Mac OS是os\nunix-\u0026gt;free BSD-\u0026gt;Darwin-\u0026gt;MacOS\nmacintosh是个人电脑的名字,就产品名\n两大类的类Unix内核,linux和BSD 经典的 ps -aux 和 ps -elf\n","id":84,"section":"posts","summary":"\u003ch1 id=\"whats-the-diff\"\u003eWhat\u0026rsquo;s the diff?\u003c/h1\u003e\n\u003ch2 id=\"x86x64386amd64i386intel64-\"\u003ex86,x64,386,amd64,i386,intel64 \u0026hellip;.\u003c/h2\u003e\n\u003cp\u003ex86,x86-32,386,80386,i386,IA32 都是指的intel的32位cpu架构\u003c/p\u003e\n\u003cp\u003ex86-64,x64,amd64,intel64 都是指的intel的64位cpu架构,基于x86\u003c/p\u003e\n\u003cp\u003eIA64,一种新的64位架构,不基于x86\u003c/p\u003e\n\u003ch2 id=\"linux--ubuntu--centos--redhat--\"\u003eLinux , Ubuntu , CentOS , RedHat  \u0026hellip;.\u003c/h2\u003e\n\u003cp\u003elinux是内核kernel的名字\u003c/p\u003e","tags":["Other"],"title":"[other] term","uri":"https://wymli.github.io/2021/03/other-term/","year":"2021"},{"content":"OAuth2.0 open authority 2.0,开放授权\n主要用于A网站向某个常用第三方社交网站请求用户信息,第三方社交网站需要给予A网站用户信息,这必须有用户的授权才行,但是如果直接给予A网站用户的用户名密码,又太不安全,并且我们希望只提供给A网站受限的资源访问权限,比如只能获取到用户名等.因此需要使用OAuth2.0\nref:\nhttps://aaronparecki.com/oauth-2-simplified/#web-server-apps\nhttps://blog.bearer.sh/understanding-auth-part-1-what-is-oauth/\n多种授权模式 客户端必须得到用户的授权（authorization grant），才能获得令牌（access token）。OAuth 2.0定义了四种授权方式。\n这里用户的授权,是在从第三方网站跳转到社交网站进行授权,用户需在社交网站登陆,并点击授权\nauthorization code implicit resource owner password credentials The authorization code grant type is the most common variant of OAuth 2.0\nUser-Agent Flow流程 以qq的OAuth2为例,qq采用了隐式(implicit)授权(client-side模式，是OAuth2.0认证的一种模式，又称User-Agent Flow)\n即不涉及后端,全在浏览器操作\nA网站向第三方注册 对于要使用第三方登陆功能的web service(此时,社交网站是第三方),必须先向第三方社交网站注册自己,获得唯一的Client ID and Secret,以qq第三方登陆为例,将会获得唯一的appid and apikey\n对于secret/apikey必须机密保存在后端,如果是前端单页面服务,没有后端,则不应该向它们发送密钥,使用PKCE拓展\n似乎 Client ID and Client Secret 被称为client credentials\n用户在A网站点击第三方登陆 前端跳转到如下URL\nhttps://graph.qq.com/oauth2.0/authorize?response_type=code\u0026amp;client_id=CLIENT_ID\u0026amp;redirect_uri=REDIRECT_URI\u0026amp;scope=photos\u0026amp;state=1234zyx 参数 isNeed 含义 response_type 必须 授权类型，此值固定为“token”。 client_id 必须 申请QQ登录成功后，分配给应用的appid。 redirect_uri 必须 成功授权后的回调地址。 scope 可选 请求用户授权时向用户显示的可进行授权的列表。 可填写的值是API列表中列出的接口，以及一些动作型的授权（目前仅有：do_like），如果要填写多个接口名称，请用逗号隔开。 例如：scope=get_user_info,list_album,upload_pic,do_like 不传则默认请求对接口get_user_info进行授权。 建议控制授权项的数量，只传入必要的接口名称，因为授权项越多，用户越可能拒绝进行任何授权。 state 可选 client端的状态值。用于第三方应用防止CSRF攻击，成功授权后回调时会原样带回 如果用户成功登录并授权，则会跳转到指定的回调地址，并在URL后加“#”号，带上Access Token以及expires_in等参数。如果请求参数中传入了state，这里会带上原始的state值。如果redirect_uri地址后已经有“#”号，则加“\u0026amp;”号，带上相应的返回参数。如： http://graph.qq.com/demo/index.jsp?#access_token=FE04************************CCE2\u0026amp;expires_in=7776000\u0026amp;state=test\nexpires_in是该access token的有效期，单位为秒。\nTips：\n可通过js方法：window.location.hash来获取URL中#后的参数值。 建议用js设置cookie存储token。 获取openID openid是qq用户的唯一标识\n拿到access_token后,get如下的url:\nhttps://graph.qq.com/oauth2.0/me?access_token=YOUR_ACCESS_TOKEN 返回\ncallback( {\u0026quot;client_id\u0026quot;:\u0026quot;YOUR_APPID\u0026quot;,\u0026quot;openid\u0026quot;:\u0026quot;YOUR_OPENID\u0026quot;} ); 获取用户信息 获得用户标识openid后,get如下url:\nhttps://graph.qq.com/user/get_simple_userinfo?access_token=1234ABD1234ABD\u0026amp;oauth_consumer_key=12345\u0026amp; openid=B08D412EEC4000FFC37CAABBDC1234CC\u0026amp;format=json 参数 含义 access_token 可通过使用Implicit Grant方式获取Access Token来获取。 access_token有3个月有效期。 oauth_consumer_key 申请QQ登录成功后，分配给应用的appid(即client_id) openid 用户的ID，与QQ号码一一对应。 可通过调用https://graph.qq.com/oauth2.0/me?access_token=YOUR_ACCESS_TOKEN 来获取。 注意,不是直接返回用户信息,而是让网站自己去请求\n注意 Implicit was previously recommended for clients without a secret, but has been superseded by using the Authorization Code grant with PKCE.\n授权码流程 参考上述的User-Agent Flow,在第一次访问授权服务的时候,不直接返回access_token,而是返回一个授权码\n接着,我们拿这个授权码去得到access_token\nPOST https://api.authorization-server.com/token? grant_type=authorization_code\u0026amp; code=AUTH_CODE_HERE\u0026amp; redirect_uri=REDIRECT_URI\u0026amp; client_id=CLIENT_ID\u0026amp; client_secret=CLIENT_SECRET 因为是server发起的,所以可以带上secret\n响应:\n{ \u0026quot;access_token\u0026quot;:\u0026quot;RsT5OjbzRn430zqMLgV3Ia\u0026quot;, \u0026quot;expires_in\u0026quot;:3600 } 为什么不直接返回access_token? 因为不安全,我们希望access_token只在后端持有,所以多了一步用code换access_token的步骤\nLegs implicit和authority code都是three-legs,即都需要用户的参与\n2-legs的使用场景和第三方登陆无关,故不讨论\nThree legged does not imply a certain type of app as in \u0026ldquo;browser based\u0026rdquo;. Three legged means that an application acts on the direct behalf of a user. In the three legged scenarios there is\nan application (consumer), a user (resource owner) and an API (service provider). In two legged scenarios there is no concept of a user. Typically this has to do with application-to-application solutions. There the application (consumer) acts on behalf of itself. So in two legged OAuth, there is:\nan application (consumer), an API (service provider) The difference is simply that there is no need of a user authorisation step in the 2-legged approach.\n","id":85,"section":"posts","summary":"\u003ch1 id=\"oauth20\"\u003eOAuth2.0\u003c/h1\u003e\n\u003cp\u003eopen authority 2.0,开放授权\u003c/p\u003e\n\u003cp\u003e主要用于A网站向某个常用第三方社交网站请求用户信息,第三方社交网站需要给予A网站用户信息,这必须有用户的授权才行,但是如果直接给予A网站用户的用户名密码,又太不安全,并且我们希望只提供给A网站受限的资源访问权限,比如只能获取到用户名等.因此需要使用OAuth2.0\u003c/p\u003e","tags":["oauth2"],"title":"[protocol] OAuth2","uri":"https://wymli.github.io/2021/03/protocol-oauth2/","year":"2021"},{"content":"RPC识记-微服务概述 respect： rpc框架: https://doc.rpcx.io/\n关键字 服务发现，注册中心，服务治理，限流熔断隔离降级，codec等\nOutline 一般的，一个rpc框架就是一个微服务框架\n一个好的协议,request和response应该是同样的格式\n插件化与回调\n服务发现\n点对点 注册中心 服务选择\n重试策略 节点选择策略 限流熔断，隔离降级\n编解码codec\n不同的序列化手段 服务监控\ntrace：调用链追踪 logging：日志 metric：指标，统计分析 服务发现 服务发现\n类似DNS，是一个kv数据库，完成servicName到ip:port的映射\n点对点\n直接指定对端ip:port，dial对端，不需要服务发现 点对多\n同点对点，但指定了多个对端ip：port,它们将提供同样的服务，客户端在此模式下可以有不同的重试策略。 注册中心： zookeeper ， etcd ， consul\n服务注册中心用来实现服务发现和服务的元数据存储（比如serviceName到多个ip:port的映射）。\n传统的服务发现可能直接由静态配置文件设置，并且可以运行时动态监听文件修改并重新读入并应用。\n更现代的方式是拥有一个注册中心，我们不再维护本地的配置文件，好处是注册中心是中心化管理，多个客户端共享。\n注册中心都实现了某种分布式共识算法（指注册中心本身是分布式的（比如一个部署好的zookeeper集群），保证其某个节点失效仍可正常运行),其本质就是一个分布式键值数据库，如etcd\n此模式下，使用rpc时，不再需要指定服务主机地址，而替换为注册中心集群地址\n一般的，客户端将会向注册中心订阅，这样服务的动态变化将会异步通知到客户端。而不是客户端每次请求都去访问注册中心\ndubbo架构：\n服务选择 服务选择：\n失败模式（重试模式）：当遇到超时或网络错误，该怎么办？ 直接失败 重试其他节点 重试当前节点 广播一定数量的目标节点，有一个成功就算成功 节点选择 随机 roundrobin（顺序调用） weightedRoundRobin（在一个周期内，权值高的调用次数多，且较均匀的分布在周期内） 本质也是生成一个调用队列，依次出队 网络质量优先（基于ICMP ping） 也要防止网络状态不好的服务主机一直饥饿 一致性哈希 指满足均衡性，单调性，分散性，低负载的哈希算法，该算法将hash值空间组织成虚拟的环 首先将服务主机的ip:port计算出哈希值，store进哈希表 然后客户端对serviceName:serviceMethod:args计算出哈希值，将该值在环上按一定方向移动，第一个遇到的主机就是选中的主机 地理位置优先（计算经纬度） 自定义 限流熔断，隔离降级 限流：rateLimit\n目的：有损服务，而不是不服务\n限流对象\nTCP连接请求 一般无法限制tcp的建立，除非中间加一层代理网关 QPS：连接建立后，是否被处理 限流处理\n返回错误码，比如http常见的500 internal error 服务端阻塞等待一段时间，看能否在超时时间内被处理 常见算法：\n固定窗口计数器\n比如每分钟为一个窗口（一般以整分钟开始1分钟到2分钟一个窗口），限制每个窗口内最多1000个连接 缺点：对于随机选取的时间长度为1分钟的区间（比如1.5分钟到2.5分钟），不一定满足连接数小于1000 滑动窗口计数器\n固定窗口相当于长度为1的滑动窗口 比如以每秒钟为一个窗口，设置滑动窗口的长度为60，要求每分钟最多1000个连接。 每过1秒钟，滑动窗口向前移动一个小窗口，每个小窗口将维护一个计数，记录这个小窗口的时间期间到来的连接数 新的连接能否在新的小的时间窗口内被接收，取决于的逻辑的长度为60的滑动窗口内的所有小窗口记录的连接数之和是否大于1000 令牌桶 token bucket\n维护一个有大小的令牌桶，若桶未满，则以一定的速率生成令牌放入桶中\n每个请求必须在申请到令牌后，才会被处理，否则限流\n原生令牌桶是基于字节数判断一个packet是否有效，即限制的是读写的byte数\n详见https://en.wikipedia.org/wiki/Token_bucket\n一个限流器实现： https://github.com/juju/ratelimit, 其reader/writer实现:\nfunc (r *reader) Read(buf []byte) (int, error) { n, err := r.r.Read(buf) if n \u0026lt;= 0 { return n, err } r.bucket.Wait(int64(n)) return n, err } func (w *writer) Write(buf []byte) (int, error) { w.bucket.Wait(int64(len(buf))) return w.w.Write(buf) } 实际上也可以用于直接限制连接：\n// rpcx的限流插件：实现了PostConnAcceptPlugin接口 //\tPostConnAcceptPlugin interface { //\tHandleConnAccept(net.Conn) (net.Conn, bool) //\t} func (plugin *RateLimitingPlugin) HandleConnAccept(conn net.Conn) (net.Conn, bool) { return conn, plugin.bucket.TakeAvailable(1) \u0026gt; 0 } 漏桶\n维持一个固定大小的连接队列，以恒定的速率出队 熔断： circuit breaker（断路器）\n熔断属于服务作为客户端时的行为 当对一个节点的调用出现连续的错误时，断路器将打开，后续对该节点的调用将直接返回错误。一定时间后断路器半开，允许一定数量的请求，若正常访问则全开，否则继续断开 这主要是为了防止大量的请求处于请求发出而未超时的等待阶段，若这个客户端本身作为服务，则也会影响自身的服务提供，导致雪崩 因为资源是有限的，一个goroutine要2k的栈，再加上1k的recv buffer等等 降级\n服务降级：本质就是提供有损服务 限流和熔断都属于服务降级 隔离\n将本机的各个服务隔离开，这也是docker这类容器的优点：隔离 实现上，就是对资源的获取是有限度的，比如设置最大的goroutine数，这可以通过线程池做到 编解码codec 常见的编解码器，即对对象的序列化和反序列化功能\nbinary json 对性能要求不高的场景，可读性高 protobuf google出品 messagePack 插件化和回调 rpcx提供了多种回调接口,只要插件实现了这些接口，再注册进插件中心即可在合适的地方被调用\n比如限流插件，我们期望其在连接建立后被调用，因此要实现HandleConnAccept(conn net.Conn) (net.Conn, bool)方法\ntype ( // ... 省略一部分 // PostConnAcceptPlugin represents connection accept plugin. // if returns false, it means subsequent IPostConnAcceptPlugins should not continue to handle this conn // and this conn has been closed. PostConnAcceptPlugin interface { HandleConnAccept(net.Conn) (net.Conn, bool) } // PostConnClosePlugin represents client connection close plugin. PostConnClosePlugin interface { HandleConnClose(net.Conn) bool } // PreReadRequestPlugin represents . PreReadRequestPlugin interface { PreReadRequest(ctx context.Context) error } // PostReadRequestPlugin represents . PostReadRequestPlugin interface { PostReadRequest(ctx context.Context, r *protocol.Message, e error) error } // ...省略一部分 ) 插件中心将会在合适的地方调用注册好的插件，比如read前后的回调：\nfunc (s *Server) readRequest(ctx context.Context, r io.Reader) (req *protocol.Message, err error) { // here callback err = s.Plugins.DoPreReadRequest(ctx) if err != nil { return nil, err } // pool req? req = protocol.GetPooledMsg() err = req.Decode(r) if err == io.EOF { return req, err } // here callback perr := s.Plugins.DoPostReadRequest(ctx, req, err) if err == nil { err = perr } return req, err } 一个朴素的插件中心的实现,将会把不同的插件无差别的放进一个[]interface{}，调用时再遍历一个个type assertion，看是否是想要的接口，这也是rpcx默认的插件中心的实现方法\n//DoPostConnAccept handles accepted conn func (p *pluginContainer) DoPostConnAccept(conn net.Conn) (net.Conn, bool) { var flag bool for i := range p.plugins { if plugin, ok := p.plugins[i].(PostConnAcceptPlugin); ok { conn, flag = plugin.HandleConnAccept(conn) if !flag { //interrupt conn.Close() return conn, false } } } return conn, true } 下一代微服务 service mesh\n分为数据面和控制面，用户只需编写数据面即可 ","id":86,"section":"posts","summary":"\u003ch1 id=\"rpc识记-微服务概述\"\u003eRPC识记-微服务概述\u003c/h1\u003e\n\u003cp\u003erespect： rpc框架:  \u003ca href=\"https://doc.rpcx.io/\"\u003ehttps://doc.rpcx.io/\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"关键字\"\u003e关键字\u003c/h2\u003e\n\u003cp\u003e服务发现，注册中心，服务治理，限流熔断隔离降级，codec等\u003c/p\u003e\n\u003ch2 id=\"outline\"\u003eOutline\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e一般的，一个rpc框架就是一个微服务框架\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e一个好的协议,request和response应该是同样的格式\u003c/p\u003e","tags":["rpc"],"title":"[rpc] rpcx","uri":"https://wymli.github.io/2021/03/rpc-rpcx/","year":"2021"},{"content":"Inotify The inotify API provides a mechanism for monitoring filesystem events. Inotify can be used to monitor individual files, or to monitor directories. When a directory is monitored, inotify will return events for the directory itself, and for files inside the directory. 四个API\nfunc InotifyInit() (fd int, err error) func InotifyInit1(flags int) (fd int, err error) 这个可以设置flags(O_NONBLOCK,O_BLOCK),这涉及到read(fd,buffer,buff_size)时是阻塞还是非阻塞 func InotifyAddWatch(fd int, pathname string, mask uint32) (watchdesc int, err error) 对pathname进行监听,并绑定到fd上,mask表示监听哪些事件 返回watch desciptor,专用于remove取消监听 func InotifyRmWatch(fd int, watchdesc uint32) (success int, err error) 将监听事件从fd上取消 其他 读取事件 read(fd , buf , buf_sz) 关闭监听 close(fd) buf 将需要被解释成:\nstruct inotify_event { int wd; /* Watch descriptor */ uint32_t mask; /* Mask describing event */ uint32_t cookie; /* Unique cookie associating related events (for rename(2)) */ uint32_t len; /* Size of name field */ char name[]; /* Optional null-terminated name */ }; 在go语言中就是:\nevent := (*syscall.InotifyEvent)(unsafe.Pointer(\u0026amp;buffer[offset])) 示例: from: tomnomnom/go-learning\nfunc main() { fd, err := syscall.InotifyInit() if err != nil { log.Fatal(err) } defer syscall.Close(fd) wd1, err := syscall.InotifyAddWatch(fd, \u0026quot;test1.log\u0026quot;, syscall.IN_ALL_EVENTS) wd2, err = syscall.InotifyAddWatch(fd, \u0026quot;../test2.log\u0026quot;, syscall.IN_ALL_EVENTS) //_, err = syscall.InotifyAddWatch(fd, \u0026quot;.\u0026quot;, syscall.IN_ALL_EVENTS) if err != nil { log.Fatal(err) } defer syscall.InotifyRmWatch(fd, uint32(wd1)) defer syscall.InotifyRmWatch(fd, uint32(wd2)) fmt.Printf(\u0026quot;WD is %d\\n\u0026quot;, wd) for { // Room for at least 128 events buffer := make([]byte, syscall.SizeofInotifyEvent*128) bytesRead, err := syscall.Read(fd, buffer) if err != nil { log.Fatal(err) } if bytesRead \u0026lt; syscall.SizeofInotifyEvent { // No point trying if we don't have at least one event continue } fmt.Printf(\u0026quot;Size of InotifyEvent is %s\\n\u0026quot;, syscall.SizeofInotifyEvent) fmt.Printf(\u0026quot;Bytes read: %d\\n\u0026quot;, bytesRead) offset := 0 for offset \u0026lt; bytesRead-syscall.SizeofInotifyEvent { event := (*syscall.InotifyEvent)(unsafe.Pointer(\u0026amp;buffer[offset])) fmt.Printf(\u0026quot;%+v\\n\u0026quot;, event) if (event.Mask \u0026amp; syscall.IN_ACCESS) \u0026gt; 0 { fmt.Printf(\u0026quot;Saw IN_ACCESS for %+v\\n\u0026quot;, event) } // We need to account for the length of the name offset += syscall.SizeofInotifyEvent + int(event.Len) } } } ","id":87,"section":"posts","summary":"\u003ch1 id=\"inotify\"\u003eInotify\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cpre\u003e\u003ccode\u003eThe inotify API provides a mechanism for monitoring filesystem\nevents.  Inotify can be used to monitor individual files, or to\nmonitor directories.  When a directory is monitored, inotify will\nreturn events for the directory itself, and for files inside the\ndirectory.\n\u003c/code\u003e\u003c/pre\u003e\u003c/blockquote\u003e\n\u003cp\u003e四个API\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003efunc InotifyInit() (fd int, err error)\n\u003cul\u003e\n\u003cli\u003efunc InotifyInit1(flags int) (fd int, err error) 这个可以设置flags(O_NONBLOCK,O_BLOCK),这涉及到read(fd,buffer,buff_size)时是阻塞还是非阻塞\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003efunc InotifyAddWatch(fd int, pathname string, mask uint32) (watchdesc int, err error)\n\u003cul\u003e\n\u003cli\u003e对pathname进行监听,并绑定到fd上,mask表示监听哪些事件\u003c/li\u003e\n\u003cli\u003e返回watch desciptor,专用于remove取消监听\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003efunc InotifyRmWatch(fd int, watchdesc uint32) (success int, err error)\n\u003cul\u003e\n\u003cli\u003e将监听事件从fd上取消\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e其他\n\u003cul\u003e\n\u003cli\u003e读取事件\n\u003cul\u003e\n\u003cli\u003eread(fd , buf , buf_sz)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e关闭监听\n\u003cul\u003e\n\u003cli\u003eclose(fd)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003ebuf 将需要被解释成:\u003c/p\u003e","tags":["sys"],"title":"[sys] inotify","uri":"https://wymli.github.io/2021/03/sys-inotify/","year":"2021"},{"content":"TSAR taobao system activity reporter\n该工具本质是在读取linux系统/proc目录下的一些计数器文件,本片文章来介绍这些文件,及其内部包含的信息\n关于此目录下的文件信息,\n可直接看linux官方文档:https://man7.org/linux/man-pages/man5/procfs.5.html\n也可关注tsar给的文档: https://github.com/alibaba/tsar/blob/master/info.md\n由于每个文件是非常verbose的,如果你只想关注更重要的那些字段,你可以看看top命令打印了哪些字段\nCPU coreInfo 使用此指令打印出一个逻辑核的相关信息,其他核是类似的信息,因为是SMP\ncat cpuinfo | head -n 27\nprocessor : 0 vendor_id : GenuineIntel cpu family : 6 model : 142 model name : Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz stepping : 10 microcode : 0xffffffff cpu MHz : 1799.999 cache size : 6144 KB physical id : 0 siblings : 8 core id : 0 cpu cores : 4 apicid : 0 initial apicid : 0 fpu : yes fpu_exception : yes cpuid level : 21 wp : yes flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 xsaves flush_l1d arch_capabilities bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit bogomips : 3599.99 clflush size : 64 cache_alignment : 64 address sizes : 39 bits physical, 48 bits virtual power management: 解释:\n摘自https://www.cnblogs.com/wxxjianchi/p/10522049.html\nprocessor　：系统中逻辑处理核心数的编号，从0开始排序。 vendor_id　：CPU制造商 cpu family　：CPU产品系列代号 model　：CPU属于其系列中的哪一代的代号 model name：CPU属于的名字及其编号、标称主频 stepping　：CPU属于制作更新版本 cpu MHz　：CPU的实际使用主频 cache size ：CPU二级缓存大小 physical id ：单个物理CPU的标号 siblings ：单个物理CPU的逻辑CPU数。siblings=cpu cores [*2]。 core id ：当前物理核在其所处CPU中的编号，这个编号不一定连续。 cpu cores ：该逻辑核所处CPU的物理核数。比如此处cpu cores 是4个，那么对应core id 可能是 1、3、4、5。 apicid ：用来区分不同逻辑核的编号，系统中每个逻辑核的此编号必然不同，此编号不一定连续 fpu ：是否具有浮点运算单元（Floating Point Unit） fpu_exception ：是否支持浮点计算异常 cpuid level ：执行cpuid指令前，eax寄存器中的值，根据不同的值cpuid指令会返回不同的内容 wp ：表明当前CPU是否在内核态支持对用户空间的写保护（Write Protection） flags ：当前CPU支持的功能 bogomips：在系统内核启动时粗略测算的CPU速度（Million Instructions Per Second clflush size ：每次刷新缓存的大小单位 cache_alignment ：缓存地址对齐单位 address sizes ：可访问地址空间位数 power management ：对能源管理的支持 注解 上面已经讲的很清楚了,可以看出,我们的cpu的缓存是64字节为一个缓存行的,有专门的浮点数alu,每秒大概能执行3.6G条指令,虚拟地址空间是48位,物理地址空间是39位.cpu的实际主频是1.8GHZ,在flags里,我们看到了熟悉的avx,也就是是否支持向量化拓展指令集.\n使用\ncat cpuinfo | grep processor\n可以看到输出是8个处理器,这是因为intel的单CPU四核八线程,这里的线程可以理解为就是处理器的意思\n超线程技术 我们知道一个核支持并行执行指令有几个级别,比如数据级并行,指令级并行和线程级并行\n数据级并行 多个ALU 指令级并行 多个取址译码器,多个ALU,同时执行一个线程的多条指令 也叫多发射 动态多发射叫超标量,即运行时确定同时执行哪些指令 与之相比的是静态多发射,由编译器确定同时执行哪些指令 瓶颈很明显,由于各自依赖(比如数据依赖),单线程没有那么多指令可以并行 线程级并行 多个取址译码器,多个ALU,多个Context(执行上下文/也就是寄存器组) 同时执行不同线程的多条指令 超线程应该就是同时多线程的一种实现\ncpuTime cat /proc/stat 此命令查看cpu的时间分配,典型的就是用户态运行时间,内核态运行时间,io阻塞时间,空闲空转时间,中断时间等\n参考: http://gityuan.com/2017/08/12/proc_stat/\n//CPU指标：user，nice, system, idle, iowait, irq, softirq cpu 151 0 1822 3035462 65 0 66 0 0 0 cpu0 17 0 737 378763 6 0 44 0 0 0 cpu1 6 0 38 379698 8 0 11 0 0 0 cpu2 30 0 320 379258 28 0 11 0 0 0 cpu3 8 0 24 379718 1 0 0 0 0 0 cpu4 29 0 239 379427 6 0 0 0 0 0 cpu5 5 0 15 379698 0 0 0 0 0 0 cpu6 22 0 422 379221 8 0 0 0 0 0 cpu7 34 0 27 379674 4 0 0 0 0 0 intr 31441 0 0 0 0 0 0 0 0 0 18 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ctxt 151746 // 进程上下文切换次数 btime 1616574037 // 计算机启动时间(Unix时间) processes 403 // Number of forks since boot. 如果想看当前的进程数,可以看/proc/loadavg或top procs_running 1 // 正在运行的进程数 procs_blocked 0 // 阻塞数 softirq 147819 0 41104 0 123 4812 0 20320 42642 0 38818 cpu指标 含义 user 用户态时间(一般/高优先级,nice\u0026lt;=0) nice 用户态时间(低优先级，nice\u0026gt;0) system 内核态时间 idle 空闲时间 iowait I/O等待时间 irq 硬中断 softirq 软中断 steal 被盗时间,Steal time is the percentage of time a virtual CPU waits for a real CPU while the hypervisor is servicing another virtual processor. guest 来宾时间 guest_nice nice来宾时间 单位是jiffies , 1 jiffies = 0.01s = 10ms\n统计cpu利用率: 总时间就是它们的和\ntop 在top命令的第三行,即打印出了全局的cpu利用率\n%Cpu(s): 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st 进程 如果想看某个进程的统计信息,一是strace -p [pid],二就是直接看统计文件\n某个进程的统计文件在/proc/[pid]/stat\nMemory /rpoc/meminfo\nMemTotal: 6399360 kB // 总共可用空间,由physical - reserved bits - kernel binary code MemFree: 6285756 kB // LowFree+HighFree. MemAvailable: 6181148 kB // 在不换页的情况下,一个新进程可以使用多少内存 Buffers: 7140 kB // 尚未被写回硬盘的块 Cached: 21828 kB // page cache,not include wapcached SwapCached: 0 kB // 和swapfile有关 Active: 19984 kB // Inactive: 11220 kB Active(anon): 2352 kB Inactive(anon): 8 kB Active(file): 17632 kB Inactive(file): 11212 kB Unevictable: 0 kB Mlocked: 0 kB SwapTotal: 2097152 kB SwapFree: 2097152 kB Dirty: 76 kB Writeback: 0 kB AnonPages: 2228 kB Mapped: 4000 kB Shmem: 68 kB Slab: 26720 kB SReclaimable: 12924 kB SUnreclaim: 13796 kB KernelStack: 1892 kB PageTables: 448 kB NFS_Unstable: 0 kB Bounce: 0 kB WritebackTmp: 0 kB CommitLimit: 5296832 kB Committed_AS: 8048 kB VmallocTotal: 34359738367 kB VmallocUsed: 0 kB VmallocChunk: 0 kB Percpu: 1888 kB AnonHugePages: 0 kB ShmemHugePages: 0 kB ShmemPmdMapped: 0 kB HugePages_Total: 0 HugePages_Free: 0 HugePages_Rsvd: 0 HugePages_Surp: 0 Hugepagesize: 2048 kB Hugetlb: 0 kB DirectMap4k: 17408 kB DirectMap2M: 2398208 kB DirectMap1G: 5242880 kB util = (total - free - buff - cache) / total * 100% 在top的第四/五行:\nKiB Mem : 6399360 total, 6276944 free, 75224 used, 47192 buff KiB Swap: 2097152 total, 2097152 free, 0 used. 6175056 avai LoadAvg /proc/loadavg\n0.00 0.00 0.00 1/110 52 The first three fields in this file are load average figures giving the number of jobs in the run queue (state R) or waiting for disk I/O (state D) averaged over 1, 5, and 15 minutes. They are the same as the load average numbers given by uptime(1) and other programs. The fourth field consists of two numbers separated by a slash (/). The first of these is the number of currently runnable kernel scheduling entities (processes, threads). The value after the slash is the number of kernel scheduling entities that currently exist on the system. The fifth field is the PID of the process that was most recently created on the system. Trafic /proc/net/dev\nInter-| Receive | Transmit face |bytes packets errs drop fifo frame compressed multicast|bytes packets errs drop fifo colls carrier compressed eth0: 2234 22 0 0 0 0 0 21 1266 17 0 0 0 0 0 0 lo: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 dummy0: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 bond0: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 sit0: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 TCP/UDP/ICMP /proc/net/snmp\ndiskIO /proc/diskstats\nother 更多详细的可以直接看linux官方文档和tsar\n注意一般官方文档的释义可能也比较简略,这时自己再搜索一下基本就ok了\n","id":88,"section":"posts","summary":"\u003ch1 id=\"tsar\"\u003eTSAR\u003c/h1\u003e\n\u003cp\u003etaobao system activity reporter\u003c/p\u003e\n\u003cp\u003e该工具本质是在读取linux系统/proc目录下的一些计数器文件,本片文章来介绍这些文件,及其内部包含的信息\u003c/p\u003e\n\u003cp\u003e关于此目录下的文件信息,\u003c/p\u003e\n\u003cp\u003e可直接看linux官方文档:https://man7.org/linux/man-pages/man5/procfs.5.html\u003c/p\u003e","tags":["proc"],"title":"[sys] tsar\u0026proc","uri":"https://wymli.github.io/2021/03/sys-tsarproc/","year":"2021"},{"content":"1. vue的生命周期/运行流程/渲染流程/初始化流程 doc link\nvue的入口文件可以有四个可能的命名:main.js,index.js,app.vue,App.vue\n真正的入口文件取决于哪个文件包含了vue实例(new Vue({})),渲染流程从vue实例开始 流程大致如下:\nnew Vue({}) init event 回调 beforeCreate() init element 回调 created() 检查Vue实例: 是否有{el:\u0026quot;\u0026hellip;\u0026quot;}? 没有:等待vm.$mount(el)被调用,然后下一步 例: new Vue({render: h =\u0026gt; h(App),}).$mount('#app') 一般出现在main.js,index.js文件中 有:下一步 是否有\u0026lt;template\u0026gt; 有:把\u0026lt;template\u0026gt;编译到render function 没有:把el的outerHTML作为template编译 回调 beforeMount() 创建vm.$el,并且用vm.$el替换#el(应该指渲染,用前面的renderFunc/template) 回调 mounted() 实例进入监听循环,当数据被改变时,重新渲染 回调: beforeUpdate() 回调: updated() 当vm.$destroy()被调用 回调: beforeDestroy() teardown(拆除) watchers,子组件,事件监听器 回调: destroyed() 分析:\nvue实例一定要挂载到一个html元素上 手动使用vm.$mount(\u0026quot;#app\u0026quot;),是为了延迟挂载渲染 render:h=\u0026gt;h(oneComponent) 是一种渲染组件的方式 render: function (createElement) { return createElement(App); } 使用vue-cli,vue create hello-word生成的代码分析 main.js import Vue from 'vue' import App from './App.vue' Vue.config.productionTip = false new Vue({ render: h =\u0026gt; h(App), }).$mount('#app') 等价于,...就是把字典解包\nimport Vue from 'vue' import App from './App.vue' Vue.config.productionTip = false new Vue({ el: '#app', ...App }) ","id":89,"section":"posts","summary":"\u003ch1 id=\"1-vue的生命周期运行流程渲染流程初始化流程\"\u003e1. vue的生命周期/运行流程/渲染流程/初始化流程\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://cn.vuejs.org/v2/guide/instance.html#%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E5%9B%BE%E7%A4%BA\"\u003edoc link\u003c/a\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003evue的入口文件可以有四个可能的命名:main.js,index.js,app.vue,App.vue\u003c/p\u003e","tags":["Vue"],"title":"[vue] everything","uri":"https://wymli.github.io/2021/03/vue-everything/","year":"2021"},{"content":"About import and export 这是es6的语法,即js的语法 export用于对外输出本模块的数据 import用于引入其他模块的数据 语法细则 // 导出变量 // 法一 // js1 export var name = \u0026quot;a\u0026quot; // js2 import {name} from \u0026quot;./js1.js\u0026quot; // 法二 // js1 var name1 = \u0026quot;a\u0026quot; var name2 = \u0026quot;b\u0026quot; export {name1 , name2} // 或者 export name1 export name2 // 或者 export var name1 = \u0026quot;a\u0026quot; export var name2 = \u0026quot;b\u0026quot; // js2 import {name1 , name2} from \u0026quot;./js1.js\u0026quot; // 或者 import {name1} from \u0026quot;./js1.js\u0026quot; import {name2} from \u0026quot;./js1.js\u0026quot; // =========================== // 导出函数,和变量是一致的 function add(x,y){ return (x+y) } export {add} // 或者 export function add(x,y){ return x+y } // js2 import {add} from \u0026quot;./js1.js\u0026quot; export and export default export,export default均可用于导出变量,函数,文件,模块等 一个文件或模块中,export/import可以有多个,但是export default只能有一个 export的导出,import时要加入{},但是export default则不需要 export default相当于指定默认输出,而export时,import要完整写出对应导出的变量/函数名 export default { address：'1', } export var title = '2' export var zzz = '3' // js2 import js1,{title as t , zzz} from \u0026quot;./js1.js\u0026quot; import的后缀名省略 直接使用import js from \u0026quot;./js1\u0026quot; 规则: 在 webpack.base.conf.js 中设置 可以省略js,vue后缀 若同时存在js,vue后缀同名文件,js\u0026gt;vue from后可以是文件夹 加载规则: 先看该文件夹有没有packag.json 若有:取package.main指定的js作为from的来源 index.js index.vue 注意,一般来说 package.json都只会出现项目根目录,注意不是@,是@的再外面一层,用来配置npm install这些指令 ","id":90,"section":"posts","summary":"\u003ch1 id=\"about-import-and-export\"\u003eAbout import and export\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e这是es6的语法,即js的语法\u003c/li\u003e\n\u003cli\u003eexport用于对外输出本模块的数据\u003c/li\u003e\n\u003cli\u003eimport用于引入其他模块的数据\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"语法细则\"\u003e语法细则\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-js\"\u003e// 导出变量\n// 法一\n// js1\nexport var name = \u0026quot;a\u0026quot;\n// js2\nimport {name} from \u0026quot;./js1.js\u0026quot;\n\n// 法二\n// js1\nvar name1 = \u0026quot;a\u0026quot;\nvar name2 = \u0026quot;b\u0026quot;\nexport {name1 , name2}\n// 或者\nexport name1\nexport name2\n// 或者\nexport var name1 = \u0026quot;a\u0026quot;\nexport var name2 = \u0026quot;b\u0026quot;\n\n// js2\nimport {name1 , name2} from \u0026quot;./js1.js\u0026quot;\n// 或者\nimport {name1} from \u0026quot;./js1.js\u0026quot;\nimport {name2} from \u0026quot;./js1.js\u0026quot;\n\n// ===========================\n\n// 导出函数,和变量是一致的\nfunction add(x,y){\n  return (x+y)\n}\nexport {add}\n// 或者\nexport function add(x,y){\n  return x+y\n}\n// js2\nimport {add} from \u0026quot;./js1.js\u0026quot;\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"export-and-export-default\"\u003eexport and export default\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eexport,export default均可用于导出变量,函数,文件,模块等\u003c/li\u003e\n\u003cli\u003e一个文件或模块中,export/import可以有多个,但是export default只能有一个\u003c/li\u003e\n\u003cli\u003eexport的导出,import时要加入{},但是export default则不需要\u003c/li\u003e\n\u003cli\u003eexport default相当于指定默认输出,而export时,import要完整写出对应导出的变量/函数名\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"language-js\"\u003eexport default {\n\taddress：'1',\n}\nexport var title = '2'\nexport var zzz = '3'\n// js2\nimport js1,{title as t , zzz} from \u0026quot;./js1.js\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"import的后缀名省略\"\u003eimport的后缀名省略\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e直接使用\u003ccode\u003eimport js from \u0026quot;./js1\u0026quot;\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e规则:\n\u003cul\u003e\n\u003cli\u003e在 \u003ccode\u003ewebpack.base.conf.js\u003c/code\u003e 中设置\u003c/li\u003e\n\u003cli\u003e可以省略js,vue后缀\u003c/li\u003e\n\u003cli\u003e若同时存在js,vue后缀同名文件,js\u0026gt;vue\u003c/li\u003e\n\u003cli\u003efrom后可以是文件夹\n\u003cul\u003e\n\u003cli\u003e加载规则:\n\u003cul\u003e\n\u003cli\u003e先看该文件夹有没有packag.json\n\u003cul\u003e\n\u003cli\u003e若有:取package.main指定的js作为from的来源\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eindex.js\u003c/li\u003e\n\u003cli\u003eindex.vue\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e注意,一般来说 package.json都只会出现项目根目录,注意不是@,是@的再外面一层,用来配置npm install这些指令\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","tags":["Vue"],"title":"[vue] import-export","uri":"https://wymli.github.io/2021/03/vue-import-export/","year":"2021"},{"content":"聚类 聚类是一种无监督的方法,我们仅仅通过向量的特征即可将不同的向量按相邻的距离聚在一起\n对于输入的数值元组的不同的视角,我们可以定义不同的距离\n将元组视为向量 计算cos距离来求解相似度,即余弦值,可有余弦定理计算得出 将元组视为集合 计算jaccard距离,即A∩B/A∪B 将元组视为欧氏空间中的坐标点 计算欧式距离 层次聚类 方法是不断的将小聚类合并(合并两个最近的聚类),形成大的聚类,从单个点作为一个聚类开始\n也可以是top down的方法,不断将大聚类split,但一般采用bottom up方法\n聚类的代表 centroid : average of its points(这要求欧式空间(欧式距离),此时直线最短,所以直接求平均,便是聚类的中心点) centroid 可能不是一个实际存在的点 clustroid: point closest to other points clustroid一定是一个实际存在的点 聚类内closest的定义(clustroid选举) 某个点关于其他所有点的最大距离最小,则这个点是clustroid 某个点关于其他所有点的平均距离最小 某个点关于其他所有点的距离平方和最小 聚类间nearness定义(聚类合并选择) 将clustroid视作centroid,计算两个cluster的centroid/clustroid之间的距离 注意如果没有定义欧式距离就没有centroid,但一定会有距离的定义,只是不是直线最短 分别从两个聚类选择两个点,得到的最小的距离即使聚类之间的距离 凝聚度(计算合并后的聚类的凝聚度) 直径: 聚类内的点之间的最大距离 平均距离: 聚类内所有点之间的平均距离 密度: 使用直径或平均距离除以点数,密度越小越好(相同直径下,点越多,密度越小,聚类越密集) 看网上其他博客,基本都采用这样的距离定义来计算聚类间的nearness: 聚类间两点距离的最小值 聚类间两点距离的最大值 聚类间两点距离的平均值 k-means 算法 这里的k指的是k个聚类\n首先会给每个聚类随机初始化为1个点,也就是我们要随机选取k个点,每个点作为一个聚类.\n但显然,如果随机选,可能选到两个很近的点,因此针对初始化的不同,提出了k-means++算法,二者仅仅在初始化时不同,后续跌打是一样的\n初始化 随机 k-means++ 随机遍历点,但是否将它们加入初始点集合取决于它与已加入初始点集合内的点的最短距离的平方 因此,以这种方法选出来的k个初始点将会尽可能的远 于是,每个cluster都有了一个centroid 聚类 遍历所有点,将其加入离他最近的centroid所属的cluster(你可以认为也遍历了初始点,反正肯定离自己最近,当迭代一次后,一般centroid都不再是实际存在的点) 遍历完后,更新cluster的centroid位置 重新遍历所有点,加入离他最近的centroid所属的cluster 此时,点对cluster的所属关系可能变更 重复上述过程 收敛 当点对cluster的所属关系不再变更,并且centroid稳定时,认为收敛 k的选择 我们计算聚类内的点到centroid的平均距离作为k的好坏,平均距离越小,k越好 实践证明,k越大,平均距离越小,当大到一定程度后,平均距离几乎不变,此时即为最佳的k BFR 算法 算法名字是三个发明人的首字母\nBFR算法是k-means算法的变种,用于解决大规模数据集问题(这些数据集一般驻留在磁盘上)\n首先我们假设聚类内的点是关于centroid呈正太分布的,不同的维度的标准差不同,这意味着一个聚类将会很像一个关于轴对齐的椭圆(一个轴就是一个维度)\n? 我们的目标是找到cluster的centroid,然后就可以按照k-means的算法,对所有点计算得到离他最近的centroid,并归入那个cluster(这称为point assignment)\n算法流程:\n初始化k个cluster的centroid 加载一些point到内存 对这些点进行point assignment,前提是最小距离小于一定的阈值,如果这些点离最近的centroid的距离大于所设置的阈值,则将这些点视为outlier离群点 将离群点独立为一个cluster,于是现存k+1个cluster 对k+1个cluster中的两个cluster执行merge,生成k个cluster 重复2-5 我们将维护三类点集\nDiscard set(DS): 能够被分配给某个cluster的点(我们可以加载它,计算统计信息,然后丢弃这个实例,有点充分统计量的感觉) Compression set(CS): 一些足够近的点的集合,但这些点离最近的centroid足够远,所以独立成为一个cluster Retained set(RS): 孤立的等待被分配给CS压缩集的点 每个discard set将会维护2d+1个值,d是向量的维度\n1: 点数 d: sum向量,sum_i代表set内的所有点的第i个分量的和 d: sumsq向量,sumsq_i代表sum_i的平方 有了这三个数值,我们可以很方便的计算ds的centroid和方差(centroid就是每个维度的平均值,sum/N , 方差就是(sumsq/N) - (sum/N)^2),我们不需要知道到底哪些点属于ds,我们唯一要维护的就是这三个统计量\n注意,cluster是轴对齐的,这样的好处是sumsq是一个d维向量,而不是一个dxd的二维协方差矩阵\n将点加载到内存,如果发现这些点离某个centroid足够近,就将这些点分配给那个cluster,并添加到ds\n这样,一次加载进内存的点将还会剩下一些点没有进入任何集合,这些点由于离现存的centroid们比较远而无法进入discard set,现在我们对这些在内存中的点运用任何in-memory的聚类方法分类即可,我们要分出两类,一类是compression set,一类是retained set\n比如我们直接对剩下的点随机初始化几个centroid(或使用层次聚类),然后遍历所有点,如果离这些centroid足够近,就加入这些cluster对应的compression set,否则便是离群点,加入retained set\n下一步,我们首先处理ds,之前加入ds的点,在这一步用于更新ds的统计量(N,sum,sumsq)(实际上这一步完全可以放在加入ds时就直接更新统计量)\n然后,考虑合并compressed set,如果这是最后一轮,那么合并compressed set和ratained set到最近的cluster中\n距离 使用mahalanobis distance(马氏距离),点x到centroid点c的距离定义为: $$ d(x,c) = \\sqrt{\\sum_{i=1}^d(\\frac{x_i-c_i}{\\sigma_i})^2} $$ 即对每个维度进行标准化,然后求平方和的根号\n根据3sigma原则, 当x_i = c_i + sigma_i或c_i - sigma时,dist = sqrt(d)\n此时,有68%的概率,使得dist\u0026lt;sqrt(d),如果x服从正态分布\n一般的,我们认为一个点x属于某个cluster,如果dist\u0026lt;2sqrt(d)\n合并 何时合并cs中的集合呢? 如果合并后的方差小于某个阈值,则合并两个compressed set\nCURE \u0026hellip;\n","id":91,"section":"posts","summary":"\u003ch1 id=\"聚类\"\u003e聚类\u003c/h1\u003e\n\u003cp\u003e聚类是一种无监督的方法,我们仅仅通过向量的特征即可将不同的向量按相邻的距离聚在一起\u003c/p\u003e\n\u003cp\u003e对于输入的数值元组的不同的视角,我们可以定义不同的距离\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e将元组视为向量\n\u003cul\u003e\n\u003cli\u003e计算cos距离来求解相似度,即余弦值,可有余弦定理计算得出\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e将元组视为集合\n\u003cul\u003e\n\u003cli\u003e计算jaccard距离,即A∩B/A∪B\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e将元组视为欧氏空间中的坐标点\n\u003cul\u003e\n\u003cli\u003e计算欧式距离\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"层次聚类\"\u003e层次聚类\u003c/h2\u003e\n\u003cp\u003e方法是不断的将小聚类合并(合并两个最近的聚类),形成大的聚类,从单个点作为一个聚类开始\u003c/p\u003e","tags":null,"title":"","uri":"https://wymli.github.io/1/01/datamining-cluster/","year":"0001"}],"tags":[{"title":"Ai Agent","uri":"https://wymli.github.io/tags/ai-agent/"},{"title":"Airflow","uri":"https://wymli.github.io/tags/airflow/"},{"title":"Algorithm","uri":"https://wymli.github.io/tags/algorithm/"},{"title":"Arch","uri":"https://wymli.github.io/tags/arch/"},{"title":"Atomic","uri":"https://wymli.github.io/tags/atomic/"},{"title":"BigData","uri":"https://wymli.github.io/tags/bigdata/"},{"title":"ByteDance","uri":"https://wymli.github.io/tags/bytedance/"},{"title":"C","uri":"https://wymli.github.io/tags/c/"},{"title":"Cache","uri":"https://wymli.github.io/tags/cache/"},{"title":"Cli","uri":"https://wymli.github.io/tags/cli/"},{"title":"Concurrency","uri":"https://wymli.github.io/tags/concurrency/"},{"title":"Container","uri":"https://wymli.github.io/tags/container/"},{"title":"Containerd","uri":"https://wymli.github.io/tags/containerd/"},{"title":"Database","uri":"https://wymli.github.io/tags/database/"},{"title":"DataMining","uri":"https://wymli.github.io/tags/datamining/"},{"title":"DataStructure","uri":"https://wymli.github.io/tags/datastructure/"},{"title":"Db","uri":"https://wymli.github.io/tags/db/"},{"title":"Deploy","uri":"https://wymli.github.io/tags/deploy/"},{"title":"DesignPattern","uri":"https://wymli.github.io/tags/designpattern/"},{"title":"Distribute","uri":"https://wymli.github.io/tags/distribute/"},{"title":"Eino","uri":"https://wymli.github.io/tags/eino/"},{"title":"Epoll","uri":"https://wymli.github.io/tags/epoll/"},{"title":"Event-Stream","uri":"https://wymli.github.io/tags/event-stream/"},{"title":"Golang","uri":"https://wymli.github.io/tags/golang/"},{"title":"Gpu","uri":"https://wymli.github.io/tags/gpu/"},{"title":"Http","uri":"https://wymli.github.io/tags/http/"},{"title":"Interview","uri":"https://wymli.github.io/tags/interview/"},{"title":"K8s","uri":"https://wymli.github.io/tags/k8s/"},{"title":"Kafka","uri":"https://wymli.github.io/tags/kafka/"},{"title":"Llm","uri":"https://wymli.github.io/tags/llm/"},{"title":"LSH","uri":"https://wymli.github.io/tags/lsh/"},{"title":"Net","uri":"https://wymli.github.io/tags/net/"},{"title":"Oauth2","uri":"https://wymli.github.io/tags/oauth2/"},{"title":"Oci","uri":"https://wymli.github.io/tags/oci/"},{"title":"Other","uri":"https://wymli.github.io/tags/other/"},{"title":"Overlayfs","uri":"https://wymli.github.io/tags/overlayfs/"},{"title":"Proc","uri":"https://wymli.github.io/tags/proc/"},{"title":"Python","uri":"https://wymli.github.io/tags/python/"},{"title":"Redis","uri":"https://wymli.github.io/tags/redis/"},{"title":"Rpc","uri":"https://wymli.github.io/tags/rpc/"},{"title":"Runc","uri":"https://wymli.github.io/tags/runc/"},{"title":"Scheduler","uri":"https://wymli.github.io/tags/scheduler/"},{"title":"Script","uri":"https://wymli.github.io/tags/script/"},{"title":"Server","uri":"https://wymli.github.io/tags/server/"},{"title":"Socket","uri":"https://wymli.github.io/tags/socket/"},{"title":"Sys","uri":"https://wymli.github.io/tags/sys/"},{"title":"TaskQueue","uri":"https://wymli.github.io/tags/taskqueue/"},{"title":"Temporal","uri":"https://wymli.github.io/tags/temporal/"},{"title":"Tensorflow","uri":"https://wymli.github.io/tags/tensorflow/"},{"title":"Todo","uri":"https://wymli.github.io/tags/todo/"},{"title":"UnderTheHood","uri":"https://wymli.github.io/tags/underthehood/"},{"title":"Ut","uri":"https://wymli.github.io/tags/ut/"},{"title":"Uv","uri":"https://wymli.github.io/tags/uv/"},{"title":"Volcano","uri":"https://wymli.github.io/tags/volcano/"},{"title":"Vue","uri":"https://wymli.github.io/tags/vue/"},{"title":"Workflow","uri":"https://wymli.github.io/tags/workflow/"},{"title":"Wsl","uri":"https://wymli.github.io/tags/wsl/"},{"title":"Zookeeper","uri":"https://wymli.github.io/tags/zookeeper/"}]}