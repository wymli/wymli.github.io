<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deploy on UnderTheHood</title>
    <link>https://wymli.github.io/categories/deploy/</link>
    <description>Recent content in Deploy on UnderTheHood</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>CC BY 4.0 CN</copyright>
    <lastBuildDate>Thu, 25 Mar 2021 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://wymli.github.io/categories/deploy/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[BigData] 大数据入门</title>
      <link>https://wymli.github.io/2022/04/big-data-hadoop%E7%9B%B8%E5%85%B3%E5%85%A5%E9%97%A8/</link>
      <pubDate>Sun, 10 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://wymli.github.io/2022/04/big-data-hadoop%E7%9B%B8%E5%85%B3%E5%85%A5%E9%97%A8/</guid>
      <description>&lt;h1 id=&#34;大数据&#34;&gt;大数据&lt;/h1&gt;
&lt;p&gt;未来工作或多或少要接触大数据，学习下。&lt;/p&gt;
&lt;h1 id=&#34;glossary&#34;&gt;glossary&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;hadoop， 可以认为大数据平台就是hadoop平台/hadoop集群的代名词&lt;/li&gt;
&lt;li&gt;hadoop集群作为基础设施，主要包括存储和调度。存储是hdfs（hadoop distributed file system），调度是yarn（yet another resource negotiater），在计算方面，一般是和用户强相关的，执行的是用户传入的Job，在计算框架上，一般有MapReduce/Spark/Flink等。使用这些分布式计算框架实现的作业，当被yarn调度从而运行时，一般称之为“XX On Yarn”，比如&amp;quot;Spark On yarn&amp;quot;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;hdfs&#34;&gt;Hdfs&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;hdfs是一个流式的分布式的文件存储系统&lt;/li&gt;
&lt;li&gt;存的是文件，但不是以文件为单位分布式副本存储；而是将文件切分成多个小块block（一个block 128MB），每个block将按照一定的副本策略存在多个机器上。&lt;/li&gt;
&lt;li&gt;hdfs的架构主要分为NameNode和DataNode，DataNode存储文件块数据，NameNode存储元数据
&lt;ul&gt;
&lt;li&gt;元数据包括1.目录树信息 2.文件到块的映射 3.块到DataNode的映射&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;hdfs还包括secondaryNameNode，不过这个进程不是很重要，他的工作主要合并日志，NameNode对于写文件操作，一般不是直接进行随机内存访问的直接修改磁盘上的持久化的文件目录数和映射关系（称作fsimage），而是将写操作以日志追加的方式append到一个叫做edit.log的文件中，类似于各种AOF，WAL，secondaryNameNode的工作就是合并fsimage和edit.log（按道理来说，这个合并应该直接让NameNode分出一个线程来合并就完事了，但是这里独立了一个进程，优劣性可以再讨论）&lt;/li&gt;
&lt;li&gt;hdfs是流式的，这意味着文件只能追加，不能修改。一次写入，多次读。&lt;/li&gt;
&lt;li&gt;在写操作时，先写到本地临时文件，当文件大小达到一个块后，开始以4KB为一个packet发送给第一个DataNode，第一个DataNode会接受并转发给第二个DataNode（递归形式），当文件全部写完后，文件才可见。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;yarn&#34;&gt;Yarn&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Yarn是资源管理调度器，所谓的资源是硬件资源，包括内存，CPU，磁盘，网络等，以容器的形式交付给应用&lt;/li&gt;
&lt;li&gt;我感觉就是k8s+docker的感觉，提供统一的nodeManager和容器资源交付。&lt;/li&gt;
&lt;li&gt;架构上是资源管理器（分为资源调度器和应用程序管理器）+节点管理器
&lt;ul&gt;
&lt;li&gt;资源调度器根据需要的资源声明交付容器&lt;/li&gt;
&lt;li&gt;应用程序管理器管理应用的提交，与资源调度器协商资源等&lt;/li&gt;
&lt;li&gt;节点管理器，顾名思义，节点代理，实际上的工作者，分配容器资源，启动工作进程等。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;每个任务的提交需要三个东西
&lt;ul&gt;
&lt;li&gt;应用的Master程序（ApplicationMaster），比如MapReduceApplicationMaster，类似于k8s中CRD Operator的感觉，比如spark中的driver就是这种appMaster程序（也就是spark的main程序，包含sparkcontext）&lt;/li&gt;
&lt;li&gt;应用的Master程序的启动程序，估计是启动脚本一类的。&lt;/li&gt;
&lt;li&gt;用户程序，比如用户自己编写的MapReduce程序&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;我比较好奇容器是怎么交付的，可以深究一下&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[tensorflow-arch] 入门</title>
      <link>https://wymli.github.io/2022/04/tensorflow-intro/</link>
      <pubDate>Sun, 10 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://wymli.github.io/2022/04/tensorflow-intro/</guid>
      <description>&lt;h1 id=&#34;tensorflow入门&#34;&gt;tensorflow入门&lt;/h1&gt;
&lt;h2 id=&#34;intro&#34;&gt;intro&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;tensorflow采用基于数据流图的模型设计方法。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;基础平台层软件设计模式： 库模式和框架模式。库模式下，平台层软件以静态和动态的开发库存在，主程序(main)入口和控制流程掌握在用户手中，比如pytorch，numpy，tensorflow。框架模式下，平台层软件以可执行文件的形式存在，以后端守护进程独立运行，程序的入口和整体流程由框架控制，比如spark，mapreduce。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[脚本] 脚本</title>
      <link>https://wymli.github.io/2021/07/%E8%84%9A%E6%9C%AC/</link>
      <pubDate>Thu, 22 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://wymli.github.io/2021/07/%E8%84%9A%E6%9C%AC/</guid>
      <description>&lt;h2 id=&#34;输出version到文件&#34;&gt;输出version到文件&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;version=`git log --date=iso --pretty=format:&amp;quot;%cd @%H&amp;quot; -1`
if [ $? -ne 0 ]; then
    version=&amp;quot;unknown version&amp;quot;
fi

compile=`date +&amp;quot;%F %T %z&amp;quot;`&amp;quot; by &amp;quot;`go version`
if [ $? -ne 0 ]; then
    compile=&amp;quot;unknown datetime&amp;quot;
fi

describe=`git describe --tags 2&amp;gt;/dev/null`
if [ $? -eq 0 ]; then
    version=&amp;quot;${version} @${describe}&amp;quot;
fi

cat &amp;lt;&amp;lt; EOF | gofmt &amp;gt; pkg/utils/version.go
package utils
const (
    Version = &amp;quot;$version&amp;quot;
    Compile = &amp;quot;$compile&amp;quot;
)
EOF

cat &amp;lt;&amp;lt; EOF &amp;gt; bin/version
version = $version
compile = $compile
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;或&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Go] 多步骤构造器</title>
      <link>https://wymli.github.io/2021/07/go-%E5%A4%9A%E6%AD%A5%E9%AA%A4%E6%9E%84%E5%BB%BA/</link>
      <pubDate>Sat, 10 Jul 2021 12:23:27 +0800</pubDate>
      
      <guid>https://wymli.github.io/2021/07/go-%E5%A4%9A%E6%AD%A5%E9%AA%A4%E6%9E%84%E5%BB%BA/</guid>
      <description>&lt;h1 id=&#34;设计模式-多步骤构造器&#34;&gt;设计模式-多步骤构造器&lt;/h1&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;想像这样一个场景,我们有一个工人类,工人可以吃饭,工作,睡觉&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type worker interface{
    eat()
    work()
    sleep()
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;但是如何获得一个工人呢?常见的我们有一个New函数用于构造:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type workerImpl struct{
}

var _ worker = new(workerImpl)

func NewWorker() workerImpl {
    return &amp;amp;workerImpl{}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;注意这里使用的常见的技巧有:&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[DB] redis</title>
      <link>https://wymli.github.io/2021/07/db-redis/</link>
      <pubDate>Sat, 03 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://wymli.github.io/2021/07/db-redis/</guid>
      <description>&lt;h1 id=&#34;关于redis的大部分事情&#34;&gt;关于redis的大部分事情&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;非常不错: &lt;a href=&#34;https://redis.io/topics/data-types-intro&#34;&gt;https://redis.io/topics/data-types-intro&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;redis的数据结构:
&lt;ul&gt;
&lt;li&gt;Binary-safe strings.&lt;/li&gt;
&lt;li&gt;Lists: collections of string elements sorted according to the order of insertion. They are basically &lt;em&gt;linked lists&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Sets: collections of unique, unsorted string elements.&lt;/li&gt;
&lt;li&gt;Sorted sets, similar to Sets but where every string element is associated to a            floating number value, called &lt;em&gt;score&lt;/em&gt;. The elements are always taken sorted by their score, so unlike Sets it is possible to retrieve a range of elements (for example you may ask: give me the top 10, or the bottom 10).&lt;/li&gt;
&lt;li&gt;Hashes, which are maps composed of fields associated with values. Both the field and the value are strings. This is very similar to Ruby or Python hashes.&lt;/li&gt;
&lt;li&gt;Bit arrays (or simply bitmaps): it is possible, using special commands, to  handle String values like an array of bits: you can set and clear individual bits, count all the bits set to 1, find the first set or unset bit, and so forth.&lt;/li&gt;
&lt;li&gt;HyperLogLogs: this is a probabilistic data structure which is used in order to estimate the cardinality of a set. Don&amp;rsquo;t be scared, it is simpler than it seems&amp;hellip; See later in the HyperLogLog section of this tutorial.&lt;/li&gt;
&lt;li&gt;Streams: append-only collections of map-like entries that provide an abstract log data type. They are covered in depth in the &lt;a href=&#34;https://redis.io/topics/streams-intro&#34;&gt;Introduction to Redis Streams&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;hyperloglog计数(计算集合大小)的误差 less than 1% ,  最多 12KB的空间&lt;/li&gt;
&lt;li&gt;redis的value最多512MB, 但是经验表明100MB就比较慢了&lt;/li&gt;
&lt;li&gt;redis server-assisted client side caching
&lt;ol&gt;
&lt;li&gt;很明显,我们有时候要在机器上做localcache,比如常见的bigcache&lt;/li&gt;
&lt;li&gt;如何保证本地缓存和redis数据的一致性是一个问题
&lt;ol&gt;
&lt;li&gt;简单场景,对实时性要求不高,给本地缓存设置一个过期时间即可&lt;/li&gt;
&lt;li&gt;复杂场景,使用redis的pub/sub系统来发送失效消息(类似基于失效的缓存一致性模型)
&lt;ol&gt;
&lt;li&gt;但是这个发大了太多倍写流量,对每个写,都要发失效消息给每个订阅的client,但很可能那个client其实没有缓存该数据&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;redis实现:
&lt;ol&gt;
&lt;li&gt;tracking模式: redis存储客户端请求过哪些key,当这个key变动时,发送失效消息给客户端; &lt;code&gt;客户端需要显式传送CLIENT TRACKING ON指令来开启tracking&lt;/code&gt;
&lt;ol&gt;
&lt;li&gt;实际上server维护了固定大小的全局一张表,当满时,淘汰旧的key,发送invalid消息,这造成了不必要的流量,但有限减少了server的内存开销&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;broadcasting模式: 客户端决定订阅哪些前缀,server维护一个前缀表,当某个key被修改,server则发往所有订阅了该前缀的client invalid消息,而不管client是否之前read了这个key&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;redis cluster
&lt;ol&gt;
&lt;li&gt;主从读写分离, 写只由master写,读均摊到各个slave?&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;redis 附加组件module
&lt;ol&gt;
&lt;li&gt;比如RedisBloom - Probabilistic Datatypes Module for Redis, 提供了布隆过滤器,topk等数据结构用于大数据流处理&lt;/li&gt;
&lt;li&gt;使用: 在redis.conf中的loadmodule字段配置 /${dir}/redisbloom.so , 该.so的获得一般是通过clone 源代码,然后make&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>[Go] 单测</title>
      <link>https://wymli.github.io/2021/06/go-%E5%8D%95%E6%B5%8B/</link>
      <pubDate>Fri, 25 Jun 2021 12:23:27 +0800</pubDate>
      
      <guid>https://wymli.github.io/2021/06/go-%E5%8D%95%E6%B5%8B/</guid>
      <description>&lt;h1 id=&#34;单测&#34;&gt;单测&lt;/h1&gt;
&lt;p&gt;单测在业务开发的重要性中不言而喻,在常见的epc规范中,一般的存量覆盖率要求达到50%,增量覆盖率要求达到80%.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;当然,这个很教条,我们一般只测有意义的目录,对于像config目录,dao目录测试的必要性不是很高&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>recommend system</title>
      <link>https://wymli.github.io/2021/04/datamining-recsys/</link>
      <pubDate>Tue, 13 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://wymli.github.io/2021/04/datamining-recsys/</guid>
      <description>&lt;h1 id=&#34;推荐系统&#34;&gt;推荐系统&lt;/h1&gt;
&lt;p&gt;utility matrix效用矩阵,横轴是用户,纵轴是商品,矩阵元素是打分&lt;/p&gt;
&lt;p&gt;推荐系统的三个核心步骤:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;收集效用矩阵中的打分&lt;/li&gt;
&lt;li&gt;从已知的打分中预测未知的打分&lt;/li&gt;
&lt;li&gt;评估预测性能&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;gathering-ratings&#34;&gt;Gathering Ratings&lt;/h2&gt;
&lt;p&gt;我们可以显式让用户打分或付钱让它们打分,也可以从它们的行为推测分数,比如它们经常观看,或购买&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[dataMining] LSH</title>
      <link>https://wymli.github.io/2021/04/datamining-lsh/</link>
      <pubDate>Mon, 12 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://wymli.github.io/2021/04/datamining-lsh/</guid>
      <description>&lt;h1 id=&#34;locality-sensitive-hashing&#34;&gt;locality sensitive hashing&lt;/h1&gt;
&lt;p&gt;位置敏感哈希,这是一种hash算法,当两个对象被hash到同一个桶中时,我们认为这两个对象是可能相似的,然后去检查这两个对象的相似性,最后得出答案,这避免了对所有对象两两之间进行O(N^2)的比较&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[c] 符号与链接</title>
      <link>https://wymli.github.io/2021/04/c-%E7%AC%A6%E5%8F%B7%E4%B8%8E%E9%93%BE%E6%8E%A5/</link>
      <pubDate>Sat, 10 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://wymli.github.io/2021/04/c-%E7%AC%A6%E5%8F%B7%E4%B8%8E%E9%93%BE%E6%8E%A5/</guid>
      <description>&lt;h1 id=&#34;c-符号与链接&#34;&gt;[c] 符号与链接&lt;/h1&gt;
&lt;p&gt;我们知道,一个可执行文件的生成过程经历了一些步骤:&lt;/p&gt;
&lt;p&gt;预处理-&amp;gt;编译-&amp;gt;汇编-&amp;gt;链接&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;最终的步骤,是将不同的.o目标文件链接在一起,形成一个可执行文件,不同的.o文件将会引用其他.o文件内的变量或函数,那么它们是怎么找到对应的变量或函数的地址的呢?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[mq] kafka4 工作原理</title>
      <link>https://wymli.github.io/2021/04/mq-kafka4-%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/</link>
      <pubDate>Sat, 03 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://wymli.github.io/2021/04/mq-kafka4-%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/</guid>
      <description>&lt;h1 id=&#34;深入kafka&#34;&gt;深入kafka&lt;/h1&gt;
&lt;p&gt;在此前的系列中,其实对于kafka集群和zk集群的区分很模糊,数据似乎有时是存在某个broker中的,又有时是存在zk中的&lt;/p&gt;
&lt;h2 id=&#34;kafka成员&#34;&gt;kafka成员&lt;/h2&gt;
&lt;p&gt;kafka使用zk来维护集群成员的信息.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[zk] zk1 intro</title>
      <link>https://wymli.github.io/2021/04/zk-zk1-intro/</link>
      <pubDate>Sat, 03 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://wymli.github.io/2021/04/zk-zk1-intro/</guid>
      <description>&lt;h1 id=&#34;intro&#34;&gt;Intro&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;官方文档： &lt;a href=&#34;https://zookeeper.apache.org/doc/r3.4.14/&#34;&gt;https://zookeeper.apache.org/doc/r3.4.14/&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;zookeeper是一种分布式协调服务(也就是说常称的注册中心),分布式应用正在运行的一组系统称为&lt;strong&gt;集群&lt;/strong&gt;，而在集群中运行的每台机器被称为&lt;strong&gt;节点&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[mq] kafka3 consumer</title>
      <link>https://wymli.github.io/2021/04/mq-kafka3-consumer/</link>
      <pubDate>Fri, 02 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://wymli.github.io/2021/04/mq-kafka3-consumer/</guid>
      <description>&lt;h1 id=&#34;kafka3-consumer&#34;&gt;kafka3 consumer&lt;/h1&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&#34;消费组&#34;&gt;消费组&lt;/h2&gt;
&lt;p&gt;往群组里增加消费者是横向伸缩消费能力的主要方式&lt;/p&gt;
&lt;p&gt;消费组内的消费者可以订阅不同的topic,这意味着不是所有的消费者都能接收到某个topic的消息,而必须要订阅&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[mq] kafka1.5 install</title>
      <link>https://wymli.github.io/2021/04/mq-kafka1.5-install/</link>
      <pubDate>Thu, 01 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://wymli.github.io/2021/04/mq-kafka1.5-install/</guid>
      <description>&lt;h1 id=&#34;安装kafka&#34;&gt;安装kafka&lt;/h1&gt;
&lt;p&gt;我们知道apt-get install只能安装某个版本的软件,这取决于在软件源那里的最新软件版本,你可以使用apt-get search搜索看有没有自己想要的版本&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[mq] kafka2 producer</title>
      <link>https://wymli.github.io/2021/03/mq-kafka2-producer/</link>
      <pubDate>Wed, 31 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://wymli.github.io/2021/03/mq-kafka2-producer/</guid>
      <description>&lt;h1 id=&#34;kafka-producer&#34;&gt;kafka producer&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;参考kafka技术内幕:图文详解kafka源码设计和实现&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;本节主要讲关于kafka的生产者相关的事情,比如同步与异步的api调用,底层的网络通信框架(比如rpc)&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[sys] 虚拟内存与缓存缓冲</title>
      <link>https://wymli.github.io/2021/03/sys-virtmempage-cachebuffer-cache/</link>
      <pubDate>Tue, 30 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://wymli.github.io/2021/03/sys-virtmempage-cachebuffer-cache/</guid>
      <description>&lt;h1 id=&#34;虚拟内存virtual-memory&#34;&gt;虚拟内存virtual memory&lt;/h1&gt;
&lt;p&gt;什么是虚拟内存,应该不用多言.本质就是一个逻辑的虚拟地址空间,这些地址空间中,有的地址真正的对应到了物理内存的地址,有的地址却是对应到了磁盘上的地址(通过swap交换换页进入物理内存).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[mq] kafka1 intro</title>
      <link>https://wymli.github.io/2021/03/mq-kafka1-intro/</link>
      <pubDate>Mon, 29 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://wymli.github.io/2021/03/mq-kafka1-intro/</guid>
      <description>&lt;h1 id=&#34;kafka1-intro&#34;&gt;kafka1 intro&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;部分参考&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;kafka技术内幕:图文详解kafka源码设计和实现&lt;/li&gt;
&lt;li&gt;kafka权威指南&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/68052232&#34;&gt;https://zhuanlan.zhihu.com/p/68052232&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/blockquote&gt;
&lt;p&gt;kafka是一种流式数据处理平台(消息队列的进阶版,即除了完成的消息的转发外,还可以处理消息)&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[sys] unix domain socket</title>
      <link>https://wymli.github.io/2021/03/sys-unix-domain-socket/</link>
      <pubDate>Sun, 28 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://wymli.github.io/2021/03/sys-unix-domain-socket/</guid>
      <description>&lt;p&gt;荐读 &lt;a href=&#34;https://lists.freebsd.org/pipermail/freebsd-performance/2005-February/001143.html&#34;&gt;unix domain sockets vs. internet sockets&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;简单说来,就是internet socket(使用AF_INET地址族),即使是dial本机localhost来通信,其也会经历一个完整的网络流程(虽然是通过lo网卡),也会收到syn,ack包,只是碰巧在解析的过程中,机器发现了这个包是要路由到本机的,于是借助lo网卡回来,本质仍然是一种尽力交付&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Other] Go优点</title>
      <link>https://wymli.github.io/2021/03/other-go%E4%BC%98%E7%82%B9/</link>
      <pubDate>Sat, 27 Mar 2021 21:09:05 +0800</pubDate>
      
      <guid>https://wymli.github.io/2021/03/other-go%E4%BC%98%E7%82%B9/</guid>
      <description>&lt;h1 id=&#34;列举我心目中的go的优点&#34;&gt;列举我心目中的go的优点&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;实现开源,源代码可以很方便的通过代码跳转去追踪,而不像c/c++都是链接库,或者只能追踪到头文件&lt;/li&gt;
&lt;li&gt;现代的包管理go get/go mod,类似pip一样方便的包安装,但是也有很多不足,经常被人诟病
&lt;ol&gt;
&lt;li&gt;但就我个人使用上,感觉还是比较方便&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;类,结构与方法分离. 这在阅读源代码时很方便清爽,不必被各种inline函数搞得眼花缭乱
&lt;ol&gt;
&lt;li&gt;虽然go严格并没有类的概念&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;方便的方法函数拓展,只需要新写一个方法即可,不需要改动任何原来的代码&lt;/li&gt;
&lt;li&gt;简洁的语法,不必把时间花费在底层理解上,但这也导致了无法极度的优化,不过相信大多数程序员都没有那么强,仍然利大于弊,不同的语言用来解决不同领域的问题&lt;/li&gt;
&lt;li&gt;go的文档是直接放在一页的,直接ctrf-f搜索,很方便&lt;/li&gt;
&lt;li&gt;待更&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>[Interview] ByteDance2</title>
      <link>https://wymli.github.io/2021/03/interview-bytedance2/</link>
      <pubDate>Sat, 27 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://wymli.github.io/2021/03/interview-bytedance2/</guid>
      <description>&lt;h1 id=&#34;字节二面&#34;&gt;字节二面&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;算法题: 二叉树中的最长距离
&lt;ol&gt;
&lt;li&gt;又拉跨了,太久没做题了,做了很久&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;并发和并行的区别&lt;/li&gt;
&lt;li&gt;讲讲go的协程调度
&lt;ol&gt;
&lt;li&gt;GMP模型,balabala讲一堆,提到了netpoller,触发linux io复用剧情&lt;/li&gt;
&lt;li&gt;讲到了steal机制,面试官问我为什么在全局队列未空的时候要去steal呢?
&lt;ol&gt;
&lt;li&gt;回答,应该不会吧,毕竟其他p的g可能不在一个核上,会增加cahce缺失率&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;讲讲linux的io复用
&lt;ol&gt;
&lt;li&gt;select/poll/epoll&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;select和epoll的区别
&lt;ol&gt;
&lt;li&gt;说了些常见的,比如select用链表不限制fd个数,但是触发后要遍历所有fd,epoll只需要遍历已经激活的fd,数组的前n个&lt;/li&gt;
&lt;li&gt;似乎不是面试官想要的,让我回去再看看&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;提到epoll只返回激活的fd的个数,问我怎么设计这个数据结构
&lt;ol&gt;
&lt;li&gt;其实没搞懂想问什么,于是我balabal扯了一堆&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;讲讲docker
&lt;ol&gt;
&lt;li&gt;一种linux容器&lt;/li&gt;
&lt;li&gt;虚拟化,轻量级,隔离&lt;/li&gt;
&lt;li&gt;dockerfile可以很方便的构建容器镜像&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;讲讲TCP的分包
&lt;ol&gt;
&lt;li&gt;tcp是面向流的协议&lt;/li&gt;
&lt;li&gt;基于长度&lt;/li&gt;
&lt;li&gt;基于分隔符&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;分隔符和内容冲突了怎么办?
&lt;ol&gt;
&lt;li&gt;转义
&lt;ol&gt;
&lt;li&gt;这里可以参考http协议,使用\r\n来分隔,对于body,会使用base64编码转义成文本字符,header和body之间有两个\r\n来区分&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;配对
&lt;ol&gt;
&lt;li&gt;比如json,xml这种,但显然面临注入的风险,也要转义&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;定长
&lt;ol&gt;
&lt;li&gt;对于简单的报文,直接定长即可&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;看我实验室的经历,问我知道哪些机器学习算法
&lt;ol&gt;
&lt;li&gt;讲了些简单的&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;怎么对垃圾邮件分类
&lt;ol&gt;
&lt;li&gt;首先肯定是要特征工程,将邮件编码为欧氏空间中的一个点(向量,embedding),然后就是加标签之类的,丢到算法里面fit参数,我只懂些皮毛&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;问我svm怎么分类
&lt;ol&gt;
&lt;li&gt;没搞懂要问什么,以为要讲原理,我说一个分类间隔,支持向量啥啥啥的,反正我不懂,瞎扯一堆&lt;/li&gt;
&lt;li&gt;最后说只需要怎么使用
&lt;ol&gt;
&lt;li&gt;那不是直接丢进去fit参数就行了嘛,重点在特征工程,分词那些吧,没搞懂面试官的逻辑&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;其他,忘了,暂时只想起来这么多&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>[rpc] grpc</title>
      <link>https://wymli.github.io/2021/03/rpc-grpc/</link>
      <pubDate>Sat, 27 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://wymli.github.io/2021/03/rpc-grpc/</guid>
      <description>&lt;h1 id=&#34;grpc&#34;&gt;grpc&lt;/h1&gt;
&lt;p&gt;grpc是一种rpc框架,先不管其实现或特点.首先我们明确,不管是什么rpc框架,其最终目标都是让用户能够在应用层轻松的调用远程的函数,就像在本机上调用一样.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
